{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, cross_val_predict,  StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, make_scorer, confusion_matrix, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import RFE\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucap\\AppData\\Local\\Temp\\ipykernel_13396\\1101075947.py:3: DtypeWarning: Columns (0,4,8,9,10,11,12,13,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,44,45,46,47,49,50,51,52,53,54,55,61,62,63,64,65,66,68,69,70,71,78,80,82,84,85,86,87,91,93,94,96,97,98,99,101,102,103,105,106,108,109,110,111,113,114,115,117,118,119,120,121,123,124,125,126,128,129,130,132,133,134,136,137,138,139,140,142,143,144,145,146,147,148,150,151,153,154,155,157,158,159,162,164,165,166,167,169,170,171,172,173,174,175,176,177,178,179,180,181,182,184,185,186,187,188,189,190,191,192,194,195,196,197,198,199,200,201,202,203,204,205,207,209,211,212,213,214,215,217,218,219,221,222,223,224,225,226,227,228,229,230,231,232,233,235,236,239,240,242,243,245,246,248,249,250,251,252,253,254,255,256,257,258,261,263,264,265,266,267,272,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,292,293,294,295,296,297,298,299,300,301,302,303,305,306,307,309,310,311,312,313,314,316,317,318,320,321,322,324,325,326,327,328,330,331,332,333,334,335,337,338,339,340,342,343,344,345,346,347,348,349,350,352,353,354,356,357,358,359,360,362,363,364,365,367,368,369,370,371,372,373,374,376,377,378,379,380,381,382,384,385,386,387,388,389,390,392,393,394,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,419,420,421,422,423,424,426,427,428,429,431,432,433,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,472,473,474,475,476,477,478,480,481,482,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,517,518,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,551,552,553,554,555,556,557,559,560,561,562,563,564,565,566,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,604,605,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,628,629,630,631,632,633,634,636,637,638,639,641,642,643,644,646,647,648,649,651,652,653,656,657,658,659,660,661,662,663,664,665,666,667,669,670,671,672,674,675,676,677,678,680,682,684,685,686,688,689,690,691,692,693,694,695,696,697,698,700,701,702,703,704,705,706,707,709,710,711,713,714,715,716,717,718,719,720,721,722,724,725,726,727,728,729,730,731,734,735,737,738,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath, sep = \";\" )\n"
     ]
    }
   ],
   "source": [
    "#lettura csv\n",
    "filepath = r\"C:\\Users\\lucap\\OneDrive\\Desktop\\PhD\\Paper SDS\\Walden 97-19 integrated v2.csv\"\n",
    "df = pd.read_csv(filepath, sep = \";\" )\n",
    "#df = df[df['m_anno_indagine'] > 2016] #seleziono le righe che riguardano l'osservatorio dal 2019 in poi\n",
    "df = df[df['m_anno_indagine']>=2017].drop_duplicates(subset='IDU', keep=\"last\")\n",
    "df = df[\n",
    "   df.columns[ df.isna().sum() <= 0.3 * len(df) ] ]#seleziono solo le colonne hanno valori Nan inferiori al 30%\n",
    "# Rimuovere gli spazi bianchi da tutte le colonne\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['m_sesso'] = le.fit_transform(df['m_sesso'])\n",
    "df['m_p_pubblico_privato'] = le.fit_transform(df['m_p_pubblico_privato'])\n",
    "df['m_p_nascita_in_italia_genitori'] = le.fit_transform(df['m_p_nascita_in_italia_genitori'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsToDrop = ['IDU','m_anno_indagine','m_pesos','m_peso',\"m_p_cittadinanza\", \"m_p_data_nascita\", \"m_modalita_telefono_vs_online\",\n",
    "    'm_p_comune_istat',\n",
    "                'm_p_data_nascita','m_p_eta_6',\n",
    "                    'm_p_in_ita_dal','m_p_origini',\n",
    "                            'm_sr_professione','m_sr_statusSocioEconomico_ceto',\"m_p_autocol\"\n",
    "                            ] # rimuovo regioni perchè uso one hot e non voglio aumentare troppo il numero di colonne\n",
    "df= df.drop(varsToDrop, axis=1)\n",
    "\n",
    "\n",
    "# # Demografiche\n",
    "# varsToDrop = ['IDU','m_anno_indagine','m_pesos','m_peso',\"m_p_cittadinanza\", \"m_p_data_nascita\", \"m_modalita_telefono_vs_online\",\n",
    "#     'm_p_frequenza_cinema','m_p_frequenza_teatro','m_p_frequenza_concerti',\n",
    "#         'm_p_frequenza_mostre','m_p_frequenza_palestra_sport',\n",
    "#             'm_modernizz_vs_regress_Paese',\n",
    "#                 'm_fiducia_proprieIdee_rispetto_avvenimentiMondo','m_p_comune_istat',\n",
    "#                 'm_p_data_nascita','m_p_eta_6',\\\n",
    "#                     'm_p_in_ita_dal','m_p_origini',\n",
    "#                         'm_p_radio_ore','m_p_lettura_quotidiani','m_p_iscrizione_sindacato',\n",
    "#                             'm_sr_professione','m_sr_statusSocioEconomico_ceto',\"m_p_autocol\"\n",
    "#                               ,\"m_istat_reg\"] # rimuovo regioni perchè uso one hot e non voglio aumentare troppo il numero di colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4504, 204)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsToDrop_val = [\"m_op_unita_nazionale\", \"m_op_costituzione.1\",\"m_op_miglioramento_rapp_stato_cittadini\",\n",
    "    \"m_op_disorientamento_realta_quotidiana_vs_3anniFa\", \"m_op_ventennio\", \"m_op_attitudine_italiani_fascismo\", \"m_op_criminalita_ultimiAnni_doveVive\",\n",
    "    \"m_op_situazEconomic_propria_ultimi10anni\", \"m_op_situazEconomic_futura\", \"m_op_legge_aborto_1987\", \"m_op_tensioneSociale_italianiVSextracom_propriaCitta\",\n",
    "    \"m_op_organizzazioneEuropa_futuro\",\"m_op_sentimento_italianoVSeuropeo\", \"m_op_importanza_essereItaliano\", \"m_op_fiducia_in_sindacati\",\n",
    "    \"m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico\", \"m_op_fiducia_negli_altri\", \"m_op_sistemaScolasticoItaliano\", \"m_op_scuolaPubblica_ultimiAnni\",\n",
    "    \"m_op_reazione_a_discussioni_politiche\", \"m_op_paure_della_vecchiaia\", \"m_op_reazione_a_discussioni_politiche\", \"m_op_origine_maggiorImpulso_ripresa_italia\",\n",
    "    \"m_op_fiducia_negli amici che fanno parte della sua rete social network\",\n",
    "\"m_op_fiducia_nei familiari con cui convive\",\n",
    "\"m_op_fiducia_negli italiani\",\n",
    "\"m_op_fiducia_nei suoi parenti\",\n",
    "\"m_op_fiducia_negli amici e conoscenti dei suoi familiari\",\n",
    "\"m_op_fiducia_nei colleghi di lavoro\",\n",
    "\"m_op_fiducia_nei vicini di casa\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_degli italiani\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_degli amici che fanno parte della sua rete social network\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_dei familiari con cui convive\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_dei suoi parenti\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_degli amici e conoscenti dei suoi familiari\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_dei colleghi di lavoro\",\n",
    "\"m_op_aiutoReciproco_inCasoDiBisogno_dei vicini di casa\",\n",
    "\"m_op_causePrincipali_violenzaDonne_1\",\n",
    "\"m_op_causePrincipali_violenzaDonne_2\",\n",
    "\"m_op_circostanze_cheGiustificano_violenzaMoglie\",\n",
    "\"m_op_priorita_per_affrontare_violenzaDonne_1\",\n",
    "\"m_op_priorita_per_affrontare_violenzaDonne_2\",\n",
    "\"m_ac_preparazione_nuoveGenerazioni_piuScadente\",\n",
    "\"m_op_rimanere_in_propriaZona_vs_spostarsi\",\n",
    "\"m_op_preferenza_lavorativa\",\n",
    "\"m_op_definizione_bene_comune\",\n",
    "\"m_op_ottica_di_beneComune_italia\",\n",
    "\"m_op_ottica_di_beneComune_comuneResidenza\",\n",
    "\"m_op_pericoliEdisagi_figli_cheSpaventano_genitori_01\",\n",
    "\"m_op_pericoliEdisagi_figli_cheSpaventano_genitori_02\",\n",
    "\"m_op_pericoliEdisagi_figli_cheSpaventano_genitori_03\",\n",
    "\"m_op_pericoliEdisagi_figli_cheSpaventano_genitori_04\",\n",
    "\"m_op_cosa_contradistingue_comunita\",\n",
    "\"m_op_caratteristiche_dei_politici_apprezzati\",\n",
    "\"m_op_definizione_populismo\",\n",
    "\"m_op_danni_populismo_in_italia\",\n",
    "\"m_op_quanto_populista_PD\",\n",
    "\"m_op_quanto_populista_M5S\",\n",
    "\"m_op_quanto_populista_Lega\",\n",
    "\"m_op_quanto_populista_FI\",\n",
    "\"m_op_attualita_concetti_sinistraCentroDestra\",\n",
    "\"m_TREND_15_FASCISMO NEW\",\n",
    "\"m_op_cambio_legge_aborto\",\n",
    "\"m_op_favore_eutanasia_a_determinate_condizioni\",\n",
    "\"m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff\",\n",
    "\"m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative\",\n",
    "\"m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili\",\n",
    "\"m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura\",\n",
    "\"m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti\",\n",
    "\"m_op_contributoDelSingolo_salvaguardia_ambiente\",\n",
    "\"m_op_impegnoPersone_in_tutelaAmbiente\",\n",
    "\"m_op_inclusione_societa\",\n",
    "\"m_op_partecipazione_in_UE\",\n",
    "\"m_op_comunita_appartenenza_01\",\n",
    "\"m_op_disorientamento_veros_realta_quotidiana\",\n",
    "\"m_op_rinuncie_per_postoStabile\",\n",
    "\"m_op_margineIntervento_vita\",\n",
    "\"m_op_profilo_socioCulturale_vs_genitori\"\n",
    "]\n",
    "df= df.drop(varsToDrop_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "varsToDrop_val = [\"m_op_unita_nazionale\", 'm_op_costituzione.1','m_op_miglioramento_rapp_stato_cittadini','m_op_ventennio',\n",
    "'m_op_criminalita_ultimiAnni_doveVive','m_op_cambio_legge_aborto','m_op_organizzazioneEuropa_futuro', 'm_op_fiducia_in_sindacati','m_p_iscrizione_sindacato'\n",
    ",'m_op_tensioneSociale_italianiVSextracom_propriaCitta','m_op_sistemaScolasticoItaliano','m_op_reazione_a_discussioni_politiche',\n",
    "'m_op_fiducia_negli_altri','m_op_inclusione_societa','m_op_margineIntervento_vita','m_op_paure_della_vecchiaia','m_fiducia_proprieIdee_rispetto_avvenimentiMondo'\n",
    ",'m_op_origine_maggiorImpulso_ripresa_italia', 'm_op_profilo_socioCulturale_vs_genitori','m_op_causePrincipali_violenzaDonne_1','m_op_causePrincipali_violenzaDonne_2',\n",
    "'m_op_circostanze_cheGiustificano_violenzaMoglie','m_op_priorita_per_affrontare_violenzaDonne_1','m_op_priorita_per_affrontare_violenzaDonne_2', 'm_TREND_15_FASCISMO NEW',\n",
    "'m_op_quanto_populista_PD','m_op_quanto_populista_M5S','m_op_quanto_populista_Lega','m_op_quanto_populista_FI','m_op_definizione_populismo',\n",
    "'m_op_caratteristiche_dei_politici_apprezzati','m_op_cosa_contradistingue_comunita','m_op_pericoliEdisagi_figli_cheSpaventano_genitori_04',\n",
    "'m_op_pericoliEdisagi_figli_cheSpaventano_genitori_03','m_op_pericoliEdisagi_figli_cheSpaventano_genitori_02','m_op_pericoliEdisagi_figli_cheSpaventano_genitori_01',\n",
    "'m_op_definizione_bene_comune','m_op_comunita_appartenenza_01','m_p_zona_5istat','m_op_rimanere_in_propriaZona_vs_spostarsi',\n",
    "'m_ac_preparazione_nuoveGenerazioni_piuScadente','m_op_attualita_concetti_sinistraCentroDestra','m_op_importanza_essereItaliano',\n",
    "'m_op_attitudine_italiani_fascismo']\n",
    "df= df.drop(varsToDrop_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_sesso</th>\n",
       "      <th>m_p_r_eta</th>\n",
       "      <th>m_p_scolarita</th>\n",
       "      <th>m_p_pubblico_privato</th>\n",
       "      <th>m_p_r_ampiezza6</th>\n",
       "      <th>m_istat_reg</th>\n",
       "      <th>m_p_nascita_in_italia_genitori</th>\n",
       "      <th>m_p_frequenza_cinema</th>\n",
       "      <th>m_p_frequenza_teatro</th>\n",
       "      <th>m_p_frequenza_concerti</th>\n",
       "      <th>m_p_frequenza_mostre</th>\n",
       "      <th>m_p_frequenza_palestra_sport</th>\n",
       "      <th>m_p_radio_ore</th>\n",
       "      <th>m_p_lettura_quotidiani</th>\n",
       "      <th>m_ac_valore_attuale_patria</th>\n",
       "      <th>m_ac_privilegio_lavoratori_sett_pubblico</th>\n",
       "      <th>m_ac_propensioneRischio_italia_vs_europa</th>\n",
       "      <th>m_ac_importanza_partiti</th>\n",
       "      <th>m_ac_diminuzione_ruolo_partiti</th>\n",
       "      <th>m_ac_affidamento_pubblica_tecnici</th>\n",
       "      <th>m_ac_valori_resistenza_altra_epoca</th>\n",
       "      <th>m_ac_sindacato_ancoraUtile</th>\n",
       "      <th>m_ac_uguaglianza_sociale_frena_individui</th>\n",
       "      <th>m_ac_troppo_focus_uguaglianza_vs_merito</th>\n",
       "      <th>m_ac_meglio_uguaglianza_vs_merito_singolo</th>\n",
       "      <th>m_op_disorientamento_veros_realta_quotidiana</th>\n",
       "      <th>m_op_disorientamento_realta_quotidiana_vs_3anniFa</th>\n",
       "      <th>m_ac_vantaggi_globalizz_economie_mercati</th>\n",
       "      <th>m_ac_globaliz_inarrestabile</th>\n",
       "      <th>m_ac_dovere_difesa_produzPaese_vs_globaliz</th>\n",
       "      <th>m_ac_aumento_competizione_con_piuPreparati</th>\n",
       "      <th>m_ac_aumento_stress_competizione</th>\n",
       "      <th>m_ac_percez_inadeguatezza_da_velocitaCambiamento</th>\n",
       "      <th>m_ac_nonSicuro_doveVive</th>\n",
       "      <th>m_ac_repressione_unicaArma_vs_crimin</th>\n",
       "      <th>m_ac_crimin_diventera_incontenibile</th>\n",
       "      <th>m_op_situazEconomic_propria_ultimi10anni</th>\n",
       "      <th>m_op_situazEconomic_futura</th>\n",
       "      <th>m_op_come_reddito_consenteDiVivere</th>\n",
       "      <th>m_op_legge_aborto_1987</th>\n",
       "      <th>m_ac_validita_insegnamChiesa</th>\n",
       "      <th>m_op_favore_eutanasia_a_determinate_condizioni</th>\n",
       "      <th>m_ac_societa_troppoPermissiva_gay</th>\n",
       "      <th>m_ac_legalizz_drogheLeggere</th>\n",
       "      <th>m_ac_chiesa_nonDovrebbe_condizionare_stato.1</th>\n",
       "      <th>m_ac_testamento_biologico</th>\n",
       "      <th>m_ac_immigrati_rubano_lavoro</th>\n",
       "      <th>m_ac_immigrati_risorsa</th>\n",
       "      <th>m_ac_immigrati_portano_criminalita</th>\n",
       "      <th>m_ac_immigrati_devono_adeguarsi</th>\n",
       "      <th>m_ac_immigrati_diritto_voto</th>\n",
       "      <th>m_ac_immigrati_nonRispettano_regoleDelloStareInsieme</th>\n",
       "      <th>m_op_sentimento_italianoVSeuropeo</th>\n",
       "      <th>m_ac_modernizzazioneItalia_grazie_UE</th>\n",
       "      <th>m_ac_giovani di 30anniFa miglioriDiOggi</th>\n",
       "      <th>m_ac_giovaniOggi_incapaci_fareSacrifici</th>\n",
       "      <th>m_ac_nuoveGenerazioni_miglioreranno_mondo</th>\n",
       "      <th>m_ac_impegnoSocialeGiovani_sempreMenoForte</th>\n",
       "      <th>m_ac_governatori_scegliere_senzaBadareOpposizione</th>\n",
       "      <th>m_ac_mediazione_nonRisolve_problemi</th>\n",
       "      <th>m_ac_ricercaCompromesso_faMarcire_situazioni</th>\n",
       "      <th>m_ac_religioneIslamica_pericoloPerTutti</th>\n",
       "      <th>m_ac_musulmaniInItalia_dirittoReligione_inScuole</th>\n",
       "      <th>m_ac_italia_troppeConcessioni_immigratiMusulmani</th>\n",
       "      <th>m_ac_generazioniFuture_vivrannoPeggio</th>\n",
       "      <th>m_modernizz_vs_regress_Paese</th>\n",
       "      <th>m_ac_passato_vivereMeglio_ancheSePiuPoveri</th>\n",
       "      <th>m_ac_italia_paeseInDeclino</th>\n",
       "      <th>m_op_partecipazione_in_UE</th>\n",
       "      <th>m_ac_scienza_problemi_piuChe_benefici</th>\n",
       "      <th>m_ac_scoperte_scientificTecnol_rendono_vita_piuFacile</th>\n",
       "      <th>m_ac_troppo_allarmismo_ecologia_inquinamento</th>\n",
       "      <th>m_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente</th>\n",
       "      <th>m_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo</th>\n",
       "      <th>m_op_contributoDelSingolo_salvaguardia_ambiente</th>\n",
       "      <th>m_op_impegnoPersone_in_tutelaAmbiente</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti</th>\n",
       "      <th>m_ac_sacrificioEconomico_per_migliorare_ScuolaUniversitaRicerca</th>\n",
       "      <th>m_ac_ScuolaEFormazione_principaleProblema_delPaese</th>\n",
       "      <th>m_op_scuolaPubblica_ultimiAnni</th>\n",
       "      <th>m_ac_scuola_deveEssere_severa_selettiva_meritocratica</th>\n",
       "      <th>m_ac_valorizzare_scuoleEccellenza</th>\n",
       "      <th>m_ac_difesa_scuolaPubblica_insensata</th>\n",
       "      <th>m_ac_attuale_classeInsegnante_incompetente</th>\n",
       "      <th>m_ac_sperimentazioniGenetiche_piuRischi_cheVantaggi</th>\n",
       "      <th>m_ac_problemi_eticiMorali_sperimentazioneGenetica</th>\n",
       "      <th>m_ac_nord_unicoMotore_economiaItaliana</th>\n",
       "      <th>m_ac_lavoroNord_consente_diEssere_alPasso_con_UE</th>\n",
       "      <th>m_ac_guerre_talvolta_maleNecessario.1</th>\n",
       "      <th>m_ac_italia_ipartecipazioneIn_missioniMilitariEstere</th>\n",
       "      <th>m_ac_lavorare_importante_postoStabile_no</th>\n",
       "      <th>m_op_rinuncie_per_postoStabile</th>\n",
       "      <th>m_ac_badare_propriInteressi_perSopravvivere</th>\n",
       "      <th>m_ac_sentirsiSpesso_solo_isolato</th>\n",
       "      <th>m_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti</th>\n",
       "      <th>m_ac_modelloImprenditorialePrivato_unico_meritocratico</th>\n",
       "      <th>m_ac_modelloImprenditorialePrivato_unico_garantireEquita</th>\n",
       "      <th>m_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale</th>\n",
       "      <th>m_ac_dazi_su_produzioni_importanti</th>\n",
       "      <th>m_ac_comprareItaliano_perFronteggiare_crisi</th>\n",
       "      <th>m_ac_generazionePrecedente_piuFelice</th>\n",
       "      <th>m_ac_generazionePrecedente_migliore_qualitaVita</th>\n",
       "      <th>m_ac_generazionePrecedente_maggiore_sicurezzaLavorativa</th>\n",
       "      <th>m_ac_generazionePrecedente_maggiore_mobilitaEconomicoSociale</th>\n",
       "      <th>m_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa</th>\n",
       "      <th>m_op_fiducia_negli italiani</th>\n",
       "      <th>m_op_fiducia_negli amici che fanno parte della sua rete social network</th>\n",
       "      <th>m_op_fiducia_nei familiari con cui convive</th>\n",
       "      <th>m_op_fiducia_nei suoi parenti</th>\n",
       "      <th>m_op_fiducia_negli amici e conoscenti dei suoi familiari</th>\n",
       "      <th>m_op_fiducia_nei colleghi di lavoro</th>\n",
       "      <th>m_op_fiducia_nei vicini di casa</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_degli italiani</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_degli amici che fanno parte della sua rete social network</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei familiari con cui convive</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei suoi parenti</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_degli amici e conoscenti dei suoi familiari</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei colleghi di lavoro</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei vicini di casa</th>\n",
       "      <th>m_op_preferenza_lavorativa</th>\n",
       "      <th>m_op_ottica_di_beneComune_italia</th>\n",
       "      <th>m_op_ottica_di_beneComune_comuneResidenza</th>\n",
       "      <th>m_op_importanza_farParte_comunita</th>\n",
       "      <th>m_op_sviluppo_sensoCivico_Paese</th>\n",
       "      <th>m_op_attività_associazionismo_Italia</th>\n",
       "      <th>m_op_importanza_nellaSocieta_solidarieta</th>\n",
       "      <th>m_op_importanza_nellaSocieta_altruismo</th>\n",
       "      <th>m_op_importanza_nellaSocieta_mutualismo</th>\n",
       "      <th>m_op_danni_populismo_in_italia</th>\n",
       "      <th>m_op_peso_volontariato_in_economiaPaese</th>\n",
       "      <th>m_p_int_voto</th>\n",
       "      <th>m_TREND_1_PATRIA E UNITA' NAZIONALE (credono ancora nellla patria)</th>\n",
       "      <th>m_TREND_7_SFIDUCIA NEL SISTEMA DEI PARTI</th>\n",
       "      <th>m_TREND_8_VALORI FONDATIVI (mantiene radicati i valori)</th>\n",
       "      <th>m_TREND_10_MERITO (propende per la meritocrazia)</th>\n",
       "      <th>m_TREND_15_INADEGUATEZZA INDIVIDUALE</th>\n",
       "      <th>m_TREND_19_SICUREZZA - CRIMINALITA' (si sente al sicuro)</th>\n",
       "      <th>m_TREND_25_IMMIGRAZIONE (atteggiamento POSITIVO nei confronti degli immigrati)</th>\n",
       "      <th>m_TREND_26_NAZIONE EUROPA</th>\n",
       "      <th>m_TREND_27_SINDACATO (crede ancora nel modello sindacale)</th>\n",
       "      <th>m_TREND_28_GIOVANI (fiducia alle nuove generazioni)</th>\n",
       "      <th>m_TREND_29_RADICALIZZAZIONE (crede nel compromesso)</th>\n",
       "      <th>m_TREND_30_ISLAM (tolleranza e fiducia nei confronti dell Islam)</th>\n",
       "      <th>m_TREND_31_EPOCALITA' E FUTURO SMARRITO (nostalgico nei confronti del passato)</th>\n",
       "      <th>m_TREND_35_EUROPA E MODERNITA' (crede che l'entrata in Europa abbia modernizzato il nostro paese)</th>\n",
       "      <th>m_TREND_37_SCIENZA FECONDA (crede nelle potenzialita' dell'innovazione scientifica)</th>\n",
       "      <th>m_TREND_39_SCUOLA E FORMAZIONE (formazione e' una priorita' del Paese)</th>\n",
       "      <th>m_TREND_46_SPERIMENTAZIONE GENETICA</th>\n",
       "      <th>m_TREND_53_INCLUSI ED ESCLUSI (si sente pienamente parte della societa)</th>\n",
       "      <th>m_TREND_50_IL MODELLO IMPRESA (individua nell'impresa modello economico vincente)</th>\n",
       "      <th>m_TREND_56_TERRITORIALITA' (2009) (individua nella difesa della territorialita' l'arma vicente)</th>\n",
       "      <th>m_TREND_58_CONFRONTO CON LA GENERAZIONE PASSATA</th>\n",
       "      <th>m_TREND_52_SOLIDARIETA'</th>\n",
       "      <th>m_TREND_53_IL PERICOLO POPULISTA</th>\n",
       "      <th>m_TREND_54_DISORIENTAMENTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31575</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>laurea specialistica di II livello o laurea 4-...</td>\n",
       "      <td>1</td>\n",
       "      <td>da 100.001 a 250.000</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>1</td>\n",
       "      <td>alcune volte l'anno</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>alcune volte l'anno</td>\n",
       "      <td>mai</td>\n",
       "      <td>da piu' di un'ora fino a due ore</td>\n",
       "      <td>si alcune volte alla settimana</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne d'accordo ne' in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>poco</td>\n",
       "      <td>maggiore</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>rimasta la stessa</td>\n",
       "      <td>peggiorare</td>\n",
       "      <td>con tranquillita'</td>\n",
       "      <td>una cattiva legge</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>no</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>piu' europeo che italiano</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>si sta modernizzando</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo</td>\n",
       "      <td>piu' vantaggi</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>molto</td>\n",
       "      <td>poco</td>\n",
       "      <td>bassa</td>\n",
       "      <td>media</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>rimasta uguale</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>preferisco non rispondere</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>molta</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>pocao</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>molto</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>pocao</td>\n",
       "      <td>pocao</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>Nel settore pubblico</td>\n",
       "      <td>poco</td>\n",
       "      <td>poco</td>\n",
       "      <td>molto</td>\n",
       "      <td>poco</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>poco</td>\n",
       "      <td>molti danni</td>\n",
       "      <td>molto</td>\n",
       "      <td>Partito Democratico-PD</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>non classificati</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31576</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>laurea triennale di I livello</td>\n",
       "      <td>0</td>\n",
       "      <td>da 30.001 a 100.000</td>\n",
       "      <td>Lombardia</td>\n",
       "      <td>1</td>\n",
       "      <td>mensile</td>\n",
       "      <td>mai</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>piu' volte alla settimana</td>\n",
       "      <td>oltre quattro</td>\n",
       "      <td>si ogni giorno</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo</td>\n",
       "      <td>poco</td>\n",
       "      <td>inferiore</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>peggiorata</td>\n",
       "      <td>rimanere la stessa</td>\n",
       "      <td>arrivo a fine mese con molte difficolta'</td>\n",
       "      <td>una legge buona ma che va cambiata</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>si</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>piu' europeo che italiano</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>si sta modernizzando</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>vantaggi e svantaggi in egual misura</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>poco</td>\n",
       "      <td>poco</td>\n",
       "      <td>bassa</td>\n",
       "      <td>media</td>\n",
       "      <td>media</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>peggiorata</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>molta</td>\n",
       "      <td>molta</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>nessuna</td>\n",
       "      <td>pocao</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>molto</td>\n",
       "      <td>molto</td>\n",
       "      <td>per niente</td>\n",
       "      <td>pocao</td>\n",
       "      <td>per niente</td>\n",
       "      <td>Libero professionista</td>\n",
       "      <td>per niente</td>\n",
       "      <td>poco</td>\n",
       "      <td>per niente</td>\n",
       "      <td>per niente</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>nessun danno</td>\n",
       "      <td>poco</td>\n",
       "      <td>MoVimento 5 Stelle</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31577</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>universita` in corso/nessuna laurea conseguita</td>\n",
       "      <td>1</td>\n",
       "      <td>da 100.001 a 250.000</td>\n",
       "      <td>Sardegna</td>\n",
       "      <td>1</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>meno di un'ora</td>\n",
       "      <td>si alcune volte alla settimana</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>molto</td>\n",
       "      <td>maggiore</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arrivo a fine mese con molte difficolta'</td>\n",
       "      <td>una buona legge</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>dipende dalle condizioni</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>solo italiano</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>sta regredendo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>piu' svantaggi</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>poco</td>\n",
       "      <td>alta</td>\n",
       "      <td>media</td>\n",
       "      <td>bassa</td>\n",
       "      <td>media</td>\n",
       "      <td>media</td>\n",
       "      <td>alta</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>peggiorata</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto&lt;BR&gt;in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>molta</td>\n",
       "      <td>molta</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>pocao</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>molto</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>pocao</td>\n",
       "      <td>pocao</td>\n",
       "      <td>pocao</td>\n",
       "      <td>Nel settore pubblico</td>\n",
       "      <td>per niente</td>\n",
       "      <td>per niente</td>\n",
       "      <td>molto</td>\n",
       "      <td>per niente</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>nessun danno</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>sono indeciso</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31578</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>master/scuola di specializzazione post laurea</td>\n",
       "      <td>1</td>\n",
       "      <td>da 5.001 a 10.000</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>1</td>\n",
       "      <td>alcune volte l'anno</td>\n",
       "      <td>alcune volte l'anno</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>mai</td>\n",
       "      <td>meno di un'ora</td>\n",
       "      <td>si ogni giorno</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne d'accordo ne' in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>uguale</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>non sa/non risponde</td>\n",
       "      <td>peggiorare</td>\n",
       "      <td>avverto difficolta'</td>\n",
       "      <td>una buona legge</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>si</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>sia italiano che europeo</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>si sta modernizzando</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo</td>\n",
       "      <td>vantaggi e svantaggi in egual misura</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>poco</td>\n",
       "      <td>media</td>\n",
       "      <td>alta</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>media</td>\n",
       "      <td>media</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>peggiorata</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto disaccordo</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto&lt;BR&gt;d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>molta</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>poca&amp;nbsp;</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>pocao</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>pocao</td>\n",
       "      <td>pocao</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>pocao</td>\n",
       "      <td>Nel settore pubblico</td>\n",
       "      <td>poco</td>\n",
       "      <td>poco</td>\n",
       "      <td>molto</td>\n",
       "      <td>poco</td>\n",
       "      <td>molto</td>\n",
       "      <td>molto</td>\n",
       "      <td>poco</td>\n",
       "      <td>poco</td>\n",
       "      <td>qualche danno</td>\n",
       "      <td>molto</td>\n",
       "      <td>Sinistra italiana (SEL + altri)</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight in trend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31579</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>laurea specialistica di II livello o laurea 4-...</td>\n",
       "      <td>1</td>\n",
       "      <td>piu` di 250.001</td>\n",
       "      <td>Emilia Romagna</td>\n",
       "      <td>1</td>\n",
       "      <td>settimanale</td>\n",
       "      <td>alcune volte l'anno</td>\n",
       "      <td>piu' raramente</td>\n",
       "      <td>mensile</td>\n",
       "      <td>settimanale</td>\n",
       "      <td>da piu' di un'ora fino a due ore</td>\n",
       "      <td>si ogni giorno</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>maggiore</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>peggiorata</td>\n",
       "      <td>non sa/non risponde</td>\n",
       "      <td>con tranquillita'</td>\n",
       "      <td>una legge buona ma che va cambiata</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>si</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>solo italiano</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>sta regredendo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>piu' svantaggi</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>molto</td>\n",
       "      <td>per niente</td>\n",
       "      <td>bassa</td>\n",
       "      <td>media</td>\n",
       "      <td>bassa</td>\n",
       "      <td>bassa</td>\n",
       "      <td>media</td>\n",
       "      <td>alta</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>ne' d'accordo ne' in disaccordo (NON STIMOLARE)</td>\n",
       "      <td>peggiorata</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>del tutto&lt;BR&gt;in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto in disaccordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>in disaccordo</td>\n",
       "      <td>d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>del tutto d'accordo</td>\n",
       "      <td>molta</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>molta</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>nessuna</td>\n",
       "      <td>nessuna</td>\n",
       "      <td>per niente</td>\n",
       "      <td>pocao</td>\n",
       "      <td>molto</td>\n",
       "      <td>pocao</td>\n",
       "      <td>pocao</td>\n",
       "      <td>per niente</td>\n",
       "      <td>per niente</td>\n",
       "      <td>Nel settore pubblico</td>\n",
       "      <td>per niente</td>\n",
       "      <td>poco</td>\n",
       "      <td>molto</td>\n",
       "      <td>per niente</td>\n",
       "      <td>poco</td>\n",
       "      <td>molto</td>\n",
       "      <td>molto</td>\n",
       "      <td>molto</td>\n",
       "      <td>non saprei</td>\n",
       "      <td>abbastanza</td>\n",
       "      <td>Partito Democratico-PD</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>slight off trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>slight in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>in trend</td>\n",
       "      <td>off trend</td>\n",
       "      <td>in trend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       m_sesso  m_p_r_eta                                      m_p_scolarita  \\\n",
       "31575        1         62  laurea specialistica di II livello o laurea 4-...   \n",
       "31576        1         35                      laurea triennale di I livello   \n",
       "31577        0         50     universita` in corso/nessuna laurea conseguita   \n",
       "31578        1         56      master/scuola di specializzazione post laurea   \n",
       "31579        0         46  laurea specialistica di II livello o laurea 4-...   \n",
       "\n",
       "       m_p_pubblico_privato       m_p_r_ampiezza6     m_istat_reg  \\\n",
       "31575                     1  da 100.001 a 250.000         Toscana   \n",
       "31576                     0   da 30.001 a 100.000       Lombardia   \n",
       "31577                     1  da 100.001 a 250.000        Sardegna   \n",
       "31578                     1     da 5.001 a 10.000         Toscana   \n",
       "31579                     1       piu` di 250.001  Emilia Romagna   \n",
       "\n",
       "       m_p_nascita_in_italia_genitori m_p_frequenza_cinema  \\\n",
       "31575                               1  alcune volte l'anno   \n",
       "31576                               1              mensile   \n",
       "31577                               1                  mai   \n",
       "31578                               1  alcune volte l'anno   \n",
       "31579                               1          settimanale   \n",
       "\n",
       "      m_p_frequenza_teatro m_p_frequenza_concerti m_p_frequenza_mostre  \\\n",
       "31575       piu' raramente         piu' raramente  alcune volte l'anno   \n",
       "31576                  mai         piu' raramente       piu' raramente   \n",
       "31577                  mai                    mai                  mai   \n",
       "31578  alcune volte l'anno         piu' raramente       piu' raramente   \n",
       "31579  alcune volte l'anno         piu' raramente              mensile   \n",
       "\n",
       "      m_p_frequenza_palestra_sport                     m_p_radio_ore  \\\n",
       "31575                          mai  da piu' di un'ora fino a due ore   \n",
       "31576    piu' volte alla settimana                     oltre quattro   \n",
       "31577                          mai                    meno di un'ora   \n",
       "31578                          mai                    meno di un'ora   \n",
       "31579                  settimanale  da piu' di un'ora fino a due ore   \n",
       "\n",
       "               m_p_lettura_quotidiani  \\\n",
       "31575  si alcune volte alla settimana   \n",
       "31576                  si ogni giorno   \n",
       "31577  si alcune volte alla settimana   \n",
       "31578                  si ogni giorno   \n",
       "31579                  si ogni giorno   \n",
       "\n",
       "                            m_ac_valore_attuale_patria  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                              del tutto d'accordo   \n",
       "31578                                        d'accordo   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "      m_ac_privilegio_lavoratori_sett_pubblico  \\\n",
       "31575           ne d'accordo ne' in disaccordo   \n",
       "31576                      del tutto d'accordo   \n",
       "31577                            in disaccordo   \n",
       "31578           ne d'accordo ne' in disaccordo   \n",
       "31579                            in disaccordo   \n",
       "\n",
       "      m_ac_propensioneRischio_italia_vs_europa  \\\n",
       "31575                            in disaccordo   \n",
       "31576                            in disaccordo   \n",
       "31577                  del tutto in disaccordo   \n",
       "31578                                d'accordo   \n",
       "31579                            in disaccordo   \n",
       "\n",
       "                               m_ac_importanza_partiti  \\\n",
       "31575                                        d'accordo   \n",
       "31576                                    in disaccordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                        d'accordo   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "      m_ac_diminuzione_ruolo_partiti  \\\n",
       "31575        del tutto in disaccordo   \n",
       "31576            del tutto d'accordo   \n",
       "31577                  in disaccordo   \n",
       "31578        del tutto in disaccordo   \n",
       "31579                      d'accordo   \n",
       "\n",
       "                     m_ac_affidamento_pubblica_tecnici  \\\n",
       "31575                                    in disaccordo   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                                    in disaccordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "                    m_ac_valori_resistenza_altra_epoca  \\\n",
       "31575                                    in disaccordo   \n",
       "31576                                        d'accordo   \n",
       "31577                                    in disaccordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "      m_ac_sindacato_ancoraUtile  \\\n",
       "31575                  d'accordo   \n",
       "31576              in disaccordo   \n",
       "31577                  d'accordo   \n",
       "31578                  d'accordo   \n",
       "31579              in disaccordo   \n",
       "\n",
       "              m_ac_uguaglianza_sociale_frena_individui  \\\n",
       "31575                                    in disaccordo   \n",
       "31576                                        d'accordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "               m_ac_troppo_focus_uguaglianza_vs_merito  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                                        d'accordo   \n",
       "31577                                    in disaccordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                                        d'accordo   \n",
       "\n",
       "      m_ac_meglio_uguaglianza_vs_merito_singolo  \\\n",
       "31575                   del tutto in disaccordo   \n",
       "31576           ne' d'accordo ne' in disaccordo   \n",
       "31577                                 d'accordo   \n",
       "31578           ne' d'accordo ne' in disaccordo   \n",
       "31579           ne' d'accordo ne' in disaccordo   \n",
       "\n",
       "      m_op_disorientamento_veros_realta_quotidiana  \\\n",
       "31575                                         poco   \n",
       "31576                                         poco   \n",
       "31577                                        molto   \n",
       "31578                                   abbastanza   \n",
       "31579                                   abbastanza   \n",
       "\n",
       "      m_op_disorientamento_realta_quotidiana_vs_3anniFa  \\\n",
       "31575                                          maggiore   \n",
       "31576                                         inferiore   \n",
       "31577                                          maggiore   \n",
       "31578                                            uguale   \n",
       "31579                                          maggiore   \n",
       "\n",
       "              m_ac_vantaggi_globalizz_economie_mercati  \\\n",
       "31575                                        d'accordo   \n",
       "31576                              del tutto d'accordo   \n",
       "31577                                    in disaccordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                                        d'accordo   \n",
       "\n",
       "                           m_ac_globaliz_inarrestabile  \\\n",
       "31575                                        d'accordo   \n",
       "31576                                        d'accordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                        d'accordo   \n",
       "31579                          del tutto in disaccordo   \n",
       "\n",
       "      m_ac_dovere_difesa_produzPaese_vs_globaliz  \\\n",
       "31575                                  d'accordo   \n",
       "31576            ne' d'accordo ne' in disaccordo   \n",
       "31577                        del tutto d'accordo   \n",
       "31578                                  d'accordo   \n",
       "31579                    del tutto in disaccordo   \n",
       "\n",
       "            m_ac_aumento_competizione_con_piuPreparati  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                                    in disaccordo   \n",
       "31578                                        d'accordo   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "                      m_ac_aumento_stress_competizione  \\\n",
       "31575                          del tutto in disaccordo   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                              del tutto d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "      m_ac_percez_inadeguatezza_da_velocitaCambiamento  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                                        d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "                               m_ac_nonSicuro_doveVive  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                              del tutto d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "                  m_ac_repressione_unicaArma_vs_crimin  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                              del tutto d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                                        d'accordo   \n",
       "\n",
       "                   m_ac_crimin_diventera_incontenibile  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                                        d'accordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "      m_op_situazEconomic_propria_ultimi10anni m_op_situazEconomic_futura  \\\n",
       "31575                        rimasta la stessa                 peggiorare   \n",
       "31576                               peggiorata         rimanere la stessa   \n",
       "31577                                      NaN                        NaN   \n",
       "31578                      non sa/non risponde                 peggiorare   \n",
       "31579                               peggiorata        non sa/non risponde   \n",
       "\n",
       "             m_op_come_reddito_consenteDiVivere  \\\n",
       "31575                         con tranquillita'   \n",
       "31576  arrivo a fine mese con molte difficolta'   \n",
       "31577  arrivo a fine mese con molte difficolta'   \n",
       "31578                       avverto difficolta'   \n",
       "31579                         con tranquillita'   \n",
       "\n",
       "                   m_op_legge_aborto_1987 m_ac_validita_insegnamChiesa  \\\n",
       "31575                   una cattiva legge          del tutto d'accordo   \n",
       "31576  una legge buona ma che va cambiata                in disaccordo   \n",
       "31577                     una buona legge                    d'accordo   \n",
       "31578                     una buona legge                    d'accordo   \n",
       "31579  una legge buona ma che va cambiata          del tutto d'accordo   \n",
       "\n",
       "      m_op_favore_eutanasia_a_determinate_condizioni  \\\n",
       "31575                                             no   \n",
       "31576                                             si   \n",
       "31577                       dipende dalle condizioni   \n",
       "31578                                             si   \n",
       "31579                                             si   \n",
       "\n",
       "                     m_ac_societa_troppoPermissiva_gay  \\\n",
       "31575                                        d'accordo   \n",
       "31576                                    in disaccordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                    in disaccordo   \n",
       "31579                                    in disaccordo   \n",
       "\n",
       "                           m_ac_legalizz_drogheLeggere  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                              del tutto d'accordo   \n",
       "31577                                        d'accordo   \n",
       "31578                                        d'accordo   \n",
       "31579                                    in disaccordo   \n",
       "\n",
       "          m_ac_chiesa_nonDovrebbe_condizionare_stato.1  \\\n",
       "31575                                    in disaccordo   \n",
       "31576                              del tutto d'accordo   \n",
       "31577                                    in disaccordo   \n",
       "31578                              del tutto d'accordo   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "      m_ac_testamento_biologico  \\\n",
       "31575   del tutto in disaccordo   \n",
       "31576       del tutto d'accordo   \n",
       "31577                 d'accordo   \n",
       "31578             in disaccordo   \n",
       "31579             in disaccordo   \n",
       "\n",
       "                          m_ac_immigrati_rubano_lavoro  \\\n",
       "31575                                    in disaccordo   \n",
       "31576                                    in disaccordo   \n",
       "31577                              del tutto d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "                                m_ac_immigrati_risorsa  \\\n",
       "31575                                        d'accordo   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                                    in disaccordo   \n",
       "31578                              del tutto d'accordo   \n",
       "31579                                        d'accordo   \n",
       "\n",
       "                    m_ac_immigrati_portano_criminalita  \\\n",
       "31575                                    in disaccordo   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                        d'accordo   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "      m_ac_immigrati_devono_adeguarsi  \\\n",
       "31575                       d'accordo   \n",
       "31576                       d'accordo   \n",
       "31577             del tutto d'accordo   \n",
       "31578                       d'accordo   \n",
       "31579                       d'accordo   \n",
       "\n",
       "                           m_ac_immigrati_diritto_voto  \\\n",
       "31575                                        d'accordo   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                        d'accordo   \n",
       "31579                                        d'accordo   \n",
       "\n",
       "      m_ac_immigrati_nonRispettano_regoleDelloStareInsieme  \\\n",
       "31575                                      in disaccordo     \n",
       "31576                                          d'accordo     \n",
       "31577                                del tutto d'accordo     \n",
       "31578                                         non saprei     \n",
       "31579                                          d'accordo     \n",
       "\n",
       "      m_op_sentimento_italianoVSeuropeo m_ac_modernizzazioneItalia_grazie_UE  \\\n",
       "31575         piu' europeo che italiano                            d'accordo   \n",
       "31576         piu' europeo che italiano                            d'accordo   \n",
       "31577                     solo italiano              del tutto in disaccordo   \n",
       "31578          sia italiano che europeo                           non saprei   \n",
       "31579                     solo italiano                        in disaccordo   \n",
       "\n",
       "               m_ac_giovani di 30anniFa miglioriDiOggi  \\\n",
       "31575                          del tutto in disaccordo   \n",
       "31576                              del tutto d'accordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                          del tutto in disaccordo   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "               m_ac_giovaniOggi_incapaci_fareSacrifici  \\\n",
       "31575                                        d'accordo   \n",
       "31576                              del tutto d'accordo   \n",
       "31577                                        d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "      m_ac_nuoveGenerazioni_miglioreranno_mondo  \\\n",
       "31575                   del tutto in disaccordo   \n",
       "31576                       del tutto d'accordo   \n",
       "31577                                 d'accordo   \n",
       "31578                                 d'accordo   \n",
       "31579                       del tutto d'accordo   \n",
       "\n",
       "      m_ac_impegnoSocialeGiovani_sempreMenoForte  \\\n",
       "31575                                  d'accordo   \n",
       "31576                                  d'accordo   \n",
       "31577                              in disaccordo   \n",
       "31578                              in disaccordo   \n",
       "31579                        del tutto d'accordo   \n",
       "\n",
       "      m_ac_governatori_scegliere_senzaBadareOpposizione  \\\n",
       "31575   ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                               del tutto d'accordo   \n",
       "31577   ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578   ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                                     in disaccordo   \n",
       "\n",
       "                   m_ac_mediazione_nonRisolve_problemi  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                                        d'accordo   \n",
       "31578                                        d'accordo   \n",
       "31579                                    in disaccordo   \n",
       "\n",
       "          m_ac_ricercaCompromesso_faMarcire_situazioni  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                              del tutto d'accordo   \n",
       "31577  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                        d'accordo   \n",
       "31579                                    in disaccordo   \n",
       "\n",
       "               m_ac_religioneIslamica_pericoloPerTutti  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                                    in disaccordo   \n",
       "31577                              del tutto d'accordo   \n",
       "31578                                        d'accordo   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "      m_ac_musulmaniInItalia_dirittoReligione_inScuole  \\\n",
       "31575                                        d'accordo   \n",
       "31576                                    in disaccordo   \n",
       "31577                                    in disaccordo   \n",
       "31578                                        d'accordo   \n",
       "31579  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "      m_ac_italia_troppeConcessioni_immigratiMusulmani  \\\n",
       "31575                                    in disaccordo   \n",
       "31576                                    in disaccordo   \n",
       "31577                              del tutto d'accordo   \n",
       "31578                                    in disaccordo   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "      m_ac_generazioniFuture_vivrannoPeggio m_modernizz_vs_regress_Paese  \\\n",
       "31575                            non saprei         si sta modernizzando   \n",
       "31576                             d'accordo         si sta modernizzando   \n",
       "31577               del tutto in disaccordo               sta regredendo   \n",
       "31578                         in disaccordo         si sta modernizzando   \n",
       "31579                   del tutto d'accordo               sta regredendo   \n",
       "\n",
       "            m_ac_passato_vivereMeglio_ancheSePiuPoveri  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                                        d'accordo   \n",
       "31577                                        d'accordo   \n",
       "31578                              del tutto d'accordo   \n",
       "31579                              del tutto d'accordo   \n",
       "\n",
       "            m_ac_italia_paeseInDeclino             m_op_partecipazione_in_UE  \\\n",
       "31575  ne' d'accordo ne' in disaccordo                         piu' vantaggi   \n",
       "31576              del tutto d'accordo  vantaggi e svantaggi in egual misura   \n",
       "31577              del tutto d'accordo                        piu' svantaggi   \n",
       "31578  ne' d'accordo ne' in disaccordo  vantaggi e svantaggi in egual misura   \n",
       "31579              del tutto d'accordo                        piu' svantaggi   \n",
       "\n",
       "                 m_ac_scienza_problemi_piuChe_benefici  \\\n",
       "31575  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31576                                    in disaccordo   \n",
       "31577                                        d'accordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                                        d'accordo   \n",
       "\n",
       "      m_ac_scoperte_scientificTecnol_rendono_vita_piuFacile  \\\n",
       "31575                                          d'accordo      \n",
       "31576                                del tutto d'accordo      \n",
       "31577                                          d'accordo      \n",
       "31578                                          d'accordo      \n",
       "31579                                          d'accordo      \n",
       "\n",
       "      m_ac_troppo_allarmismo_ecologia_inquinamento  \\\n",
       "31575                                in disaccordo   \n",
       "31576                      del tutto in disaccordo   \n",
       "31577                                in disaccordo   \n",
       "31578                                in disaccordo   \n",
       "31579                      del tutto in disaccordo   \n",
       "\n",
       "      m_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente  \\\n",
       "31575                                      in disaccordo       \n",
       "31576                                      in disaccordo       \n",
       "31577                            del tutto in disaccordo       \n",
       "31578                                      in disaccordo       \n",
       "31579                            del tutto in disaccordo       \n",
       "\n",
       "      m_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo  \\\n",
       "31575                                      in disaccordo        \n",
       "31576                                          d'accordo        \n",
       "31577                                del tutto d'accordo        \n",
       "31578                                          d'accordo        \n",
       "31579                                del tutto d'accordo        \n",
       "\n",
       "      m_op_contributoDelSingolo_salvaguardia_ambiente  \\\n",
       "31575                                           molto   \n",
       "31576                                            poco   \n",
       "31577                                      abbastanza   \n",
       "31578                                      abbastanza   \n",
       "31579                                           molto   \n",
       "\n",
       "      m_op_impegnoPersone_in_tutelaAmbiente  \\\n",
       "31575                                  poco   \n",
       "31576                                  poco   \n",
       "31577                                  poco   \n",
       "31578                                  poco   \n",
       "31579                            per niente   \n",
       "\n",
       "      m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico  \\\n",
       "31575                                              bassa               \n",
       "31576                                              bassa               \n",
       "31577                                               alta               \n",
       "31578                                              media               \n",
       "31579                                              bassa               \n",
       "\n",
       "      m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff  \\\n",
       "31575                                              media               \n",
       "31576                                              media               \n",
       "31577                                              media               \n",
       "31578                                               alta               \n",
       "31579                                              media               \n",
       "\n",
       "      m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative  \\\n",
       "31575                                              bassa                     \n",
       "31576                                              media                     \n",
       "31577                                              bassa                     \n",
       "31578                                              bassa                     \n",
       "31579                                              bassa                     \n",
       "\n",
       "      m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili  \\\n",
       "31575                                              bassa                           \n",
       "31576                                              bassa                           \n",
       "31577                                              media                           \n",
       "31578                                              bassa                           \n",
       "31579                                              bassa                           \n",
       "\n",
       "      m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura  \\\n",
       "31575                                              bassa                       \n",
       "31576                                              bassa                       \n",
       "31577                                              media                       \n",
       "31578                                              media                       \n",
       "31579                                              media                       \n",
       "\n",
       "      m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti  \\\n",
       "31575                                              bassa                               \n",
       "31576                                              bassa                               \n",
       "31577                                               alta                               \n",
       "31578                                              media                               \n",
       "31579                                               alta                               \n",
       "\n",
       "      m_ac_sacrificioEconomico_per_migliorare_ScuolaUniversitaRicerca  \\\n",
       "31575                                del tutto d'accordo                \n",
       "31576    ne' d'accordo ne' in disaccordo (NON STIMOLARE)                \n",
       "31577                                      in disaccordo                \n",
       "31578    ne' d'accordo ne' in disaccordo (NON STIMOLARE)                \n",
       "31579                                          d'accordo                \n",
       "\n",
       "      m_ac_ScuolaEFormazione_principaleProblema_delPaese  \\\n",
       "31575                                          d'accordo   \n",
       "31576    ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577    ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31578                                          d'accordo   \n",
       "31579    ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "\n",
       "      m_op_scuolaPubblica_ultimiAnni  \\\n",
       "31575                 rimasta uguale   \n",
       "31576                     peggiorata   \n",
       "31577                     peggiorata   \n",
       "31578                     peggiorata   \n",
       "31579                     peggiorata   \n",
       "\n",
       "      m_ac_scuola_deveEssere_severa_selettiva_meritocratica  \\\n",
       "31575                                      in disaccordo      \n",
       "31576                                del tutto d'accordo      \n",
       "31577                                      in disaccordo      \n",
       "31578                                      in disaccordo      \n",
       "31579                                del tutto d'accordo      \n",
       "\n",
       "      m_ac_valorizzare_scuoleEccellenza m_ac_difesa_scuolaPubblica_insensata  \\\n",
       "31575                     in disaccordo                        in disaccordo   \n",
       "31576               del tutto d'accordo                 del tutto disaccordo   \n",
       "31577                         d'accordo                 del tutto disaccordo   \n",
       "31578                         d'accordo                 del tutto disaccordo   \n",
       "31579               del tutto d'accordo                  del tutto d'accordo   \n",
       "\n",
       "      m_ac_attuale_classeInsegnante_incompetente  \\\n",
       "31575                                  d'accordo   \n",
       "31576                        del tutto d'accordo   \n",
       "31577                              in disaccordo   \n",
       "31578                                 non saprei   \n",
       "31579                        del tutto d'accordo   \n",
       "\n",
       "      m_ac_sperimentazioniGenetiche_piuRischi_cheVantaggi  \\\n",
       "31575                                del tutto d'accordo    \n",
       "31576    ne' d'accordo ne' in disaccordo (NON STIMOLARE)    \n",
       "31577                                          d'accordo    \n",
       "31578    ne' d'accordo ne' in disaccordo (NON STIMOLARE)    \n",
       "31579                                del tutto d'accordo    \n",
       "\n",
       "      m_ac_problemi_eticiMorali_sperimentazioneGenetica  \\\n",
       "31575                               del tutto d'accordo   \n",
       "31576                                         d'accordo   \n",
       "31577                                         d'accordo   \n",
       "31578                                         d'accordo   \n",
       "31579                                     in disaccordo   \n",
       "\n",
       "      m_ac_nord_unicoMotore_economiaItaliana  \\\n",
       "31575                          in disaccordo   \n",
       "31576                              d'accordo   \n",
       "31577                del tutto in disaccordo   \n",
       "31578                          in disaccordo   \n",
       "31579                          in disaccordo   \n",
       "\n",
       "      m_ac_lavoroNord_consente_diEssere_alPasso_con_UE  \\\n",
       "31575                                    in disaccordo   \n",
       "31576                              del tutto d'accordo   \n",
       "31577                          del tutto in disaccordo   \n",
       "31578                                    in disaccordo   \n",
       "31579                                    in disaccordo   \n",
       "\n",
       "                 m_ac_guerre_talvolta_maleNecessario.1  \\\n",
       "31575                          del tutto in disaccordo   \n",
       "31576  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31577                                    in disaccordo   \n",
       "31578  ne' d'accordo ne' in disaccordo (NON STIMOLARE)   \n",
       "31579                                    in disaccordo   \n",
       "\n",
       "      m_ac_italia_ipartecipazioneIn_missioniMilitariEstere  \\\n",
       "31575                                          d'accordo     \n",
       "31576                                          d'accordo     \n",
       "31577                         del tutto<BR>in disaccordo     \n",
       "31578                             del tutto<BR>d'accordo     \n",
       "31579                         del tutto<BR>in disaccordo     \n",
       "\n",
       "      m_ac_lavorare_importante_postoStabile_no m_op_rinuncie_per_postoStabile  \\\n",
       "31575                preferisco non rispondere                      d'accordo   \n",
       "31576                            in disaccordo                  in disaccordo   \n",
       "31577                  del tutto in disaccordo        del tutto in disaccordo   \n",
       "31578                                d'accordo                      d'accordo   \n",
       "31579                            in disaccordo                  in disaccordo   \n",
       "\n",
       "      m_ac_badare_propriInteressi_perSopravvivere  \\\n",
       "31575                     del tutto in disaccordo   \n",
       "31576                               in disaccordo   \n",
       "31577                               in disaccordo   \n",
       "31578                               in disaccordo   \n",
       "31579                               in disaccordo   \n",
       "\n",
       "      m_ac_sentirsiSpesso_solo_isolato  \\\n",
       "31575                        d'accordo   \n",
       "31576          del tutto in disaccordo   \n",
       "31577                        d'accordo   \n",
       "31578                    in disaccordo   \n",
       "31579                        d'accordo   \n",
       "\n",
       "      m_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti  \\\n",
       "31575                            del tutto in disaccordo                  \n",
       "31576                                          d'accordo                  \n",
       "31577                                      in disaccordo                  \n",
       "31578                                      in disaccordo                  \n",
       "31579                            del tutto in disaccordo                  \n",
       "\n",
       "      m_ac_modelloImprenditorialePrivato_unico_meritocratico  \\\n",
       "31575                            del tutto in disaccordo       \n",
       "31576                                          d'accordo       \n",
       "31577                            del tutto in disaccordo       \n",
       "31578                                      in disaccordo       \n",
       "31579                            del tutto in disaccordo       \n",
       "\n",
       "      m_ac_modelloImprenditorialePrivato_unico_garantireEquita  \\\n",
       "31575                            del tutto in disaccordo         \n",
       "31576                                      in disaccordo         \n",
       "31577                            del tutto in disaccordo         \n",
       "31578                                      in disaccordo         \n",
       "31579                            del tutto in disaccordo         \n",
       "\n",
       "      m_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale  \\\n",
       "31575                                      in disaccordo                    \n",
       "31576                                del tutto d'accordo                    \n",
       "31577                                          d'accordo                    \n",
       "31578                                          d'accordo                    \n",
       "31579                                del tutto d'accordo                    \n",
       "\n",
       "      m_ac_dazi_su_produzioni_importanti  \\\n",
       "31575                      in disaccordo   \n",
       "31576                      in disaccordo   \n",
       "31577                del tutto d'accordo   \n",
       "31578                      in disaccordo   \n",
       "31579                del tutto d'accordo   \n",
       "\n",
       "      m_ac_comprareItaliano_perFronteggiare_crisi  \\\n",
       "31575                                  non saprei   \n",
       "31576                               in disaccordo   \n",
       "31577                         del tutto d'accordo   \n",
       "31578                                   d'accordo   \n",
       "31579                         del tutto d'accordo   \n",
       "\n",
       "      m_ac_generazionePrecedente_piuFelice  \\\n",
       "31575                            d'accordo   \n",
       "31576                            d'accordo   \n",
       "31577                            d'accordo   \n",
       "31578                            d'accordo   \n",
       "31579                  del tutto d'accordo   \n",
       "\n",
       "      m_ac_generazionePrecedente_migliore_qualitaVita  \\\n",
       "31575                                       d'accordo   \n",
       "31576                                   in disaccordo   \n",
       "31577                                       d'accordo   \n",
       "31578                                   in disaccordo   \n",
       "31579                                   in disaccordo   \n",
       "\n",
       "      m_ac_generazionePrecedente_maggiore_sicurezzaLavorativa  \\\n",
       "31575                                          d'accordo        \n",
       "31576                                          d'accordo        \n",
       "31577                                del tutto d'accordo        \n",
       "31578                                          d'accordo        \n",
       "31579                                          d'accordo        \n",
       "\n",
       "      m_ac_generazionePrecedente_maggiore_mobilitaEconomicoSociale  \\\n",
       "31575                                          d'accordo             \n",
       "31576                                          d'accordo             \n",
       "31577                                del tutto d'accordo             \n",
       "31578                                del tutto d'accordo             \n",
       "31579                                del tutto d'accordo             \n",
       "\n",
       "      m_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa  \\\n",
       "31575                                      in disaccordo    \n",
       "31576                                del tutto d'accordo    \n",
       "31577                                          d'accordo    \n",
       "31578                                      in disaccordo    \n",
       "31579                                del tutto d'accordo    \n",
       "\n",
       "      m_op_fiducia_negli italiani  \\\n",
       "31575                  abbastanza   \n",
       "31576                  poca&nbsp;   \n",
       "31577                  abbastanza   \n",
       "31578                  abbastanza   \n",
       "31579                       molta   \n",
       "\n",
       "      m_op_fiducia_negli amici che fanno parte della sua rete social network  \\\n",
       "31575                                         non saprei                       \n",
       "31576                                         abbastanza                       \n",
       "31577                                         abbastanza                       \n",
       "31578                                         abbastanza                       \n",
       "31579                                         abbastanza                       \n",
       "\n",
       "      m_op_fiducia_nei familiari con cui convive  \\\n",
       "31575                                      molta   \n",
       "31576                                      molta   \n",
       "31577                                      molta   \n",
       "31578                                      molta   \n",
       "31579                                      molta   \n",
       "\n",
       "      m_op_fiducia_nei suoi parenti  \\\n",
       "31575                    abbastanza   \n",
       "31576                         molta   \n",
       "31577                         molta   \n",
       "31578                    abbastanza   \n",
       "31579                    abbastanza   \n",
       "\n",
       "      m_op_fiducia_negli amici e conoscenti dei suoi familiari  \\\n",
       "31575                                         abbastanza         \n",
       "31576                                         poca&nbsp;         \n",
       "31577                                         poca&nbsp;         \n",
       "31578                                         poca&nbsp;         \n",
       "31579                                         abbastanza         \n",
       "\n",
       "      m_op_fiducia_nei colleghi di lavoro m_op_fiducia_nei vicini di casa  \\\n",
       "31575                          poca&nbsp;                      non saprei   \n",
       "31576                          abbastanza                         nessuna   \n",
       "31577                          poca&nbsp;                      poca&nbsp;   \n",
       "31578                          poca&nbsp;                      poca&nbsp;   \n",
       "31579                             nessuna                         nessuna   \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_degli italiani  \\\n",
       "31575                                              pocao   \n",
       "31576                                              pocao   \n",
       "31577                                              pocao   \n",
       "31578                                         abbastanza   \n",
       "31579                                         per niente   \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_degli amici che fanno parte della sua rete social network  \\\n",
       "31575                                         non saprei                                              \n",
       "31576                                         abbastanza                                              \n",
       "31577                                         abbastanza                                              \n",
       "31578                                              pocao                                              \n",
       "31579                                              pocao                                              \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_dei familiari con cui convive  \\\n",
       "31575                                              molto                  \n",
       "31576                                              molto                  \n",
       "31577                                              molto                  \n",
       "31578                                         abbastanza                  \n",
       "31579                                              molto                  \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_dei suoi parenti  \\\n",
       "31575                                         abbastanza     \n",
       "31576                                              molto     \n",
       "31577                                         abbastanza     \n",
       "31578                                              pocao     \n",
       "31579                                              pocao     \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_degli amici e conoscenti dei suoi familiari  \\\n",
       "31575                                              pocao                                \n",
       "31576                                         per niente                                \n",
       "31577                                              pocao                                \n",
       "31578                                              pocao                                \n",
       "31579                                              pocao                                \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_dei colleghi di lavoro  \\\n",
       "31575                                              pocao           \n",
       "31576                                              pocao           \n",
       "31577                                              pocao           \n",
       "31578                                         abbastanza           \n",
       "31579                                         per niente           \n",
       "\n",
       "      m_op_aiutoReciproco_inCasoDiBisogno_dei vicini di casa  \\\n",
       "31575                                         non saprei       \n",
       "31576                                         per niente       \n",
       "31577                                              pocao       \n",
       "31578                                              pocao       \n",
       "31579                                         per niente       \n",
       "\n",
       "      m_op_preferenza_lavorativa m_op_ottica_di_beneComune_italia  \\\n",
       "31575       Nel settore pubblico                             poco   \n",
       "31576      Libero professionista                       per niente   \n",
       "31577       Nel settore pubblico                       per niente   \n",
       "31578       Nel settore pubblico                             poco   \n",
       "31579       Nel settore pubblico                       per niente   \n",
       "\n",
       "      m_op_ottica_di_beneComune_comuneResidenza  \\\n",
       "31575                                      poco   \n",
       "31576                                      poco   \n",
       "31577                                per niente   \n",
       "31578                                      poco   \n",
       "31579                                      poco   \n",
       "\n",
       "      m_op_importanza_farParte_comunita m_op_sviluppo_sensoCivico_Paese  \\\n",
       "31575                             molto                            poco   \n",
       "31576                        per niente                      per niente   \n",
       "31577                             molto                      per niente   \n",
       "31578                             molto                            poco   \n",
       "31579                             molto                      per niente   \n",
       "\n",
       "      m_op_attività_associazionismo_Italia  \\\n",
       "31575                           abbastanza   \n",
       "31576                           abbastanza   \n",
       "31577                           abbastanza   \n",
       "31578                                molto   \n",
       "31579                                 poco   \n",
       "\n",
       "      m_op_importanza_nellaSocieta_solidarieta  \\\n",
       "31575                               abbastanza   \n",
       "31576                               abbastanza   \n",
       "31577                               abbastanza   \n",
       "31578                                    molto   \n",
       "31579                                    molto   \n",
       "\n",
       "      m_op_importanza_nellaSocieta_altruismo  \\\n",
       "31575                             abbastanza   \n",
       "31576                             abbastanza   \n",
       "31577                             abbastanza   \n",
       "31578                                   poco   \n",
       "31579                                  molto   \n",
       "\n",
       "      m_op_importanza_nellaSocieta_mutualismo m_op_danni_populismo_in_italia  \\\n",
       "31575                                    poco                    molti danni   \n",
       "31576                              abbastanza                   nessun danno   \n",
       "31577                              abbastanza                   nessun danno   \n",
       "31578                                    poco                  qualche danno   \n",
       "31579                                   molto                     non saprei   \n",
       "\n",
       "      m_op_peso_volontariato_in_economiaPaese  \\\n",
       "31575                                   molto   \n",
       "31576                                    poco   \n",
       "31577                              abbastanza   \n",
       "31578                                   molto   \n",
       "31579                              abbastanza   \n",
       "\n",
       "                          m_p_int_voto  \\\n",
       "31575           Partito Democratico-PD   \n",
       "31576               MoVimento 5 Stelle   \n",
       "31577                    sono indeciso   \n",
       "31578  Sinistra italiana (SEL + altri)   \n",
       "31579           Partito Democratico-PD   \n",
       "\n",
       "      m_TREND_1_PATRIA E UNITA' NAZIONALE (credono ancora nellla patria)  \\\n",
       "31575                                          off trend                   \n",
       "31576                                          off trend                   \n",
       "31577                                           in trend                   \n",
       "31578                                           in trend                   \n",
       "31579                                           in trend                   \n",
       "\n",
       "      m_TREND_7_SFIDUCIA NEL SISTEMA DEI PARTI  \\\n",
       "31575                                off trend   \n",
       "31576                                 in trend   \n",
       "31577                                off trend   \n",
       "31578                         slight off trend   \n",
       "31579                                 in trend   \n",
       "\n",
       "      m_TREND_8_VALORI FONDATIVI (mantiene radicati i valori)  \\\n",
       "31575                                           in trend        \n",
       "31576                                   slight off trend        \n",
       "31577                                           in trend        \n",
       "31578                                           in trend        \n",
       "31579                                   slight off trend        \n",
       "\n",
       "      m_TREND_10_MERITO (propende per la meritocrazia)  \\\n",
       "31575                                        off trend   \n",
       "31576                                         in trend   \n",
       "31577                                        off trend   \n",
       "31578                                        off trend   \n",
       "31579                                         in trend   \n",
       "\n",
       "      m_TREND_15_INADEGUATEZZA INDIVIDUALE  \\\n",
       "31575                            off trend   \n",
       "31576                            off trend   \n",
       "31577                      slight in trend   \n",
       "31578                     slight off trend   \n",
       "31579                            off trend   \n",
       "\n",
       "      m_TREND_19_SICUREZZA - CRIMINALITA' (si sente al sicuro)  \\\n",
       "31575                                    slight in trend         \n",
       "31576                                    slight in trend         \n",
       "31577                                          off trend         \n",
       "31578                                    slight in trend         \n",
       "31579                                          off trend         \n",
       "\n",
       "      m_TREND_25_IMMIGRAZIONE (atteggiamento POSITIVO nei confronti degli immigrati)  \\\n",
       "31575                                           in trend                               \n",
       "31576                                   slight off trend                               \n",
       "31577                                          off trend                               \n",
       "31578                                    slight in trend                               \n",
       "31579                                    slight in trend                               \n",
       "\n",
       "      m_TREND_26_NAZIONE EUROPA  \\\n",
       "31575                  in trend   \n",
       "31576                  in trend   \n",
       "31577                 off trend   \n",
       "31578           slight in trend   \n",
       "31579          slight off trend   \n",
       "\n",
       "      m_TREND_27_SINDACATO (crede ancora nel modello sindacale)  \\\n",
       "31575                                   slight off trend          \n",
       "31576                                          off trend          \n",
       "31577                                   slight off trend          \n",
       "31578                                           in trend          \n",
       "31579                                          off trend          \n",
       "\n",
       "      m_TREND_28_GIOVANI (fiducia alle nuove generazioni)  \\\n",
       "31575                                   non classificati    \n",
       "31576                                   slight off trend    \n",
       "31577                                    slight in trend    \n",
       "31578                                    slight in trend    \n",
       "31579                                   slight off trend    \n",
       "\n",
       "      m_TREND_29_RADICALIZZAZIONE (crede nel compromesso)  \\\n",
       "31575                                          off trend    \n",
       "31576                                           in trend    \n",
       "31577                                   slight off trend    \n",
       "31578                                    slight in trend    \n",
       "31579                                          off trend    \n",
       "\n",
       "      m_TREND_30_ISLAM (tolleranza e fiducia nei confronti dell Islam)  \\\n",
       "31575                                           in trend                 \n",
       "31576                                           in trend                 \n",
       "31577                                          off trend                 \n",
       "31578                                   slight off trend                 \n",
       "31579                                          off trend                 \n",
       "\n",
       "      m_TREND_31_EPOCALITA' E FUTURO SMARRITO (nostalgico nei confronti del passato)  \\\n",
       "31575                                          off trend                               \n",
       "31576                                   slight off trend                               \n",
       "31577                                    slight in trend                               \n",
       "31578                                   slight off trend                               \n",
       "31579                                           in trend                               \n",
       "\n",
       "      m_TREND_35_EUROPA E MODERNITA' (crede che l'entrata in Europa abbia modernizzato il nostro paese)  \\\n",
       "31575                                           in trend                                                  \n",
       "31576                                           in trend                                                  \n",
       "31577                                          off trend                                                  \n",
       "31578                                           in trend                                                  \n",
       "31579                                          off trend                                                  \n",
       "\n",
       "      m_TREND_37_SCIENZA FECONDA (crede nelle potenzialita' dell'innovazione scientifica)  \\\n",
       "31575                                    slight in trend                                    \n",
       "31576                                           in trend                                    \n",
       "31577                                   slight off trend                                    \n",
       "31578                                    slight in trend                                    \n",
       "31579                                   slight off trend                                    \n",
       "\n",
       "      m_TREND_39_SCUOLA E FORMAZIONE (formazione e' una priorita' del Paese)  \\\n",
       "31575                                           in trend                       \n",
       "31576                                          off trend                       \n",
       "31577                                          off trend                       \n",
       "31578                                   slight off trend                       \n",
       "31579                                   slight off trend                       \n",
       "\n",
       "      m_TREND_46_SPERIMENTAZIONE GENETICA  \\\n",
       "31575                           off trend   \n",
       "31576                    slight off trend   \n",
       "31577                           off trend   \n",
       "31578                    slight off trend   \n",
       "31579                           off trend   \n",
       "\n",
       "      m_TREND_53_INCLUSI ED ESCLUSI (si sente pienamente parte della societa)  \\\n",
       "31575                                    slight in trend                        \n",
       "31576                                          off trend                        \n",
       "31577                                   slight off trend                        \n",
       "31578                                           in trend                        \n",
       "31579                                    slight in trend                        \n",
       "\n",
       "      m_TREND_50_IL MODELLO IMPRESA (individua nell'impresa modello economico vincente)  \\\n",
       "31575                                          off trend                                  \n",
       "31576                                    slight in trend                                  \n",
       "31577                                          off trend                                  \n",
       "31578                                          off trend                                  \n",
       "31579                                          off trend                                  \n",
       "\n",
       "      m_TREND_56_TERRITORIALITA' (2009) (individua nella difesa della territorialita' l'arma vicente)  \\\n",
       "31575                                          off trend                                                \n",
       "31576                                   slight off trend                                                \n",
       "31577                                    slight in trend                                                \n",
       "31578                                   slight off trend                                                \n",
       "31579                                           in trend                                                \n",
       "\n",
       "      m_TREND_58_CONFRONTO CON LA GENERAZIONE PASSATA m_TREND_52_SOLIDARIETA'  \\\n",
       "31575                                        in trend         slight in trend   \n",
       "31576                                 slight in trend                in trend   \n",
       "31577                                        in trend                in trend   \n",
       "31578                                 slight in trend        slight off trend   \n",
       "31579                                        in trend                in trend   \n",
       "\n",
       "      m_TREND_53_IL PERICOLO POPULISTA m_TREND_54_DISORIENTAMENTO  \n",
       "31575                         in trend            slight in trend  \n",
       "31576                 slight off trend                  off trend  \n",
       "31577                  slight in trend                   in trend  \n",
       "31578                         in trend            slight in trend  \n",
       "31579                        off trend                   in trend  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4504, 160)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_sesso                                                                                                0\n",
       "m_p_r_eta                                                                                              0\n",
       "m_p_scolarita                                                                                          0\n",
       "m_p_pubblico_privato                                                                                   0\n",
       "m_p_r_ampiezza6                                                                                        0\n",
       "m_istat_reg                                                                                            0\n",
       "m_p_nascita_in_italia_genitori                                                                         0\n",
       "m_p_frequenza_cinema                                                                                   0\n",
       "m_p_frequenza_teatro                                                                                   0\n",
       "m_p_frequenza_concerti                                                                                 0\n",
       "m_p_frequenza_mostre                                                                                   0\n",
       "m_p_frequenza_palestra_sport                                                                           0\n",
       "m_p_radio_ore                                                                                          0\n",
       "m_p_lettura_quotidiani                                                                                 0\n",
       "m_ac_valore_attuale_patria                                                                           149\n",
       "m_ac_privilegio_lavoratori_sett_pubblico                                                             149\n",
       "m_ac_propensioneRischio_italia_vs_europa                                                             149\n",
       "m_ac_importanza_partiti                                                                              149\n",
       "m_ac_diminuzione_ruolo_partiti                                                                       149\n",
       "m_ac_affidamento_pubblica_tecnici                                                                    149\n",
       "m_ac_valori_resistenza_altra_epoca                                                                   149\n",
       "m_ac_sindacato_ancoraUtile                                                                           150\n",
       "m_ac_uguaglianza_sociale_frena_individui                                                             151\n",
       "m_ac_troppo_focus_uguaglianza_vs_merito                                                              151\n",
       "m_ac_meglio_uguaglianza_vs_merito_singolo                                                            151\n",
       "m_op_disorientamento_veros_realta_quotidiana                                                         151\n",
       "m_op_disorientamento_realta_quotidiana_vs_3anniFa                                                    151\n",
       "m_ac_vantaggi_globalizz_economie_mercati                                                             151\n",
       "m_ac_globaliz_inarrestabile                                                                          151\n",
       "m_ac_dovere_difesa_produzPaese_vs_globaliz                                                           151\n",
       "m_ac_aumento_competizione_con_piuPreparati                                                           151\n",
       "m_ac_aumento_stress_competizione                                                                     151\n",
       "m_ac_percez_inadeguatezza_da_velocitaCambiamento                                                     151\n",
       "m_ac_nonSicuro_doveVive                                                                              151\n",
       "m_ac_repressione_unicaArma_vs_crimin                                                                 151\n",
       "m_ac_crimin_diventera_incontenibile                                                                  151\n",
       "m_op_situazEconomic_propria_ultimi10anni                                                             689\n",
       "m_op_situazEconomic_futura                                                                           668\n",
       "m_op_come_reddito_consenteDiVivere                                                                   177\n",
       "m_op_legge_aborto_1987                                                                               177\n",
       "m_ac_validita_insegnamChiesa                                                                         177\n",
       "m_op_favore_eutanasia_a_determinate_condizioni                                                       177\n",
       "m_ac_societa_troppoPermissiva_gay                                                                    178\n",
       "m_ac_legalizz_drogheLeggere                                                                          178\n",
       "m_ac_chiesa_nonDovrebbe_condizionare_stato.1                                                         178\n",
       "m_ac_testamento_biologico                                                                            178\n",
       "m_ac_immigrati_rubano_lavoro                                                                         178\n",
       "m_ac_immigrati_risorsa                                                                               178\n",
       "m_ac_immigrati_portano_criminalita                                                                   178\n",
       "m_ac_immigrati_devono_adeguarsi                                                                      178\n",
       "m_ac_immigrati_diritto_voto                                                                          178\n",
       "m_ac_immigrati_nonRispettano_regoleDelloStareInsieme                                                 178\n",
       "m_op_sentimento_italianoVSeuropeo                                                                    178\n",
       "m_ac_modernizzazioneItalia_grazie_UE                                                                 178\n",
       "m_ac_giovani di 30anniFa miglioriDiOggi                                                              178\n",
       "m_ac_giovaniOggi_incapaci_fareSacrifici                                                              178\n",
       "m_ac_nuoveGenerazioni_miglioreranno_mondo                                                            178\n",
       "m_ac_impegnoSocialeGiovani_sempreMenoForte                                                           178\n",
       "m_ac_governatori_scegliere_senzaBadareOpposizione                                                    178\n",
       "m_ac_mediazione_nonRisolve_problemi                                                                  178\n",
       "m_ac_ricercaCompromesso_faMarcire_situazioni                                                         178\n",
       "m_ac_religioneIslamica_pericoloPerTutti                                                              178\n",
       "m_ac_musulmaniInItalia_dirittoReligione_inScuole                                                     178\n",
       "m_ac_italia_troppeConcessioni_immigratiMusulmani                                                     178\n",
       "m_ac_generazioniFuture_vivrannoPeggio                                                                178\n",
       "m_modernizz_vs_regress_Paese                                                                         178\n",
       "m_ac_passato_vivereMeglio_ancheSePiuPoveri                                                           178\n",
       "m_ac_italia_paeseInDeclino                                                                           178\n",
       "m_op_partecipazione_in_UE                                                                            178\n",
       "m_ac_scienza_problemi_piuChe_benefici                                                                178\n",
       "m_ac_scoperte_scientificTecnol_rendono_vita_piuFacile                                                178\n",
       "m_ac_troppo_allarmismo_ecologia_inquinamento                                                         178\n",
       "m_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente                                               178\n",
       "m_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo                                              178\n",
       "m_op_contributoDelSingolo_salvaguardia_ambiente                                                      178\n",
       "m_op_impegnoPersone_in_tutelaAmbiente                                                                178\n",
       "m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico                                       178\n",
       "m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff                                       178\n",
       "m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative                                 178\n",
       "m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili                           178\n",
       "m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura                               178\n",
       "m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti                       178\n",
       "m_ac_sacrificioEconomico_per_migliorare_ScuolaUniversitaRicerca                                      178\n",
       "m_ac_ScuolaEFormazione_principaleProblema_delPaese                                                   178\n",
       "m_op_scuolaPubblica_ultimiAnni                                                                       178\n",
       "m_ac_scuola_deveEssere_severa_selettiva_meritocratica                                                178\n",
       "m_ac_valorizzare_scuoleEccellenza                                                                    178\n",
       "m_ac_difesa_scuolaPubblica_insensata                                                                 178\n",
       "m_ac_attuale_classeInsegnante_incompetente                                                           178\n",
       "m_ac_sperimentazioniGenetiche_piuRischi_cheVantaggi                                                  170\n",
       "m_ac_problemi_eticiMorali_sperimentazioneGenetica                                                    170\n",
       "m_ac_nord_unicoMotore_economiaItaliana                                                               170\n",
       "m_ac_lavoroNord_consente_diEssere_alPasso_con_UE                                                     170\n",
       "m_ac_guerre_talvolta_maleNecessario.1                                                                170\n",
       "m_ac_italia_ipartecipazioneIn_missioniMilitariEstere                                                 170\n",
       "m_ac_lavorare_importante_postoStabile_no                                                             170\n",
       "m_op_rinuncie_per_postoStabile                                                                       170\n",
       "m_ac_badare_propriInteressi_perSopravvivere                                                          171\n",
       "m_ac_sentirsiSpesso_solo_isolato                                                                     173\n",
       "m_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti                                    173\n",
       "m_ac_modelloImprenditorialePrivato_unico_meritocratico                                               173\n",
       "m_ac_modelloImprenditorialePrivato_unico_garantireEquita                                             173\n",
       "m_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale                                  173\n",
       "m_ac_dazi_su_produzioni_importanti                                                                   173\n",
       "m_ac_comprareItaliano_perFronteggiare_crisi                                                          173\n",
       "m_ac_generazionePrecedente_piuFelice                                                                 173\n",
       "m_ac_generazionePrecedente_migliore_qualitaVita                                                      173\n",
       "m_ac_generazionePrecedente_maggiore_sicurezzaLavorativa                                              173\n",
       "m_ac_generazionePrecedente_maggiore_mobilitaEconomicoSociale                                         173\n",
       "m_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa                                                  177\n",
       "m_op_fiducia_negli italiani                                                                          178\n",
       "m_op_fiducia_negli amici che fanno parte della sua rete social network                               178\n",
       "m_op_fiducia_nei familiari con cui convive                                                           178\n",
       "m_op_fiducia_nei suoi parenti                                                                        178\n",
       "m_op_fiducia_negli amici e conoscenti dei suoi familiari                                             178\n",
       "m_op_fiducia_nei colleghi di lavoro                                                                  178\n",
       "m_op_fiducia_nei vicini di casa                                                                      178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_degli italiani                                                   178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_degli amici che fanno parte della sua rete social network        178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_dei familiari con cui convive                                    178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_dei suoi parenti                                                 178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_degli amici e conoscenti dei suoi familiari                      178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_dei colleghi di lavoro                                           178\n",
       "m_op_aiutoReciproco_inCasoDiBisogno_dei vicini di casa                                               178\n",
       "m_op_preferenza_lavorativa                                                                           144\n",
       "m_op_ottica_di_beneComune_italia                                                                     144\n",
       "m_op_ottica_di_beneComune_comuneResidenza                                                            144\n",
       "m_op_importanza_farParte_comunita                                                                    145\n",
       "m_op_sviluppo_sensoCivico_Paese                                                                      146\n",
       "m_op_attività_associazionismo_Italia                                                                 146\n",
       "m_op_importanza_nellaSocieta_solidarieta                                                             147\n",
       "m_op_importanza_nellaSocieta_altruismo                                                               147\n",
       "m_op_importanza_nellaSocieta_mutualismo                                                              147\n",
       "m_op_danni_populismo_in_italia                                                                       147\n",
       "m_op_peso_volontariato_in_economiaPaese                                                              152\n",
       "m_p_int_voto                                                                                           0\n",
       "m_TREND_1_PATRIA E UNITA' NAZIONALE (credono ancora nellla patria)                                   149\n",
       "m_TREND_7_SFIDUCIA NEL SISTEMA DEI PARTI                                                             149\n",
       "m_TREND_8_VALORI FONDATIVI (mantiene radicati i valori)                                              150\n",
       "m_TREND_10_MERITO (propende per la meritocrazia)                                                     151\n",
       "m_TREND_15_INADEGUATEZZA INDIVIDUALE                                                                 151\n",
       "m_TREND_19_SICUREZZA - CRIMINALITA' (si sente al sicuro)                                             151\n",
       "m_TREND_25_IMMIGRAZIONE (atteggiamento POSITIVO nei confronti degli immigrati)                       178\n",
       "m_TREND_26_NAZIONE EUROPA                                                                            178\n",
       "m_TREND_27_SINDACATO (crede ancora nel modello sindacale)                                            245\n",
       "m_TREND_28_GIOVANI (fiducia alle nuove generazioni)                                                  178\n",
       "m_TREND_29_RADICALIZZAZIONE (crede nel compromesso)                                                  178\n",
       "m_TREND_30_ISLAM (tolleranza e fiducia nei confronti dell Islam)                                     178\n",
       "m_TREND_31_EPOCALITA' E FUTURO SMARRITO (nostalgico nei confronti del passato)                       178\n",
       "m_TREND_35_EUROPA E MODERNITA' (crede che l'entrata in Europa abbia modernizzato il nostro paese)    178\n",
       "m_TREND_37_SCIENZA FECONDA (crede nelle potenzialita' dell'innovazione scientifica)                  178\n",
       "m_TREND_39_SCUOLA E FORMAZIONE (formazione e' una priorita' del Paese)                               178\n",
       "m_TREND_46_SPERIMENTAZIONE GENETICA                                                                  170\n",
       "m_TREND_53_INCLUSI ED ESCLUSI (si sente pienamente parte della societa)                              172\n",
       "m_TREND_50_IL MODELLO IMPRESA (individua nell'impresa modello economico vincente)                    173\n",
       "m_TREND_56_TERRITORIALITA' (2009) (individua nella difesa della territorialita' l'arma vicente)      173\n",
       "m_TREND_58_CONFRONTO CON LA GENERAZIONE PASSATA                                                      173\n",
       "m_TREND_52_SOLIDARIETA'                                                                              147\n",
       "m_TREND_53_IL PERICOLO POPULISTA                                                                     147\n",
       "m_TREND_54_DISORIENTAMENTO                                                                           151\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_p_int_voto\n",
       "sono indeciso                                                     695\n",
       "Partito Democratico-PD                                            608\n",
       "MoVimento 5 Stelle                                                580\n",
       "Partito Democratico                                               364\n",
       "Lega con Salvini                                                  299\n",
       "Movimento 5 stelle                                                289\n",
       "Lega                                                              244\n",
       "Forza Italia                                                      214\n",
       "Lega Nord                                                         173\n",
       "non andrei a votare                                               157\n",
       "preferisco non rispondere                                         150\n",
       "Fratelli d'Italia                                                 112\n",
       "voterei  scheda bianca / annullerei la scheda                      85\n",
       "Sinistra italiana (SEL + altri)                                    67\n",
       "Altro partito                                                      62\n",
       "Liberi e Uguali                                                    56\n",
       "La Sinistra                                                        54\n",
       "Fratelli d'Italia-Alleanza Nazionale&nbsp;                         44\n",
       "+Europa                                                            44\n",
       "piu' Europa con Emma Bonino                                        42\n",
       "Potere al Popolo                                                   39\n",
       "voterei scheda bianca / scheda nulla                               32\n",
       "Verdi                                                              30\n",
       "Rifondazione Comunista                                             26\n",
       "Italia dei Valori                                                   9\n",
       "Noi con l'Italia UDC&nbsp;                                          8\n",
       "Nuovo Centro Destra con UDC e PPI                                   8\n",
       "Scelta Civica&nbsp;                                                 7\n",
       "altro partito di area di governo (SVP, Centro Democratico....)      4\n",
       "Italia Unica di Corrado Passera                                     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['m_p_int_voto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_int_voto_deep = {\"Partito Democratico-PD\":'PD',\n",
    "                \"Partito Democratico\":'PD',\n",
    "                \"Lega con Salvini\":'Lega',\n",
    "                \"Lega Nord\":'Lega',\n",
    "                \"Lega\":'Lega',\n",
    "                \"Forza Italia\":'Centro Dx',\n",
    "                \"Fratelli d'Italia\":\"Centro Dx\",\n",
    "                'MoVimento 5 Stelle':'M5S',\n",
    "                'Movimento 5 stelle':'M5S',\n",
    "                'voterei  scheda bianca / annullerei la scheda':'astensione/bianca/nulla',\n",
    "                'voterei scheda bianca / scheda nulla':'astensione/bianca/nulla',\n",
    "                \"+Europa\":'Minoranze Sx/CSx',\n",
    "                \"piu' Europa con Emma Bonino\": \"Minoranze Sx/CSx\",\n",
    "                'Sinistra italiana (SEL + altri)':'Minoranze Sx/CSx',\n",
    "                'Potere al Popolo':'Minoranze Sx/CSx',\n",
    "                'Rifondazione Comunista':'Minoranze Sx/CSx',\n",
    "                \"Fratelli d'Italia-Alleanza Nazionale&nbsp;\":\"Centro Dx\",\n",
    "                'La Sinistra':'Minoranze Sx/CSx',\n",
    "                'Verdi':'Minoranze Sx/CSx',\n",
    "                'non andrei a votare':'astensione/bianca/nulla',\n",
    "                'sono indeciso' : 'indecisi',\n",
    "                'Liberi e Uguali' : 'Minoranze Sx/CSx',\n",
    "                'Italia dei Valori' : 'Minoranze Sx/CSx',\n",
    "                'Scelta Civica&nbsp;' : 'Minoranze Sx/CSx',\n",
    "                'Italia Unica di Corrado Passera' : 'Minoranze Sx/CSx',\n",
    "                \"Noi con l'Italia UDC&nbsp;\" : 'Altro partito',\n",
    "                \"altro partito di area di governo (SVP, Centro Democratico....)\" : 'Altro partito',\n",
    "                \"Nuovo Centro Destra con UDC e PPI\" : 'Centro Dx'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_int_voto = {\"Partito Democratico-PD\":'Sx/CSx',\n",
    "                \"Partito Democratico\":'Sx/CSx',\n",
    "                \"Lega con Salvini\":'Dx/CDx',\n",
    "                \"Lega Nord\":'Dx/CDx',\n",
    "                \"Lega\":'Dx/CDx',\n",
    "                \"Forza Italia\":'Dx/CDx',\n",
    "                \"Fratelli d'Italia\":\"Dx/CDx\",\n",
    "                'MoVimento 5 Stelle':'M5S',\n",
    "                'Movimento 5 stelle':'M5S',\n",
    "                'voterei  scheda bianca / annullerei la scheda':'astensione/indecisi',\n",
    "                'voterei scheda bianca / scheda nulla':'astensione/indecisi',\n",
    "                \"+Europa\":'Sx/CSx',\n",
    "                \"piu' Europa con Emma Bonino\": \"Sx/CSx\",\n",
    "                'Sinistra italiana (SEL + altri)':'Sx/CSx',\n",
    "                'Potere al Popolo':'Sx/CSx',\n",
    "                'Rifondazione Comunista':'Sx/CSx',\n",
    "                \"Fratelli d'Italia-Alleanza Nazionale&nbsp;\":\"Dx/CDx\",\n",
    "                'La Sinistra':'Sx/CSx',\n",
    "                'Verdi':'Sx/CSx',\n",
    "                'non andrei a votare':'astensione/indecisi',\n",
    "                'sono indeciso' : 'astensione/indecisi',\n",
    "                'Liberi e Uguali' : 'Sx/CSx',\n",
    "                'Italia dei Valori' : 'Sx/CSx',\n",
    "                'Scelta Civica&nbsp;' : 'Sx/CSx',\n",
    "                'Italia Unica di Corrado Passera' : 'Sx/CSx',\n",
    "                \"Noi con l'Italia UDC&nbsp;\" : 'Dx/CDx',\n",
    "                \"altro partito di area di governo (SVP, Centro Democratico....)\" : 'Altro partito',\n",
    "                \"Nuovo Centro Destra con UDC e PPI\" : 'Altro partito'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_p_int_voto\n",
       "Sx/CSx                       1348\n",
       "Dx/CDx                       1094\n",
       "astensione/indecisi           969\n",
       "M5S                           869\n",
       "preferisco non rispondere     150\n",
       "Altro partito                  74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['m_p_int_voto'] = df['m_p_int_voto'].replace(diz_aliases_int_voto)\n",
    "df['m_p_int_voto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['m_p_int_voto'].isin(['Altro partito', 'preferisco non rispondere', 'indecisi','astensione/indecisi' ])]\n",
    "#df = df[~df['m_p_int_voto'].isin(['Altro partito', 'preferisco non rispondere'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Dx/CDx', 'M5S', 'Sx/CSx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_p_int_voto\n",
       "Sx/CSx    1348\n",
       "Dx/CDx    1094\n",
       "M5S        869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['m_p_int_voto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3311, 160)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_ac = {\"del tutto d'accordo\":2,\n",
    "            \"del tutto<BR>d'accordo\":2,\n",
    "\t\t     \"d'accordo\":1,\n",
    "\t\t     \"ne' d'accordo ne' in disaccordo (NON STIMOLARE)\":0,\n",
    "             \"ne d'accordo ne' in disaccordo\":0,\n",
    "             \"ne' d'accordo ne' in disaccordo\":0,\n",
    "             \"preferisco non rispondere\":0,\n",
    "             \"preferisco<BR>non<BR> rispondere\":0,\n",
    "            \"non saprei\":0,\n",
    "             \"in disaccordo\":-1,\n",
    "             'del tutto in disaccordo':-2,\n",
    "             \"del tutto disaccordo\":-2,\n",
    "             \"del tutto<BR>in disaccordo\":-2,\n",
    "             \n",
    "            \n",
    "}\n",
    "\n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if '_ac_' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_op = {\"molto\":2,\n",
    "            \"poco\":-1,\n",
    "            \"pocao\":-1,\n",
    "\t\t     \"abbastanza\":1,\n",
    "\t\t     \"non saprei\":0,\n",
    "            \"nessuno\":-2,\n",
    "            \"per niente\":-2}\n",
    "\n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if 'op' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_trend = {\"in trend\":1,\n",
    "                 \"slight in trend\":1,\n",
    "                 \"slight off trend\":0,\n",
    "                 \"off trend\":0,\n",
    "                 'non classificati':0}\n",
    " \n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if 'TREND' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_scol = {\"elementare/privo di titolo\":1,\n",
    "                 \"media inferiore\":1,\n",
    "                 \"diploma di maturita` (5 anni)\":2,\n",
    "                 \"superiori in corso\":2,\n",
    "                 'diploma di istituto professionale (3 anni)':2,\n",
    "                 'universita` in corso/nessuna laurea conseguita':4,\n",
    "                 'laurea triennale di I livello':4,\n",
    "                 'diploma universitario/laurea breve':4,\n",
    "                 'laurea specialistica di II livello o laurea 4-5 anni':4,\n",
    "                 'master/scuola di specializzazione post laurea':4,\n",
    "                 'dottorato di ricerca':4\n",
    "                 }\n",
    " \n",
    "df['m_p_scolarita'] = df['m_p_scolarita'].replace(diz_aliases_scol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_geo = {'meno di 5.000':1,\n",
    "                 'da 5.001 a 10.000':1,\n",
    "                 'da 10.001 a 30.000':2,\n",
    "                 'da 30.001 a 100.000':2,\n",
    "                 'da 100.001 a 250.000':3,\n",
    "                 'piu` di 250.001':3\n",
    "                 }\n",
    " \n",
    "df['m_p_r_ampiezza6'] = df['m_p_r_ampiezza6'].replace(diz_aliases_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_eco = {\n",
    "                 \"mi sento povero e non arrivo mai a fine mese\":-1,\n",
    "                 \"avverto difficolta'\":-1,\n",
    "                 \"arrivo a fine mese con molte difficolta'\":-1,\n",
    "                 \"con tranquillita'\":1,\n",
    "                 'agiatamente':1\n",
    "                 }\n",
    " \n",
    "df['m_op_come_reddito_consenteDiVivere'] = df['m_op_come_reddito_consenteDiVivere'].replace(diz_aliases_eco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.get_dummies(df, columns=['m_p_zona_5istat'], prefix='zona')\n",
    "df = pd.get_dummies(df, columns=['m_istat_reg'], prefix='reg',dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_quot = {\n",
    "                 0:0,\n",
    "                 'preferisco non rispondere':0,\n",
    "                 \"si alcune volte alla settimana\":1,\n",
    "                 \"si ogni giorno\":1\n",
    "                 }\n",
    " \n",
    "df['m_p_lettura_quotidiani'] = df['m_p_lettura_quotidiani'].replace(diz_aliases_quot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_freq_y = {'mai':0,\n",
    "                     \"piu' raramente\":0,\n",
    "                 \"alcune volte l'anno\":1,\n",
    "                  \"piu' volte alla settimana\":2,\n",
    "                 'mensile':1,\n",
    "                 'settimanale':2}\n",
    " \n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if 'm_p_' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_freq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_freq = {'non saprei':0,\n",
    "                     \"non ascolto la radio\":0,\n",
    "                 \"da piu' di un'ora fino a due ore\":1,\n",
    "                  \"da piu' di tre ore fino a quattro ore\":2,\n",
    "                 'oltre quattro':2,\n",
    "                 \"da piu' di due ore fino a tre ore\":2,\n",
    "                 \"meno di un'ora\":1}\n",
    " \n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if 'm_p_' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_comp = {\n",
    "                 0:0,\n",
    "                 'inferiore':-1,\n",
    "                 'uguale':0,\n",
    "                 \"maggiore\":1,\n",
    "                 'nan':0\n",
    "                 }\n",
    " \n",
    "df['m_op_disorientamento_realta_quotidiana_vs_3anniFa'] = df['m_op_disorientamento_realta_quotidiana_vs_3anniFa'].replace(diz_aliases_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_situazEconomic = {\n",
    "    'rimasta la stessa': 0,\n",
    "    'peggiorata': -1,\n",
    "    'non sa/non risponde': 0,\n",
    "    'nan': 0,\n",
    "    'migliorata': 1\n",
    "}\n",
    "df['m_op_situazEconomic_propria_ultimi10anni'] = df['m_op_situazEconomic_propria_ultimi10anni'].replace(diz_aliases_situazEconomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_futEconomic = {\n",
    "    'peggiorare': -1,\n",
    "    'rimanere la stessa': 0,\n",
    "    'non sa/non risponde': 0,\n",
    "    'nan': 0,\n",
    "    'migliorare': 1\n",
    "}\n",
    "df['m_op_situazEconomic_futura'] = df['m_op_situazEconomic_futura'].replace(diz_aliases_futEconomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_abo = {\n",
    "    'una cattiva legge': -1,\n",
    "    'una legge buona ma che va cambiata': 1,\n",
    "    'una buona legge': 1,\n",
    "    'non saprei/preferisco non rispondere': 0,\n",
    "    'nan': 0\n",
    "}\n",
    "\n",
    "df['m_op_legge_aborto_1987'] = df['m_op_legge_aborto_1987'].replace(diz_aliases_abo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_eut = {\n",
    "    'no': -1,\n",
    "    'si': 2,\n",
    "    'non sa/non risponde': 0,\n",
    "    'dipende dalle condizioni':1\n",
    "}\n",
    "\n",
    "df['m_op_favore_eutanasia_a_determinate_condizioni'] = df['m_op_favore_eutanasia_a_determinate_condizioni'].replace(diz_aliases_eut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_identita = {\n",
    "    \"piu' europeo che italiano\": 2,\n",
    "    'sia italiano che europeo': 1,\n",
    "    'solo italiano': -2,\n",
    "    \"piu' italiano che europeo\": -1,\n",
    "    'non sa - non risponde': 0,\n",
    "    'solo europeo': 2,\n",
    "    'nan': 0\n",
    "}\n",
    "df['m_op_sentimento_italianoVSeuropeo'] = df['m_op_sentimento_italianoVSeuropeo'].replace(diz_aliases_identita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_modernizzazione = {\n",
    "    'si sta modernizzando': 1,\n",
    "    'sta regredendo': -1,\n",
    "    'non sa/non risponde': 0,\n",
    "    'nan': 0\n",
    "}\n",
    "df['m_modernizz_vs_regress_Paese'] = df['m_modernizz_vs_regress_Paese'].replace(diz_aliases_modernizzazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_vantaggi = {\n",
    "    \"piu' vantaggi\": 1,\n",
    "    'vantaggi e svantaggi in egual misura': 0,\n",
    "    \"piu' svantaggi\": -1,\n",
    "    \"ne' vantaggi ne' svantaggi\": 0,\n",
    "    'non sa/non risponde': 0,\n",
    "    'nan': None\n",
    "}\n",
    "df['m_op_partecipazione_in_UE'] = df['m_op_partecipazione_in_UE'].replace(diz_aliases_vantaggi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_livello = {\n",
    "    'bassa': -1,\n",
    "    'media': 1,\n",
    "    'alta': 2,\n",
    "    0: 0,\n",
    "    'nan': None\n",
    "}\n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if 'm_op_attenzione_' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_livello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_andamento = {\n",
    "    'rimasta uguale': 0,\n",
    "    'peggiorata': -1,\n",
    "    'migliorata': 1,\n",
    "    0: 0,\n",
    "    'nan': None\n",
    "}\n",
    "df['m_op_scuolaPubblica_ultimiAnni'] = df['m_op_scuolaPubblica_ultimiAnni'].replace(diz_aliases_andamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_quantita = {\n",
    "    1: 1,\n",
    "    'poca&nbsp;': -1,\n",
    "    'molta': 2,\n",
    "    'nessuna': -2,\n",
    "    0: 0,\n",
    "    'nan': None\n",
    "}\n",
    "nomi_var = df.columns.tolist()\n",
    "for var in nomi_var:\n",
    "    if 'm_op_fiducia_' in var:\n",
    "        df[var] = df[var].replace(diz_aliases_quantita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_postoStabile = {\n",
    "    \"d'accordo\": 1,\n",
    "    'in disaccordo': -1,\n",
    "    \"del tutto d'accordo\": 2,\n",
    "    'del tutto in disaccordo': -2,\n",
    "    'preferisco non rispondere': 0,\n",
    "    'nan': None\n",
    "}\n",
    "df['m_op_rinuncie_per_postoStabile'] = df['m_op_rinuncie_per_postoStabile'].replace(diz_aliases_postoStabile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_aliases_pop = {\n",
    "    'molti danni': 2,\n",
    "    'nessun danno': 0,\n",
    "    'qualche danno': 1,\n",
    "    0: 0,\n",
    "    'nan': None\n",
    "}\n",
    "df['m_op_danni_populismo_in_italia'] = df['m_op_danni_populismo_in_italia'].replace(diz_aliases_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3311, 188)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('à', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('[^a-zA-Z0-9_]', '').str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('[()\\']+|,\\s*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m_sesso</th>\n",
       "      <th>m_p_r_eta</th>\n",
       "      <th>m_p_scolarita</th>\n",
       "      <th>m_p_pubblico_privato</th>\n",
       "      <th>m_p_r_ampiezza6</th>\n",
       "      <th>m_p_nascita_in_italia_genitori</th>\n",
       "      <th>m_p_frequenza_cinema</th>\n",
       "      <th>m_p_frequenza_teatro</th>\n",
       "      <th>m_p_frequenza_concerti</th>\n",
       "      <th>m_p_frequenza_mostre</th>\n",
       "      <th>m_p_frequenza_palestra_sport</th>\n",
       "      <th>m_p_radio_ore</th>\n",
       "      <th>m_p_lettura_quotidiani</th>\n",
       "      <th>m_ac_valore_attuale_patria</th>\n",
       "      <th>m_ac_privilegio_lavoratori_sett_pubblico</th>\n",
       "      <th>m_ac_propensioneRischio_italia_vs_europa</th>\n",
       "      <th>m_ac_importanza_partiti</th>\n",
       "      <th>m_ac_diminuzione_ruolo_partiti</th>\n",
       "      <th>m_ac_affidamento_pubblica_tecnici</th>\n",
       "      <th>m_ac_valori_resistenza_altra_epoca</th>\n",
       "      <th>m_ac_sindacato_ancoraUtile</th>\n",
       "      <th>m_ac_uguaglianza_sociale_frena_individui</th>\n",
       "      <th>m_ac_troppo_focus_uguaglianza_vs_merito</th>\n",
       "      <th>m_ac_meglio_uguaglianza_vs_merito_singolo</th>\n",
       "      <th>m_op_disorientamento_veros_realta_quotidiana</th>\n",
       "      <th>m_op_disorientamento_realta_quotidiana_vs_3anniFa</th>\n",
       "      <th>m_ac_vantaggi_globalizz_economie_mercati</th>\n",
       "      <th>m_ac_globaliz_inarrestabile</th>\n",
       "      <th>m_ac_dovere_difesa_produzPaese_vs_globaliz</th>\n",
       "      <th>m_ac_aumento_competizione_con_piuPreparati</th>\n",
       "      <th>m_ac_aumento_stress_competizione</th>\n",
       "      <th>m_ac_percez_inadeguatezza_da_velocitaCambiamento</th>\n",
       "      <th>m_ac_nonSicuro_doveVive</th>\n",
       "      <th>m_ac_repressione_unicaArma_vs_crimin</th>\n",
       "      <th>m_ac_crimin_diventera_incontenibile</th>\n",
       "      <th>m_op_situazEconomic_propria_ultimi10anni</th>\n",
       "      <th>m_op_situazEconomic_futura</th>\n",
       "      <th>m_op_come_reddito_consenteDiVivere</th>\n",
       "      <th>m_op_legge_aborto_1987</th>\n",
       "      <th>m_ac_validita_insegnamChiesa</th>\n",
       "      <th>m_op_favore_eutanasia_a_determinate_condizioni</th>\n",
       "      <th>m_ac_societa_troppoPermissiva_gay</th>\n",
       "      <th>m_ac_legalizz_drogheLeggere</th>\n",
       "      <th>m_ac_chiesa_nonDovrebbe_condizionare_stato.1</th>\n",
       "      <th>m_ac_testamento_biologico</th>\n",
       "      <th>m_ac_immigrati_rubano_lavoro</th>\n",
       "      <th>m_ac_immigrati_risorsa</th>\n",
       "      <th>m_ac_immigrati_portano_criminalita</th>\n",
       "      <th>m_ac_immigrati_devono_adeguarsi</th>\n",
       "      <th>m_ac_immigrati_diritto_voto</th>\n",
       "      <th>m_ac_immigrati_nonRispettano_regoleDelloStareInsieme</th>\n",
       "      <th>m_op_sentimento_italianoVSeuropeo</th>\n",
       "      <th>m_ac_modernizzazioneItalia_grazie_UE</th>\n",
       "      <th>m_ac_giovani_di_30anniFa_miglioriDiOggi</th>\n",
       "      <th>m_ac_giovaniOggi_incapaci_fareSacrifici</th>\n",
       "      <th>m_ac_nuoveGenerazioni_miglioreranno_mondo</th>\n",
       "      <th>m_ac_impegnoSocialeGiovani_sempreMenoForte</th>\n",
       "      <th>m_ac_governatori_scegliere_senzaBadareOpposizione</th>\n",
       "      <th>m_ac_mediazione_nonRisolve_problemi</th>\n",
       "      <th>m_ac_ricercaCompromesso_faMarcire_situazioni</th>\n",
       "      <th>m_ac_religioneIslamica_pericoloPerTutti</th>\n",
       "      <th>m_ac_musulmaniInItalia_dirittoReligione_inScuole</th>\n",
       "      <th>m_ac_italia_troppeConcessioni_immigratiMusulmani</th>\n",
       "      <th>m_ac_generazioniFuture_vivrannoPeggio</th>\n",
       "      <th>m_modernizz_vs_regress_Paese</th>\n",
       "      <th>m_ac_passato_vivereMeglio_ancheSePiuPoveri</th>\n",
       "      <th>m_ac_italia_paeseInDeclino</th>\n",
       "      <th>m_op_partecipazione_in_UE</th>\n",
       "      <th>m_ac_scienza_problemi_piuChe_benefici</th>\n",
       "      <th>m_ac_scoperte_scientificTecnol_rendono_vita_piuFacile</th>\n",
       "      <th>m_ac_troppo_allarmismo_ecologia_inquinamento</th>\n",
       "      <th>m_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente</th>\n",
       "      <th>m_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo</th>\n",
       "      <th>m_op_contributoDelSingolo_salvaguardia_ambiente</th>\n",
       "      <th>m_op_impegnoPersone_in_tutelaAmbiente</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura</th>\n",
       "      <th>m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti</th>\n",
       "      <th>m_ac_sacrificioEconomico_per_migliorare_ScuolaUniversitaRicerca</th>\n",
       "      <th>m_ac_ScuolaEFormazione_principaleProblema_delPaese</th>\n",
       "      <th>m_op_scuolaPubblica_ultimiAnni</th>\n",
       "      <th>m_ac_scuola_deveEssere_severa_selettiva_meritocratica</th>\n",
       "      <th>m_ac_valorizzare_scuoleEccellenza</th>\n",
       "      <th>m_ac_difesa_scuolaPubblica_insensata</th>\n",
       "      <th>m_ac_attuale_classeInsegnante_incompetente</th>\n",
       "      <th>m_ac_sperimentazioniGenetiche_piuRischi_cheVantaggi</th>\n",
       "      <th>m_ac_problemi_eticiMorali_sperimentazioneGenetica</th>\n",
       "      <th>m_ac_nord_unicoMotore_economiaItaliana</th>\n",
       "      <th>m_ac_lavoroNord_consente_diEssere_alPasso_con_UE</th>\n",
       "      <th>m_ac_guerre_talvolta_maleNecessario.1</th>\n",
       "      <th>m_ac_italia_ipartecipazioneIn_missioniMilitariEstere</th>\n",
       "      <th>m_ac_lavorare_importante_postoStabile_no</th>\n",
       "      <th>m_op_rinuncie_per_postoStabile</th>\n",
       "      <th>m_ac_badare_propriInteressi_perSopravvivere</th>\n",
       "      <th>m_ac_sentirsiSpesso_solo_isolato</th>\n",
       "      <th>m_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti</th>\n",
       "      <th>m_ac_modelloImprenditorialePrivato_unico_meritocratico</th>\n",
       "      <th>m_ac_modelloImprenditorialePrivato_unico_garantireEquita</th>\n",
       "      <th>m_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale</th>\n",
       "      <th>m_ac_dazi_su_produzioni_importanti</th>\n",
       "      <th>m_ac_comprareItaliano_perFronteggiare_crisi</th>\n",
       "      <th>m_ac_generazionePrecedente_piuFelice</th>\n",
       "      <th>m_ac_generazionePrecedente_migliore_qualitaVita</th>\n",
       "      <th>m_ac_generazionePrecedente_maggiore_sicurezzaLavorativa</th>\n",
       "      <th>m_ac_generazionePrecedente_maggiore_mobilitaEconomicoSociale</th>\n",
       "      <th>m_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa</th>\n",
       "      <th>m_op_fiducia_negli_italiani</th>\n",
       "      <th>m_op_fiducia_negli_amici_che_fanno_parte_della_sua_rete_social_network</th>\n",
       "      <th>m_op_fiducia_nei_familiari_con_cui_convive</th>\n",
       "      <th>m_op_fiducia_nei_suoi_parenti</th>\n",
       "      <th>m_op_fiducia_negli_amici_e_conoscenti_dei_suoi_familiari</th>\n",
       "      <th>m_op_fiducia_nei_colleghi_di_lavoro</th>\n",
       "      <th>m_op_fiducia_nei_vicini_di_casa</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_degli_italiani</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_degli_amici_che_fanno_parte_della_sua_rete_social_network</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei_familiari_con_cui_convive</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei_suoi_parenti</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_degli_amici_e_conoscenti_dei_suoi_familiari</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei_colleghi_di_lavoro</th>\n",
       "      <th>m_op_aiutoReciproco_inCasoDiBisogno_dei_vicini_di_casa</th>\n",
       "      <th>m_op_ottica_di_beneComune_italia</th>\n",
       "      <th>m_op_ottica_di_beneComune_comuneResidenza</th>\n",
       "      <th>m_op_importanza_farParte_comunita</th>\n",
       "      <th>m_op_sviluppo_sensoCivico_Paese</th>\n",
       "      <th>m_op_attivita_associazionismo_Italia</th>\n",
       "      <th>m_op_importanza_nellaSocieta_solidarieta</th>\n",
       "      <th>m_op_importanza_nellaSocieta_altruismo</th>\n",
       "      <th>m_op_importanza_nellaSocieta_mutualismo</th>\n",
       "      <th>m_op_danni_populismo_in_italia</th>\n",
       "      <th>m_op_peso_volontariato_in_economiaPaese</th>\n",
       "      <th>m_p_int_voto</th>\n",
       "      <th>m_TREND_1_PATRIA_E_UNITA_NAZIONALE_credono_ancora_nellla_patria</th>\n",
       "      <th>m_TREND_7_SFIDUCIA_NEL_SISTEMA_DEI_PARTI</th>\n",
       "      <th>m_TREND_8_VALORI_FONDATIVI_mantiene_radicati_i_valori</th>\n",
       "      <th>m_TREND_10_MERITO_propende_per_la_meritocrazia</th>\n",
       "      <th>m_TREND_15_INADEGUATEZZA_INDIVIDUALE</th>\n",
       "      <th>m_TREND_19_SICUREZZA_-_CRIMINALITA_si_sente_al_sicuro</th>\n",
       "      <th>m_TREND_25_IMMIGRAZIONE_atteggiamento_POSITIVO_nei_confronti_degli_immigrati</th>\n",
       "      <th>m_TREND_26_NAZIONE_EUROPA</th>\n",
       "      <th>m_TREND_27_SINDACATO_crede_ancora_nel_modello_sindacale</th>\n",
       "      <th>m_TREND_28_GIOVANI_fiducia_alle_nuove_generazioni</th>\n",
       "      <th>m_TREND_29_RADICALIZZAZIONE_crede_nel_compromesso</th>\n",
       "      <th>m_TREND_30_ISLAM_tolleranza_e_fiducia_nei_confronti_dell_Islam</th>\n",
       "      <th>m_TREND_31_EPOCALITA_E_FUTURO_SMARRITO_nostalgico_nei_confronti_del_passato</th>\n",
       "      <th>m_TREND_35_EUROPA_E_MODERNITA_crede_che_lentrata_in_Europa_abbia_modernizzato_il_nostro_paese</th>\n",
       "      <th>m_TREND_37_SCIENZA_FECONDA_crede_nelle_potenzialita_dellinnovazione_scientifica</th>\n",
       "      <th>m_TREND_39_SCUOLA_E_FORMAZIONE_formazione_e_una_priorita_del_Paese</th>\n",
       "      <th>m_TREND_46_SPERIMENTAZIONE_GENETICA</th>\n",
       "      <th>m_TREND_53_INCLUSI_ED_ESCLUSI_si_sente_pienamente_parte_della_societa</th>\n",
       "      <th>m_TREND_50_IL_MODELLO_IMPRESA_individua_nellimpresa_modello_economico_vincente</th>\n",
       "      <th>m_TREND_56_TERRITORIALITA_2009_individua_nella_difesa_della_territorialita_larma_vicente</th>\n",
       "      <th>m_TREND_58_CONFRONTO_CON_LA_GENERAZIONE_PASSATA</th>\n",
       "      <th>m_TREND_52_SOLIDARIETA</th>\n",
       "      <th>m_TREND_53_IL_PERICOLO_POPULISTA</th>\n",
       "      <th>m_TREND_54_DISORIENTAMENTO</th>\n",
       "      <th>prf_lav_Avviare_una_sua_attivita_imprenditoriale_azienda_negozio_etc.</th>\n",
       "      <th>prf_lav_Dipendente_di_una_cooperativa</th>\n",
       "      <th>prf_lav_Dipendente_di_una_grande_impresa_italiana</th>\n",
       "      <th>prf_lav_Dipendente_di_una_multinazionale</th>\n",
       "      <th>prf_lav_Dipendente_di_una_piccola/media_impresa_italiana</th>\n",
       "      <th>prf_lav_Libero_professionista</th>\n",
       "      <th>prf_lav_Nel_settore_pubblico</th>\n",
       "      <th>prf_lav_Nel_terzo_settore_es.cooperative_sociali_enti_no_profit_etc.</th>\n",
       "      <th>prf_lav_Non_saprei</th>\n",
       "      <th>prf_lav_Preferisco_non_rispondere</th>\n",
       "      <th>reg_Abruzzo</th>\n",
       "      <th>reg_Basilicata</th>\n",
       "      <th>reg_Calabria</th>\n",
       "      <th>reg_Campania</th>\n",
       "      <th>reg_Emilia_Romagna</th>\n",
       "      <th>reg_Friuli_Venezia_Giulia</th>\n",
       "      <th>reg_Lazio</th>\n",
       "      <th>reg_Liguria</th>\n",
       "      <th>reg_Lombardia</th>\n",
       "      <th>reg_Marche</th>\n",
       "      <th>reg_Molise</th>\n",
       "      <th>reg_Piemonte</th>\n",
       "      <th>reg_Puglia</th>\n",
       "      <th>reg_Sardegna</th>\n",
       "      <th>reg_Sicilia</th>\n",
       "      <th>reg_Toscana</th>\n",
       "      <th>reg_Trentino_Alto_Adige</th>\n",
       "      <th>reg_Umbria</th>\n",
       "      <th>reg_Valle_Daosta</th>\n",
       "      <th>reg_Veneto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31575</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sx/CSx</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31576</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>M5S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31578</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sx/CSx</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31579</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sx/CSx</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31581</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M5S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       m_sesso  m_p_r_eta  m_p_scolarita  m_p_pubblico_privato  \\\n",
       "31575        1         62              4                     1   \n",
       "31576        1         35              4                     0   \n",
       "31578        1         56              4                     1   \n",
       "31579        0         46              4                     1   \n",
       "31581        0         61              1                     0   \n",
       "\n",
       "       m_p_r_ampiezza6  m_p_nascita_in_italia_genitori  m_p_frequenza_cinema  \\\n",
       "31575                3                               1                     1   \n",
       "31576                2                               1                     1   \n",
       "31578                1                               1                     1   \n",
       "31579                3                               1                     2   \n",
       "31581                3                               1                     0   \n",
       "\n",
       "       m_p_frequenza_teatro  m_p_frequenza_concerti  m_p_frequenza_mostre  \\\n",
       "31575                     0                       0                     1   \n",
       "31576                     0                       0                     0   \n",
       "31578                     1                       0                     0   \n",
       "31579                     1                       0                     1   \n",
       "31581                     0                       0                     0   \n",
       "\n",
       "       m_p_frequenza_palestra_sport  m_p_radio_ore  m_p_lettura_quotidiani  \\\n",
       "31575                             0              1                       1   \n",
       "31576                             2              2                       1   \n",
       "31578                             0              1                       1   \n",
       "31579                             2              1                       1   \n",
       "31581                             0              2                       0   \n",
       "\n",
       "       m_ac_valore_attuale_patria  m_ac_privilegio_lavoratori_sett_pubblico  \\\n",
       "31575                         0.0                                       0.0   \n",
       "31576                         0.0                                       2.0   \n",
       "31578                         1.0                                       0.0   \n",
       "31579                         2.0                                      -1.0   \n",
       "31581                         1.0                                       0.0   \n",
       "\n",
       "       m_ac_propensioneRischio_italia_vs_europa  m_ac_importanza_partiti  \\\n",
       "31575                                      -1.0                      1.0   \n",
       "31576                                      -1.0                     -1.0   \n",
       "31578                                       1.0                      1.0   \n",
       "31579                                      -1.0                      0.0   \n",
       "31581                                      -1.0                      0.0   \n",
       "\n",
       "       m_ac_diminuzione_ruolo_partiti  m_ac_affidamento_pubblica_tecnici  \\\n",
       "31575                            -2.0                               -1.0   \n",
       "31576                             2.0                                0.0   \n",
       "31578                            -2.0                                0.0   \n",
       "31579                             1.0                                2.0   \n",
       "31581                             1.0                                1.0   \n",
       "\n",
       "       m_ac_valori_resistenza_altra_epoca  m_ac_sindacato_ancoraUtile  \\\n",
       "31575                                -1.0                         1.0   \n",
       "31576                                 1.0                        -1.0   \n",
       "31578                                 0.0                         1.0   \n",
       "31579                                 2.0                        -1.0   \n",
       "31581                                 0.0                         1.0   \n",
       "\n",
       "       m_ac_uguaglianza_sociale_frena_individui  \\\n",
       "31575                                      -1.0   \n",
       "31576                                       1.0   \n",
       "31578                                       0.0   \n",
       "31579                                       2.0   \n",
       "31581                                       0.0   \n",
       "\n",
       "       m_ac_troppo_focus_uguaglianza_vs_merito  \\\n",
       "31575                                      0.0   \n",
       "31576                                      1.0   \n",
       "31578                                      0.0   \n",
       "31579                                      1.0   \n",
       "31581                                      0.0   \n",
       "\n",
       "       m_ac_meglio_uguaglianza_vs_merito_singolo  \\\n",
       "31575                                       -2.0   \n",
       "31576                                        0.0   \n",
       "31578                                        0.0   \n",
       "31579                                        0.0   \n",
       "31581                                        0.0   \n",
       "\n",
       "       m_op_disorientamento_veros_realta_quotidiana  \\\n",
       "31575                                          -1.0   \n",
       "31576                                          -1.0   \n",
       "31578                                           1.0   \n",
       "31579                                           1.0   \n",
       "31581                                           2.0   \n",
       "\n",
       "       m_op_disorientamento_realta_quotidiana_vs_3anniFa  \\\n",
       "31575                                                1.0   \n",
       "31576                                               -1.0   \n",
       "31578                                                0.0   \n",
       "31579                                                1.0   \n",
       "31581                                                1.0   \n",
       "\n",
       "       m_ac_vantaggi_globalizz_economie_mercati  m_ac_globaliz_inarrestabile  \\\n",
       "31575                                       1.0                          1.0   \n",
       "31576                                       2.0                          1.0   \n",
       "31578                                       0.0                          1.0   \n",
       "31579                                       1.0                         -2.0   \n",
       "31581                                       0.0                          1.0   \n",
       "\n",
       "       m_ac_dovere_difesa_produzPaese_vs_globaliz  \\\n",
       "31575                                         1.0   \n",
       "31576                                         0.0   \n",
       "31578                                         1.0   \n",
       "31579                                        -2.0   \n",
       "31581                                         2.0   \n",
       "\n",
       "       m_ac_aumento_competizione_con_piuPreparati  \\\n",
       "31575                                         0.0   \n",
       "31576                                         0.0   \n",
       "31578                                         1.0   \n",
       "31579                                         0.0   \n",
       "31581                                         0.0   \n",
       "\n",
       "       m_ac_aumento_stress_competizione  \\\n",
       "31575                              -2.0   \n",
       "31576                               0.0   \n",
       "31578                               0.0   \n",
       "31579                               0.0   \n",
       "31581                               1.0   \n",
       "\n",
       "       m_ac_percez_inadeguatezza_da_velocitaCambiamento  \\\n",
       "31575                                               0.0   \n",
       "31576                                               0.0   \n",
       "31578                                               0.0   \n",
       "31579                                               0.0   \n",
       "31581                                               1.0   \n",
       "\n",
       "       m_ac_nonSicuro_doveVive  m_ac_repressione_unicaArma_vs_crimin  \\\n",
       "31575                      0.0                                   0.0   \n",
       "31576                      0.0                                   0.0   \n",
       "31578                      0.0                                   0.0   \n",
       "31579                      2.0                                   1.0   \n",
       "31581                      0.0                                   1.0   \n",
       "\n",
       "       m_ac_crimin_diventera_incontenibile  \\\n",
       "31575                                  0.0   \n",
       "31576                                  1.0   \n",
       "31578                                  0.0   \n",
       "31579                                  2.0   \n",
       "31581                                 -1.0   \n",
       "\n",
       "       m_op_situazEconomic_propria_ultimi10anni  m_op_situazEconomic_futura  \\\n",
       "31575                                       0.0                        -1.0   \n",
       "31576                                      -1.0                         0.0   \n",
       "31578                                       0.0                        -1.0   \n",
       "31579                                      -1.0                         0.0   \n",
       "31581                                       0.0                         0.0   \n",
       "\n",
       "       m_op_come_reddito_consenteDiVivere  m_op_legge_aborto_1987  \\\n",
       "31575                                 1.0                    -1.0   \n",
       "31576                                -1.0                     1.0   \n",
       "31578                                -1.0                     1.0   \n",
       "31579                                 1.0                     1.0   \n",
       "31581                                -1.0                     1.0   \n",
       "\n",
       "       m_ac_validita_insegnamChiesa  \\\n",
       "31575                           2.0   \n",
       "31576                          -1.0   \n",
       "31578                           1.0   \n",
       "31579                           2.0   \n",
       "31581                          -1.0   \n",
       "\n",
       "       m_op_favore_eutanasia_a_determinate_condizioni  \\\n",
       "31575                                            -1.0   \n",
       "31576                                             2.0   \n",
       "31578                                             2.0   \n",
       "31579                                             2.0   \n",
       "31581                                             2.0   \n",
       "\n",
       "       m_ac_societa_troppoPermissiva_gay  m_ac_legalizz_drogheLeggere  \\\n",
       "31575                                1.0                          0.0   \n",
       "31576                               -1.0                          2.0   \n",
       "31578                               -1.0                          1.0   \n",
       "31579                               -1.0                         -1.0   \n",
       "31581                               -1.0                          1.0   \n",
       "\n",
       "       m_ac_chiesa_nonDovrebbe_condizionare_stato.1  \\\n",
       "31575                                          -1.0   \n",
       "31576                                           2.0   \n",
       "31578                                           2.0   \n",
       "31579                                           0.0   \n",
       "31581                                           2.0   \n",
       "\n",
       "       m_ac_testamento_biologico  m_ac_immigrati_rubano_lavoro  \\\n",
       "31575                       -2.0                          -1.0   \n",
       "31576                        2.0                          -1.0   \n",
       "31578                       -1.0                           0.0   \n",
       "31579                       -1.0                           0.0   \n",
       "31581                        2.0                          -1.0   \n",
       "\n",
       "       m_ac_immigrati_risorsa  m_ac_immigrati_portano_criminalita  \\\n",
       "31575                     1.0                                -1.0   \n",
       "31576                     0.0                                 0.0   \n",
       "31578                     2.0                                 1.0   \n",
       "31579                     1.0                                 0.0   \n",
       "31581                     1.0                                -1.0   \n",
       "\n",
       "       m_ac_immigrati_devono_adeguarsi  m_ac_immigrati_diritto_voto  \\\n",
       "31575                              1.0                          1.0   \n",
       "31576                              1.0                          0.0   \n",
       "31578                              1.0                          1.0   \n",
       "31579                              1.0                          1.0   \n",
       "31581                              1.0                          1.0   \n",
       "\n",
       "       m_ac_immigrati_nonRispettano_regoleDelloStareInsieme  \\\n",
       "31575                                               -1.0      \n",
       "31576                                                1.0      \n",
       "31578                                                0.0      \n",
       "31579                                                1.0      \n",
       "31581                                                1.0      \n",
       "\n",
       "       m_op_sentimento_italianoVSeuropeo  \\\n",
       "31575                                2.0   \n",
       "31576                                2.0   \n",
       "31578                                1.0   \n",
       "31579                               -2.0   \n",
       "31581                                1.0   \n",
       "\n",
       "       m_ac_modernizzazioneItalia_grazie_UE  \\\n",
       "31575                                   1.0   \n",
       "31576                                   1.0   \n",
       "31578                                   0.0   \n",
       "31579                                  -1.0   \n",
       "31581                                  -1.0   \n",
       "\n",
       "       m_ac_giovani_di_30anniFa_miglioriDiOggi  \\\n",
       "31575                                     -2.0   \n",
       "31576                                      2.0   \n",
       "31578                                     -2.0   \n",
       "31579                                      2.0   \n",
       "31581                                      0.0   \n",
       "\n",
       "       m_ac_giovaniOggi_incapaci_fareSacrifici  \\\n",
       "31575                                      1.0   \n",
       "31576                                      2.0   \n",
       "31578                                      0.0   \n",
       "31579                                      2.0   \n",
       "31581                                      0.0   \n",
       "\n",
       "       m_ac_nuoveGenerazioni_miglioreranno_mondo  \\\n",
       "31575                                       -2.0   \n",
       "31576                                        2.0   \n",
       "31578                                        1.0   \n",
       "31579                                        2.0   \n",
       "31581                                        1.0   \n",
       "\n",
       "       m_ac_impegnoSocialeGiovani_sempreMenoForte  \\\n",
       "31575                                         1.0   \n",
       "31576                                         1.0   \n",
       "31578                                        -1.0   \n",
       "31579                                         2.0   \n",
       "31581                                        -1.0   \n",
       "\n",
       "       m_ac_governatori_scegliere_senzaBadareOpposizione  \\\n",
       "31575                                                0.0   \n",
       "31576                                                2.0   \n",
       "31578                                                0.0   \n",
       "31579                                               -1.0   \n",
       "31581                                                0.0   \n",
       "\n",
       "       m_ac_mediazione_nonRisolve_problemi  \\\n",
       "31575                                  0.0   \n",
       "31576                                  0.0   \n",
       "31578                                  1.0   \n",
       "31579                                 -1.0   \n",
       "31581                                 -1.0   \n",
       "\n",
       "       m_ac_ricercaCompromesso_faMarcire_situazioni  \\\n",
       "31575                                           0.0   \n",
       "31576                                           2.0   \n",
       "31578                                           1.0   \n",
       "31579                                          -1.0   \n",
       "31581                                           0.0   \n",
       "\n",
       "       m_ac_religioneIslamica_pericoloPerTutti  \\\n",
       "31575                                      0.0   \n",
       "31576                                     -1.0   \n",
       "31578                                      1.0   \n",
       "31579                                      2.0   \n",
       "31581                                      0.0   \n",
       "\n",
       "       m_ac_musulmaniInItalia_dirittoReligione_inScuole  \\\n",
       "31575                                               1.0   \n",
       "31576                                              -1.0   \n",
       "31578                                               1.0   \n",
       "31579                                               0.0   \n",
       "31581                                               1.0   \n",
       "\n",
       "       m_ac_italia_troppeConcessioni_immigratiMusulmani  \\\n",
       "31575                                              -1.0   \n",
       "31576                                              -1.0   \n",
       "31578                                              -1.0   \n",
       "31579                                               2.0   \n",
       "31581                                              -1.0   \n",
       "\n",
       "       m_ac_generazioniFuture_vivrannoPeggio  m_modernizz_vs_regress_Paese  \\\n",
       "31575                                    0.0                           1.0   \n",
       "31576                                    1.0                           1.0   \n",
       "31578                                   -1.0                           1.0   \n",
       "31579                                    2.0                          -1.0   \n",
       "31581                                    2.0                           1.0   \n",
       "\n",
       "       m_ac_passato_vivereMeglio_ancheSePiuPoveri  m_ac_italia_paeseInDeclino  \\\n",
       "31575                                         0.0                         0.0   \n",
       "31576                                         1.0                         2.0   \n",
       "31578                                         2.0                         0.0   \n",
       "31579                                         2.0                         2.0   \n",
       "31581                                         0.0                         1.0   \n",
       "\n",
       "       m_op_partecipazione_in_UE  m_ac_scienza_problemi_piuChe_benefici  \\\n",
       "31575                        1.0                                    0.0   \n",
       "31576                        0.0                                   -1.0   \n",
       "31578                        0.0                                    0.0   \n",
       "31579                       -1.0                                    1.0   \n",
       "31581                        1.0                                    0.0   \n",
       "\n",
       "       m_ac_scoperte_scientificTecnol_rendono_vita_piuFacile  \\\n",
       "31575                                                1.0       \n",
       "31576                                                2.0       \n",
       "31578                                                1.0       \n",
       "31579                                                1.0       \n",
       "31581                                                1.0       \n",
       "\n",
       "       m_ac_troppo_allarmismo_ecologia_inquinamento  \\\n",
       "31575                                          -1.0   \n",
       "31576                                          -2.0   \n",
       "31578                                          -1.0   \n",
       "31579                                          -2.0   \n",
       "31581                                          -2.0   \n",
       "\n",
       "       m_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente  \\\n",
       "31575                                               -1.0        \n",
       "31576                                               -1.0        \n",
       "31578                                               -1.0        \n",
       "31579                                               -2.0        \n",
       "31581                                                1.0        \n",
       "\n",
       "       m_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo  \\\n",
       "31575                                               -1.0         \n",
       "31576                                                1.0         \n",
       "31578                                                1.0         \n",
       "31579                                                2.0         \n",
       "31581                                                2.0         \n",
       "\n",
       "       m_op_contributoDelSingolo_salvaguardia_ambiente  \\\n",
       "31575                                              2.0   \n",
       "31576                                             -1.0   \n",
       "31578                                              1.0   \n",
       "31579                                              2.0   \n",
       "31581                                              1.0   \n",
       "\n",
       "       m_op_impegnoPersone_in_tutelaAmbiente  \\\n",
       "31575                                   -1.0   \n",
       "31576                                   -1.0   \n",
       "31578                                   -1.0   \n",
       "31579                                   -2.0   \n",
       "31581                                   -1.0   \n",
       "\n",
       "       m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico  \\\n",
       "31575                                               -1.0                \n",
       "31576                                               -1.0                \n",
       "31578                                                1.0                \n",
       "31579                                               -1.0                \n",
       "31581                                                1.0                \n",
       "\n",
       "       m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff  \\\n",
       "31575                                                1.0                \n",
       "31576                                                1.0                \n",
       "31578                                                2.0                \n",
       "31579                                                1.0                \n",
       "31581                                               -1.0                \n",
       "\n",
       "       m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative  \\\n",
       "31575                                               -1.0                      \n",
       "31576                                                1.0                      \n",
       "31578                                               -1.0                      \n",
       "31579                                               -1.0                      \n",
       "31581                                               -1.0                      \n",
       "\n",
       "       m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili  \\\n",
       "31575                                               -1.0                            \n",
       "31576                                               -1.0                            \n",
       "31578                                               -1.0                            \n",
       "31579                                               -1.0                            \n",
       "31581                                               -1.0                            \n",
       "\n",
       "       m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura  \\\n",
       "31575                                               -1.0                        \n",
       "31576                                               -1.0                        \n",
       "31578                                                1.0                        \n",
       "31579                                                1.0                        \n",
       "31581                                               -1.0                        \n",
       "\n",
       "       m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti  \\\n",
       "31575                                               -1.0                                \n",
       "31576                                               -1.0                                \n",
       "31578                                                1.0                                \n",
       "31579                                                2.0                                \n",
       "31581                                               -1.0                                \n",
       "\n",
       "       m_ac_sacrificioEconomico_per_migliorare_ScuolaUniversitaRicerca  \\\n",
       "31575                                                2.0                 \n",
       "31576                                                0.0                 \n",
       "31578                                                0.0                 \n",
       "31579                                                1.0                 \n",
       "31581                                               -1.0                 \n",
       "\n",
       "       m_ac_ScuolaEFormazione_principaleProblema_delPaese  \\\n",
       "31575                                                1.0    \n",
       "31576                                                0.0    \n",
       "31578                                                1.0    \n",
       "31579                                                0.0    \n",
       "31581                                                0.0    \n",
       "\n",
       "       m_op_scuolaPubblica_ultimiAnni  \\\n",
       "31575                             0.0   \n",
       "31576                            -1.0   \n",
       "31578                            -1.0   \n",
       "31579                            -1.0   \n",
       "31581                            -1.0   \n",
       "\n",
       "       m_ac_scuola_deveEssere_severa_selettiva_meritocratica  \\\n",
       "31575                                               -1.0       \n",
       "31576                                                2.0       \n",
       "31578                                               -1.0       \n",
       "31579                                                2.0       \n",
       "31581                                                2.0       \n",
       "\n",
       "       m_ac_valorizzare_scuoleEccellenza  \\\n",
       "31575                               -1.0   \n",
       "31576                                2.0   \n",
       "31578                                1.0   \n",
       "31579                                2.0   \n",
       "31581                                2.0   \n",
       "\n",
       "       m_ac_difesa_scuolaPubblica_insensata  \\\n",
       "31575                                  -1.0   \n",
       "31576                                  -2.0   \n",
       "31578                                  -2.0   \n",
       "31579                                   2.0   \n",
       "31581                                  -2.0   \n",
       "\n",
       "       m_ac_attuale_classeInsegnante_incompetente  \\\n",
       "31575                                         1.0   \n",
       "31576                                         2.0   \n",
       "31578                                         0.0   \n",
       "31579                                         2.0   \n",
       "31581                                        -1.0   \n",
       "\n",
       "       m_ac_sperimentazioniGenetiche_piuRischi_cheVantaggi  \\\n",
       "31575                                                2.0     \n",
       "31576                                                0.0     \n",
       "31578                                                0.0     \n",
       "31579                                                2.0     \n",
       "31581                                                0.0     \n",
       "\n",
       "       m_ac_problemi_eticiMorali_sperimentazioneGenetica  \\\n",
       "31575                                                2.0   \n",
       "31576                                                1.0   \n",
       "31578                                                1.0   \n",
       "31579                                               -1.0   \n",
       "31581                                                1.0   \n",
       "\n",
       "       m_ac_nord_unicoMotore_economiaItaliana  \\\n",
       "31575                                    -1.0   \n",
       "31576                                     1.0   \n",
       "31578                                    -1.0   \n",
       "31579                                    -1.0   \n",
       "31581                                    -2.0   \n",
       "\n",
       "       m_ac_lavoroNord_consente_diEssere_alPasso_con_UE  \\\n",
       "31575                                              -1.0   \n",
       "31576                                               2.0   \n",
       "31578                                              -1.0   \n",
       "31579                                              -1.0   \n",
       "31581                                              -2.0   \n",
       "\n",
       "       m_ac_guerre_talvolta_maleNecessario.1  \\\n",
       "31575                                   -2.0   \n",
       "31576                                    0.0   \n",
       "31578                                    0.0   \n",
       "31579                                   -1.0   \n",
       "31581                                   -1.0   \n",
       "\n",
       "       m_ac_italia_ipartecipazioneIn_missioniMilitariEstere  \\\n",
       "31575                                                1.0      \n",
       "31576                                                1.0      \n",
       "31578                                                2.0      \n",
       "31579                                               -2.0      \n",
       "31581                                               -1.0      \n",
       "\n",
       "       m_ac_lavorare_importante_postoStabile_no  \\\n",
       "31575                                       0.0   \n",
       "31576                                      -1.0   \n",
       "31578                                       1.0   \n",
       "31579                                      -1.0   \n",
       "31581                                      -1.0   \n",
       "\n",
       "       m_op_rinuncie_per_postoStabile  \\\n",
       "31575                             1.0   \n",
       "31576                            -1.0   \n",
       "31578                             1.0   \n",
       "31579                            -1.0   \n",
       "31581                             1.0   \n",
       "\n",
       "       m_ac_badare_propriInteressi_perSopravvivere  \\\n",
       "31575                                         -2.0   \n",
       "31576                                         -1.0   \n",
       "31578                                         -1.0   \n",
       "31579                                         -1.0   \n",
       "31581                                         -1.0   \n",
       "\n",
       "       m_ac_sentirsiSpesso_solo_isolato  \\\n",
       "31575                               1.0   \n",
       "31576                              -2.0   \n",
       "31578                              -1.0   \n",
       "31579                               1.0   \n",
       "31581                               1.0   \n",
       "\n",
       "       m_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti  \\\n",
       "31575                                               -2.0                   \n",
       "31576                                                1.0                   \n",
       "31578                                               -1.0                   \n",
       "31579                                               -2.0                   \n",
       "31581                                               -1.0                   \n",
       "\n",
       "       m_ac_modelloImprenditorialePrivato_unico_meritocratico  \\\n",
       "31575                                               -2.0        \n",
       "31576                                                1.0        \n",
       "31578                                               -1.0        \n",
       "31579                                               -2.0        \n",
       "31581                                               -1.0        \n",
       "\n",
       "       m_ac_modelloImprenditorialePrivato_unico_garantireEquita  \\\n",
       "31575                                               -2.0          \n",
       "31576                                               -1.0          \n",
       "31578                                               -1.0          \n",
       "31579                                               -2.0          \n",
       "31581                                               -1.0          \n",
       "\n",
       "       m_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale  \\\n",
       "31575                                               -1.0                     \n",
       "31576                                                2.0                     \n",
       "31578                                                1.0                     \n",
       "31579                                                2.0                     \n",
       "31581                                                1.0                     \n",
       "\n",
       "       m_ac_dazi_su_produzioni_importanti  \\\n",
       "31575                                -1.0   \n",
       "31576                                -1.0   \n",
       "31578                                -1.0   \n",
       "31579                                 2.0   \n",
       "31581                                 2.0   \n",
       "\n",
       "       m_ac_comprareItaliano_perFronteggiare_crisi  \\\n",
       "31575                                          0.0   \n",
       "31576                                         -1.0   \n",
       "31578                                          1.0   \n",
       "31579                                          2.0   \n",
       "31581                                          1.0   \n",
       "\n",
       "       m_ac_generazionePrecedente_piuFelice  \\\n",
       "31575                                   1.0   \n",
       "31576                                   1.0   \n",
       "31578                                   1.0   \n",
       "31579                                   2.0   \n",
       "31581                                  -1.0   \n",
       "\n",
       "       m_ac_generazionePrecedente_migliore_qualitaVita  \\\n",
       "31575                                              1.0   \n",
       "31576                                             -1.0   \n",
       "31578                                             -1.0   \n",
       "31579                                             -1.0   \n",
       "31581                                             -1.0   \n",
       "\n",
       "       m_ac_generazionePrecedente_maggiore_sicurezzaLavorativa  \\\n",
       "31575                                                1.0         \n",
       "31576                                                1.0         \n",
       "31578                                                1.0         \n",
       "31579                                                1.0         \n",
       "31581                                                1.0         \n",
       "\n",
       "       m_ac_generazionePrecedente_maggiore_mobilitaEconomicoSociale  \\\n",
       "31575                                                1.0              \n",
       "31576                                                1.0              \n",
       "31578                                                2.0              \n",
       "31579                                                2.0              \n",
       "31581                                                1.0              \n",
       "\n",
       "       m_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa  \\\n",
       "31575                                               -1.0     \n",
       "31576                                                2.0     \n",
       "31578                                               -1.0     \n",
       "31579                                                2.0     \n",
       "31581                                               -2.0     \n",
       "\n",
       "       m_op_fiducia_negli_italiani  \\\n",
       "31575                          1.0   \n",
       "31576                         -1.0   \n",
       "31578                          1.0   \n",
       "31579                          2.0   \n",
       "31581                          1.0   \n",
       "\n",
       "       m_op_fiducia_negli_amici_che_fanno_parte_della_sua_rete_social_network  \\\n",
       "31575                                                0.0                        \n",
       "31576                                                1.0                        \n",
       "31578                                                1.0                        \n",
       "31579                                                1.0                        \n",
       "31581                                               -2.0                        \n",
       "\n",
       "       m_op_fiducia_nei_familiari_con_cui_convive  \\\n",
       "31575                                         2.0   \n",
       "31576                                         2.0   \n",
       "31578                                         2.0   \n",
       "31579                                         2.0   \n",
       "31581                                         2.0   \n",
       "\n",
       "       m_op_fiducia_nei_suoi_parenti  \\\n",
       "31575                            1.0   \n",
       "31576                            2.0   \n",
       "31578                            1.0   \n",
       "31579                            1.0   \n",
       "31581                            1.0   \n",
       "\n",
       "       m_op_fiducia_negli_amici_e_conoscenti_dei_suoi_familiari  \\\n",
       "31575                                                1.0          \n",
       "31576                                               -1.0          \n",
       "31578                                               -1.0          \n",
       "31579                                                1.0          \n",
       "31581                                                1.0          \n",
       "\n",
       "       m_op_fiducia_nei_colleghi_di_lavoro  m_op_fiducia_nei_vicini_di_casa  \\\n",
       "31575                                 -1.0                              0.0   \n",
       "31576                                  1.0                             -2.0   \n",
       "31578                                 -1.0                             -1.0   \n",
       "31579                                 -2.0                             -2.0   \n",
       "31581                                  0.0                              1.0   \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_degli_italiani  \\\n",
       "31575                                               -1.0    \n",
       "31576                                               -1.0    \n",
       "31578                                                1.0    \n",
       "31579                                               -2.0    \n",
       "31581                                                2.0    \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_degli_amici_che_fanno_parte_della_sua_rete_social_network  \\\n",
       "31575                                                0.0                                               \n",
       "31576                                                1.0                                               \n",
       "31578                                               -1.0                                               \n",
       "31579                                               -1.0                                               \n",
       "31581                                               -1.0                                               \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_dei_familiari_con_cui_convive  \\\n",
       "31575                                                2.0                   \n",
       "31576                                                2.0                   \n",
       "31578                                                1.0                   \n",
       "31579                                                2.0                   \n",
       "31581                                                2.0                   \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_dei_suoi_parenti  \\\n",
       "31575                                                1.0      \n",
       "31576                                                2.0      \n",
       "31578                                               -1.0      \n",
       "31579                                               -1.0      \n",
       "31581                                                2.0      \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_degli_amici_e_conoscenti_dei_suoi_familiari  \\\n",
       "31575                                               -1.0                                 \n",
       "31576                                               -2.0                                 \n",
       "31578                                               -1.0                                 \n",
       "31579                                               -1.0                                 \n",
       "31581                                                1.0                                 \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_dei_colleghi_di_lavoro  \\\n",
       "31575                                               -1.0            \n",
       "31576                                               -1.0            \n",
       "31578                                                1.0            \n",
       "31579                                               -2.0            \n",
       "31581                                                0.0            \n",
       "\n",
       "       m_op_aiutoReciproco_inCasoDiBisogno_dei_vicini_di_casa  \\\n",
       "31575                                                0.0        \n",
       "31576                                               -2.0        \n",
       "31578                                               -1.0        \n",
       "31579                                               -2.0        \n",
       "31581                                                1.0        \n",
       "\n",
       "       m_op_ottica_di_beneComune_italia  \\\n",
       "31575                              -1.0   \n",
       "31576                              -2.0   \n",
       "31578                              -1.0   \n",
       "31579                              -2.0   \n",
       "31581                              -2.0   \n",
       "\n",
       "       m_op_ottica_di_beneComune_comuneResidenza  \\\n",
       "31575                                       -1.0   \n",
       "31576                                       -1.0   \n",
       "31578                                       -1.0   \n",
       "31579                                       -1.0   \n",
       "31581                                       -2.0   \n",
       "\n",
       "       m_op_importanza_farParte_comunita  m_op_sviluppo_sensoCivico_Paese  \\\n",
       "31575                                2.0                             -1.0   \n",
       "31576                               -2.0                             -2.0   \n",
       "31578                                2.0                             -1.0   \n",
       "31579                                2.0                             -2.0   \n",
       "31581                                1.0                             -2.0   \n",
       "\n",
       "       m_op_attivita_associazionismo_Italia  \\\n",
       "31575                                   1.0   \n",
       "31576                                   1.0   \n",
       "31578                                   2.0   \n",
       "31579                                  -1.0   \n",
       "31581                                  -1.0   \n",
       "\n",
       "       m_op_importanza_nellaSocieta_solidarieta  \\\n",
       "31575                                       1.0   \n",
       "31576                                       1.0   \n",
       "31578                                       2.0   \n",
       "31579                                       2.0   \n",
       "31581                                       2.0   \n",
       "\n",
       "       m_op_importanza_nellaSocieta_altruismo  \\\n",
       "31575                                     1.0   \n",
       "31576                                     1.0   \n",
       "31578                                    -1.0   \n",
       "31579                                     2.0   \n",
       "31581                                     2.0   \n",
       "\n",
       "       m_op_importanza_nellaSocieta_mutualismo  \\\n",
       "31575                                     -1.0   \n",
       "31576                                      1.0   \n",
       "31578                                     -1.0   \n",
       "31579                                      2.0   \n",
       "31581                                      1.0   \n",
       "\n",
       "       m_op_danni_populismo_in_italia  \\\n",
       "31575                             2.0   \n",
       "31576                             0.0   \n",
       "31578                             1.0   \n",
       "31579                             0.0   \n",
       "31581                             2.0   \n",
       "\n",
       "       m_op_peso_volontariato_in_economiaPaese m_p_int_voto  \\\n",
       "31575                                      2.0       Sx/CSx   \n",
       "31576                                     -1.0          M5S   \n",
       "31578                                      2.0       Sx/CSx   \n",
       "31579                                      1.0       Sx/CSx   \n",
       "31581                                      2.0          M5S   \n",
       "\n",
       "       m_TREND_1_PATRIA_E_UNITA_NAZIONALE_credono_ancora_nellla_patria  \\\n",
       "31575                                                0.0                 \n",
       "31576                                                0.0                 \n",
       "31578                                                1.0                 \n",
       "31579                                                1.0                 \n",
       "31581                                                1.0                 \n",
       "\n",
       "       m_TREND_7_SFIDUCIA_NEL_SISTEMA_DEI_PARTI  \\\n",
       "31575                                       0.0   \n",
       "31576                                       1.0   \n",
       "31578                                       0.0   \n",
       "31579                                       1.0   \n",
       "31581                                       1.0   \n",
       "\n",
       "       m_TREND_8_VALORI_FONDATIVI_mantiene_radicati_i_valori  \\\n",
       "31575                                                1.0       \n",
       "31576                                                0.0       \n",
       "31578                                                1.0       \n",
       "31579                                                0.0       \n",
       "31581                                                1.0       \n",
       "\n",
       "       m_TREND_10_MERITO_propende_per_la_meritocrazia  \\\n",
       "31575                                             0.0   \n",
       "31576                                             1.0   \n",
       "31578                                             0.0   \n",
       "31579                                             1.0   \n",
       "31581                                             0.0   \n",
       "\n",
       "       m_TREND_15_INADEGUATEZZA_INDIVIDUALE  \\\n",
       "31575                                   0.0   \n",
       "31576                                   0.0   \n",
       "31578                                   0.0   \n",
       "31579                                   0.0   \n",
       "31581                                   1.0   \n",
       "\n",
       "       m_TREND_19_SICUREZZA_-_CRIMINALITA_si_sente_al_sicuro  \\\n",
       "31575                                                1.0       \n",
       "31576                                                1.0       \n",
       "31578                                                1.0       \n",
       "31579                                                0.0       \n",
       "31581                                                1.0       \n",
       "\n",
       "       m_TREND_25_IMMIGRAZIONE_atteggiamento_POSITIVO_nei_confronti_degli_immigrati  \\\n",
       "31575                                                1.0                              \n",
       "31576                                                0.0                              \n",
       "31578                                                1.0                              \n",
       "31579                                                1.0                              \n",
       "31581                                                1.0                              \n",
       "\n",
       "       m_TREND_26_NAZIONE_EUROPA  \\\n",
       "31575                        1.0   \n",
       "31576                        1.0   \n",
       "31578                        1.0   \n",
       "31579                        0.0   \n",
       "31581                        0.0   \n",
       "\n",
       "       m_TREND_27_SINDACATO_crede_ancora_nel_modello_sindacale  \\\n",
       "31575                                                0.0         \n",
       "31576                                                0.0         \n",
       "31578                                                1.0         \n",
       "31579                                                0.0         \n",
       "31581                                                1.0         \n",
       "\n",
       "       m_TREND_28_GIOVANI_fiducia_alle_nuove_generazioni  \\\n",
       "31575                                                0.0   \n",
       "31576                                                0.0   \n",
       "31578                                                1.0   \n",
       "31579                                                0.0   \n",
       "31581                                                1.0   \n",
       "\n",
       "       m_TREND_29_RADICALIZZAZIONE_crede_nel_compromesso  \\\n",
       "31575                                                0.0   \n",
       "31576                                                1.0   \n",
       "31578                                                1.0   \n",
       "31579                                                0.0   \n",
       "31581                                                0.0   \n",
       "\n",
       "       m_TREND_30_ISLAM_tolleranza_e_fiducia_nei_confronti_dell_Islam  \\\n",
       "31575                                                1.0                \n",
       "31576                                                1.0                \n",
       "31578                                                0.0                \n",
       "31579                                                0.0                \n",
       "31581                                                1.0                \n",
       "\n",
       "       m_TREND_31_EPOCALITA_E_FUTURO_SMARRITO_nostalgico_nei_confronti_del_passato  \\\n",
       "31575                                                0.0                             \n",
       "31576                                                0.0                             \n",
       "31578                                                0.0                             \n",
       "31579                                                1.0                             \n",
       "31581                                                0.0                             \n",
       "\n",
       "       m_TREND_35_EUROPA_E_MODERNITA_crede_che_lentrata_in_Europa_abbia_modernizzato_il_nostro_paese  \\\n",
       "31575                                                1.0                                               \n",
       "31576                                                1.0                                               \n",
       "31578                                                1.0                                               \n",
       "31579                                                0.0                                               \n",
       "31581                                                1.0                                               \n",
       "\n",
       "       m_TREND_37_SCIENZA_FECONDA_crede_nelle_potenzialita_dellinnovazione_scientifica  \\\n",
       "31575                                                1.0                                 \n",
       "31576                                                1.0                                 \n",
       "31578                                                1.0                                 \n",
       "31579                                                0.0                                 \n",
       "31581                                                1.0                                 \n",
       "\n",
       "       m_TREND_39_SCUOLA_E_FORMAZIONE_formazione_e_una_priorita_del_Paese  \\\n",
       "31575                                                1.0                    \n",
       "31576                                                0.0                    \n",
       "31578                                                0.0                    \n",
       "31579                                                0.0                    \n",
       "31581                                                0.0                    \n",
       "\n",
       "       m_TREND_46_SPERIMENTAZIONE_GENETICA  \\\n",
       "31575                                  0.0   \n",
       "31576                                  0.0   \n",
       "31578                                  0.0   \n",
       "31579                                  0.0   \n",
       "31581                                  0.0   \n",
       "\n",
       "       m_TREND_53_INCLUSI_ED_ESCLUSI_si_sente_pienamente_parte_della_societa  \\\n",
       "31575                                                1.0                       \n",
       "31576                                                0.0                       \n",
       "31578                                                1.0                       \n",
       "31579                                                1.0                       \n",
       "31581                                                1.0                       \n",
       "\n",
       "       m_TREND_50_IL_MODELLO_IMPRESA_individua_nellimpresa_modello_economico_vincente  \\\n",
       "31575                                                0.0                                \n",
       "31576                                                1.0                                \n",
       "31578                                                0.0                                \n",
       "31579                                                0.0                                \n",
       "31581                                                0.0                                \n",
       "\n",
       "       m_TREND_56_TERRITORIALITA_2009_individua_nella_difesa_della_territorialita_larma_vicente  \\\n",
       "31575                                                0.0                                          \n",
       "31576                                                0.0                                          \n",
       "31578                                                0.0                                          \n",
       "31579                                                1.0                                          \n",
       "31581                                                1.0                                          \n",
       "\n",
       "       m_TREND_58_CONFRONTO_CON_LA_GENERAZIONE_PASSATA  \\\n",
       "31575                                              1.0   \n",
       "31576                                              1.0   \n",
       "31578                                              1.0   \n",
       "31579                                              1.0   \n",
       "31581                                              0.0   \n",
       "\n",
       "       m_TREND_52_SOLIDARIETA  m_TREND_53_IL_PERICOLO_POPULISTA  \\\n",
       "31575                     1.0                               1.0   \n",
       "31576                     1.0                               0.0   \n",
       "31578                     0.0                               1.0   \n",
       "31579                     1.0                               0.0   \n",
       "31581                     1.0                               1.0   \n",
       "\n",
       "       m_TREND_54_DISORIENTAMENTO  \\\n",
       "31575                         1.0   \n",
       "31576                         0.0   \n",
       "31578                         1.0   \n",
       "31579                         1.0   \n",
       "31581                         1.0   \n",
       "\n",
       "       prf_lav_Avviare_una_sua_attivita_imprenditoriale_azienda_negozio_etc.  \\\n",
       "31575                                                  0                       \n",
       "31576                                                  0                       \n",
       "31578                                                  0                       \n",
       "31579                                                  0                       \n",
       "31581                                                  0                       \n",
       "\n",
       "       prf_lav_Dipendente_di_una_cooperativa  \\\n",
       "31575                                      0   \n",
       "31576                                      0   \n",
       "31578                                      0   \n",
       "31579                                      0   \n",
       "31581                                      0   \n",
       "\n",
       "       prf_lav_Dipendente_di_una_grande_impresa_italiana  \\\n",
       "31575                                                  0   \n",
       "31576                                                  0   \n",
       "31578                                                  0   \n",
       "31579                                                  0   \n",
       "31581                                                  0   \n",
       "\n",
       "       prf_lav_Dipendente_di_una_multinazionale  \\\n",
       "31575                                         0   \n",
       "31576                                         0   \n",
       "31578                                         0   \n",
       "31579                                         0   \n",
       "31581                                         0   \n",
       "\n",
       "       prf_lav_Dipendente_di_una_piccola/media_impresa_italiana  \\\n",
       "31575                                                  0          \n",
       "31576                                                  0          \n",
       "31578                                                  0          \n",
       "31579                                                  0          \n",
       "31581                                                  0          \n",
       "\n",
       "       prf_lav_Libero_professionista  prf_lav_Nel_settore_pubblico  \\\n",
       "31575                              0                             1   \n",
       "31576                              1                             0   \n",
       "31578                              0                             1   \n",
       "31579                              0                             1   \n",
       "31581                              1                             0   \n",
       "\n",
       "       prf_lav_Nel_terzo_settore_es.cooperative_sociali_enti_no_profit_etc.  \\\n",
       "31575                                                  0                      \n",
       "31576                                                  0                      \n",
       "31578                                                  0                      \n",
       "31579                                                  0                      \n",
       "31581                                                  0                      \n",
       "\n",
       "       prf_lav_Non_saprei  prf_lav_Preferisco_non_rispondere  reg_Abruzzo  \\\n",
       "31575                   0                                  0            0   \n",
       "31576                   0                                  0            0   \n",
       "31578                   0                                  0            0   \n",
       "31579                   0                                  0            0   \n",
       "31581                   0                                  0            0   \n",
       "\n",
       "       reg_Basilicata  reg_Calabria  reg_Campania  reg_Emilia_Romagna  \\\n",
       "31575               0             0             0                   0   \n",
       "31576               0             0             0                   0   \n",
       "31578               0             0             0                   0   \n",
       "31579               0             0             0                   1   \n",
       "31581               0             0             0                   0   \n",
       "\n",
       "       reg_Friuli_Venezia_Giulia  reg_Lazio  reg_Liguria  reg_Lombardia  \\\n",
       "31575                          0          0            0              0   \n",
       "31576                          0          0            0              1   \n",
       "31578                          0          0            0              0   \n",
       "31579                          0          0            0              0   \n",
       "31581                          1          0            0              0   \n",
       "\n",
       "       reg_Marche  reg_Molise  reg_Piemonte  reg_Puglia  reg_Sardegna  \\\n",
       "31575           0           0             0           0             0   \n",
       "31576           0           0             0           0             0   \n",
       "31578           0           0             0           0             0   \n",
       "31579           0           0             0           0             0   \n",
       "31581           0           0             0           0             0   \n",
       "\n",
       "       reg_Sicilia  reg_Toscana  reg_Trentino_Alto_Adige  reg_Umbria  \\\n",
       "31575            0            1                        0           0   \n",
       "31576            0            0                        0           0   \n",
       "31578            0            1                        0           0   \n",
       "31579            0            0                        0           0   \n",
       "31581            0            0                        0           0   \n",
       "\n",
       "       reg_Valle_Daosta  reg_Veneto  \n",
       "31575                 0           0  \n",
       "31576                 0           0  \n",
       "31578                 0           0  \n",
       "31579                 0           0  \n",
       "31581                 0           0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provo a rimuovere le righe con i valori Nan poiché solo 285\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3311, 188)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['m_p_int_voto'])\n",
    "y = df.m_p_int_voto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valori numerici delle etichette:\n",
      "[2 1 2 ... 2 0 0]\n",
      "Corrispondenza tra etichette originali e nuovi valori numerici:\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "M5S --> 1\n",
      "Dx/CDx --> 0\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "M5S --> 1\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Sx/CSx --> 2\n",
      "Dx/CDx --> 0\n",
      "Dx/CDx --> 0\n"
     ]
    }
   ],
   "source": [
    "# Assuming y contains your string labels\n",
    "label = ['Dx/CDx', 'M5S', 'Sx/CSx']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit LabelEncoder and transform y\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Now y_encoded contains integer labels\n",
    "print(\"Valori numerici delle etichette:\")\n",
    "print(y_encoded)\n",
    "\n",
    "# Conoscere la corrispondenza tra le etichette originali e i nuovi valori numerici\n",
    "print(\"Corrispondenza tra etichette originali e nuovi valori numerici:\")\n",
    "for label, value in zip(y, y_encoded):\n",
    "    print(f\"{label} --> {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier() \n",
    "\n",
    "parametri_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esegui la Grid Search sul set di addestramento\n",
    "y_pred = grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Stampa i parametri migliori trovati\n",
    "print(\"Migliori parametri:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Valuta il modello migliore sul set di test\n",
    "accuracy = grid_search_rf.best_estimator_.score(X_test, y_test)\n",
    "print(\"Accuratezza sul set di test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai il miglior modello\n",
    "miglior_modello = grid_search_rf.best_estimator_\n",
    "\n",
    "# Fai previsioni sul set di test\n",
    "y_pred = miglior_modello.predict(X_test)\n",
    "\n",
    "# Calcola la matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizza la matrice di confusione utilizzando seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matrice di Confusione\")\n",
    "plt.xlabel(\"Predetto\")\n",
    "plt.ylabel(\"Effettivo\")\n",
    "plt.show()\n",
    "\n",
    "# Visualizza il classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola le metriche totali\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Stampa le metriche totali\n",
    "print(\"Accuracy:\", round(accuracy,3))\n",
    "print(\"Precision:\", round(precision,3))\n",
    "print(\"Recall:\", round(recall,3))\n",
    "print(\"F1 Score:\", round(f1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_classifier = lgb.LGBMClassifier(boosting_type='gbdt', n_jobs=4, importance_type='split',random_state=42)\n",
    "\n",
    "\n",
    "parametri_grid_lgb = {\n",
    "            'learning_rate' : [0.1,0.01],\n",
    "             'num_leaves': [32, 64, 96],\n",
    "            'n_estimators' : [50, 100],\n",
    "            'max_depth' : [5, 10, 15],\n",
    "            'colsample_bytree' : [0.8,1],\n",
    "            'reg_alpha' : [0, 0.1],\n",
    "            'reg_lambda' : [1,5]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Migliori parametri: OrderedDict([('colsample_bytree', 0.3102745722485355), ('learning_rate', 0.03368851897306291), ('max_depth', 13), ('n_estimators', 135), ('num_leaves', 93), ('reg_alpha', 0.02354920960868235), ('reg_lambda', 0.01979707285897026)])\n"
     ]
    }
   ],
   "source": [
    "# Definisci la strategia di cross-validation con 10 fold stratificati\n",
    "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Definisci lo spazio degli iperparametri\n",
    "param_space = {\n",
    "    'learning_rate': Real(0.01, 0.5, 'log-uniform'),\n",
    "    'num_leaves': Integer(2, 100),\n",
    "    'n_estimators': Integer(50, 200),\n",
    "    'max_depth': Integer(1, 20),\n",
    "    'colsample_bytree': Real(0.1, 1.0, 'uniform'),\n",
    "    'reg_alpha': Real(0.0, 1.0, 'uniform'),\n",
    "    'reg_lambda': Real(0.0, 5.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Inizializza il classificatore LightGBM\n",
    "lgb_classifier = lgb.LGBMClassifier(boosting_type='gbdt', n_jobs=4, importance_type='split', random_state=42)\n",
    "\n",
    "# Inizializza la ricerca bayesiana\n",
    "opt = BayesSearchCV(\n",
    "    lgb_classifier,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=50, # Numero di iterazioni della ricerca bayesiana\n",
    "    cv=cv_strategy, # Utilizza la strategia di cross-validation definita\n",
    "    n_jobs=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Esegui la ricerca bayesiana\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Stampa i parametri migliori trovati\n",
    "print(\"Migliori parametri:\", opt.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BayesSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fai previsioni sul set di test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred_lgb \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Calcola la matrice di confusione\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_lgb)\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:519\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    518\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BayesSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# Fai previsioni sul set di test\n",
    "y_pred_lgb = opt.predict(X_test)\n",
    "\n",
    "# Calcola la matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred_lgb)\n",
    "\n",
    "\n",
    "# Visualizza la matrice di confusione utilizzando seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matrice di Confusione\")\n",
    "plt.xlabel(\"Predetto\")\n",
    "plt.ylabel(\"Effettivo\")\n",
    "plt.show()\n",
    "\n",
    "# Visualizza il classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n",
      "Precision: 0.68\n",
      "Recall: 0.69\n",
      "F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Calcola le metriche totali\n",
    "accuracy = accuracy_score(y_test, y_pred_lgb)\n",
    "precision = precision_score(y_test, y_pred_lgb, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_lgb, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_lgb, average='weighted')\n",
    "\n",
    "# Stampa le metriche totali\n",
    "print(\"Accuracy:\", round(accuracy,2))\n",
    "print(\"Precision:\", round(precision,2))\n",
    "print(\"Recall:\", round(recall,2))\n",
    "print(\"F1 Score:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.668    \u001b[0m | \u001b[0m0.4371   \u001b[0m | \u001b[0m4.754    \u001b[0m | \u001b[0m0.3687   \u001b[0m | \u001b[0m13.18    \u001b[0m | \u001b[0m2.404    \u001b[0m | \u001b[0m73.4     \u001b[0m | \u001b[0m0.6232   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m0.6669   \u001b[0m | \u001b[0m0.8796   \u001b[0m | \u001b[0m3.006    \u001b[0m | \u001b[0m0.357    \u001b[0m | \u001b[0m3.35     \u001b[0m | \u001b[0m9.729    \u001b[0m | \u001b[0m174.9    \u001b[0m | \u001b[0m0.6849   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m0.6794   \u001b[0m | \u001b[95m0.2636   \u001b[0m | \u001b[95m0.917    \u001b[0m | \u001b[95m0.1591   \u001b[0m | \u001b[95m11.92    \u001b[0m | \u001b[95m4.888    \u001b[0m | \u001b[95m93.68    \u001b[0m | \u001b[95m0.8447   \u001b[0m |\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m0.6877   \u001b[0m | \u001b[95m0.2255   \u001b[0m | \u001b[95m1.461    \u001b[0m | \u001b[95m0.1895   \u001b[0m | \u001b[95m10.75    \u001b[0m | \u001b[95m8.067    \u001b[0m | \u001b[95m79.95    \u001b[0m | \u001b[95m0.8057   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.6839   \u001b[0m | \u001b[0m0.6332   \u001b[0m | \u001b[0m0.2323   \u001b[0m | \u001b[0m0.3077   \u001b[0m | \u001b[0m5.899    \u001b[0m | \u001b[0m1.585    \u001b[0m | \u001b[0m192.3    \u001b[0m | \u001b[0m0.9863   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.685    \u001b[0m | \u001b[0m0.8276   \u001b[0m | \u001b[0m1.523    \u001b[0m | \u001b[0m0.05786  \u001b[0m | \u001b[0m14.63    \u001b[0m | \u001b[0m4.961    \u001b[0m | \u001b[0m68.31    \u001b[0m | \u001b[0m0.7981   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.6733   \u001b[0m | \u001b[0m0.1309   \u001b[0m | \u001b[0m4.547    \u001b[0m | \u001b[0m0.1368   \u001b[0m | \u001b[0m14.26    \u001b[0m | \u001b[0m3.805    \u001b[0m | \u001b[0m128.0    \u001b[0m | \u001b[0m0.8187   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.6756   \u001b[0m | \u001b[0m0.2664   \u001b[0m | \u001b[0m4.848    \u001b[0m | \u001b[0m0.3898   \u001b[0m | \u001b[0m18.97    \u001b[0m | \u001b[0m9.053    \u001b[0m | \u001b[0m139.7    \u001b[0m | \u001b[0m0.9687   \u001b[0m |\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m0.6903   \u001b[0m | \u001b[95m0.1796   \u001b[0m | \u001b[95m0.9799   \u001b[0m | \u001b[95m0.03216  \u001b[0m | \u001b[95m8.531    \u001b[0m | \u001b[95m4.498    \u001b[0m | \u001b[95m90.7     \u001b[0m | \u001b[95m0.9315   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.6835   \u001b[0m | \u001b[0m0.4211   \u001b[0m | \u001b[0m1.405    \u001b[0m | \u001b[0m0.2759   \u001b[0m | \u001b[0m5.396    \u001b[0m | \u001b[0m8.22     \u001b[0m | \u001b[0m61.18    \u001b[0m | \u001b[0m0.9948   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.6873   \u001b[0m | \u001b[0m0.4193   \u001b[0m | \u001b[0m1.57     \u001b[0m | \u001b[0m0.3168   \u001b[0m | \u001b[0m8.585    \u001b[0m | \u001b[0m4.622    \u001b[0m | \u001b[0m90.97    \u001b[0m | \u001b[0m0.738    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.6684   \u001b[0m | \u001b[0m0.3134   \u001b[0m | \u001b[0m0.6979   \u001b[0m | \u001b[0m0.01027  \u001b[0m | \u001b[0m5.986    \u001b[0m | \u001b[0m3.423    \u001b[0m | \u001b[0m90.47    \u001b[0m | \u001b[0m0.8668   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.679    \u001b[0m | \u001b[0m0.8378   \u001b[0m | \u001b[0m0.1302   \u001b[0m | \u001b[0m0.2577   \u001b[0m | \u001b[0m8.68     \u001b[0m | \u001b[0m4.541    \u001b[0m | \u001b[0m91.36    \u001b[0m | \u001b[0m0.8967   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.6801   \u001b[0m | \u001b[0m0.3276   \u001b[0m | \u001b[0m1.135    \u001b[0m | \u001b[0m0.3921   \u001b[0m | \u001b[0m7.95     \u001b[0m | \u001b[0m5.682    \u001b[0m | \u001b[0m89.58    \u001b[0m | \u001b[0m0.8162   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.6714   \u001b[0m | \u001b[0m0.6442   \u001b[0m | \u001b[0m2.124    \u001b[0m | \u001b[0m0.4385   \u001b[0m | \u001b[0m11.55    \u001b[0m | \u001b[0m7.86     \u001b[0m | \u001b[0m79.9     \u001b[0m | \u001b[0m0.7068   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.659    \u001b[0m | \u001b[0m0.2713   \u001b[0m | \u001b[0m0.636    \u001b[0m | \u001b[0m0.488    \u001b[0m | \u001b[0m9.583    \u001b[0m | \u001b[0m5.133    \u001b[0m | \u001b[0m90.7     \u001b[0m | \u001b[0m0.6383   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.6756   \u001b[0m | \u001b[0m0.7387   \u001b[0m | \u001b[0m3.157    \u001b[0m | \u001b[0m0.4029   \u001b[0m | \u001b[0m14.46    \u001b[0m | \u001b[0m8.603    \u001b[0m | \u001b[0m82.34    \u001b[0m | \u001b[0m0.984    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.6677   \u001b[0m | \u001b[0m0.2072   \u001b[0m | \u001b[0m4.752    \u001b[0m | \u001b[0m0.4845   \u001b[0m | \u001b[0m19.21    \u001b[0m | \u001b[0m9.324    \u001b[0m | \u001b[0m85.47    \u001b[0m | \u001b[0m0.7686   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.6714   \u001b[0m | \u001b[0m0.9787   \u001b[0m | \u001b[0m3.499    \u001b[0m | \u001b[0m0.4524   \u001b[0m | \u001b[0m10.56    \u001b[0m | \u001b[0m4.672    \u001b[0m | \u001b[0m86.07    \u001b[0m | \u001b[0m0.6716   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.685    \u001b[0m | \u001b[0m0.4855   \u001b[0m | \u001b[0m1.636    \u001b[0m | \u001b[0m0.2636   \u001b[0m | \u001b[0m19.68    \u001b[0m | \u001b[0m1.152    \u001b[0m | \u001b[0m183.6    \u001b[0m | \u001b[0m0.8078   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m0.6809   \u001b[0m | \u001b[0m0.1058   \u001b[0m | \u001b[0m2.415    \u001b[0m | \u001b[0m0.1525   \u001b[0m | \u001b[0m12.97    \u001b[0m | \u001b[0m5.598    \u001b[0m | \u001b[0m73.96    \u001b[0m | \u001b[0m0.9866   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.679    \u001b[0m | \u001b[0m0.8532   \u001b[0m | \u001b[0m0.3284   \u001b[0m | \u001b[0m0.3433   \u001b[0m | \u001b[0m5.785    \u001b[0m | \u001b[0m1.08     \u001b[0m | \u001b[0m191.9    \u001b[0m | \u001b[0m0.6564   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.6862   \u001b[0m | \u001b[0m0.3082   \u001b[0m | \u001b[0m1.762    \u001b[0m | \u001b[0m0.2121   \u001b[0m | \u001b[0m8.218    \u001b[0m | \u001b[0m4.413    \u001b[0m | \u001b[0m91.86    \u001b[0m | \u001b[0m0.8882   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.6831   \u001b[0m | \u001b[0m0.2126   \u001b[0m | \u001b[0m1.889    \u001b[0m | \u001b[0m0.2824   \u001b[0m | \u001b[0m9.865    \u001b[0m | \u001b[0m7.883    \u001b[0m | \u001b[0m80.54    \u001b[0m | \u001b[0m0.622    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.685    \u001b[0m | \u001b[0m0.5756   \u001b[0m | \u001b[0m1.177    \u001b[0m | \u001b[0m0.02526  \u001b[0m | \u001b[0m14.1     \u001b[0m | \u001b[0m4.905    \u001b[0m | \u001b[0m68.1     \u001b[0m | \u001b[0m0.9796   \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.6798   \u001b[0m | \u001b[0m0.3133   \u001b[0m | \u001b[0m2.547    \u001b[0m | \u001b[0m0.05879  \u001b[0m | \u001b[0m8.746    \u001b[0m | \u001b[0m4.376    \u001b[0m | \u001b[0m90.59    \u001b[0m | \u001b[0m0.6277   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.6764   \u001b[0m | \u001b[0m0.5616   \u001b[0m | \u001b[0m2.033    \u001b[0m | \u001b[0m0.4907   \u001b[0m | \u001b[0m8.318    \u001b[0m | \u001b[0m4.109    \u001b[0m | \u001b[0m91.24    \u001b[0m | \u001b[0m0.8174   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.6658   \u001b[0m | \u001b[0m0.9903   \u001b[0m | \u001b[0m0.9439   \u001b[0m | \u001b[0m0.4969   \u001b[0m | \u001b[0m14.71    \u001b[0m | \u001b[0m5.397    \u001b[0m | \u001b[0m68.01    \u001b[0m | \u001b[0m0.8397   \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m0.6862   \u001b[0m | \u001b[0m0.8541   \u001b[0m | \u001b[0m2.963    \u001b[0m | \u001b[0m0.1933   \u001b[0m | \u001b[0m7.734    \u001b[0m | \u001b[0m9.874    \u001b[0m | \u001b[0m112.7    \u001b[0m | \u001b[0m0.9016   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m0.676    \u001b[0m | \u001b[0m0.3961   \u001b[0m | \u001b[0m3.617    \u001b[0m | \u001b[0m0.178    \u001b[0m | \u001b[0m13.36    \u001b[0m | \u001b[0m7.68     \u001b[0m | \u001b[0m53.43    \u001b[0m | \u001b[0m0.6789   \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m0.6703   \u001b[0m | \u001b[0m0.4632   \u001b[0m | \u001b[0m3.334    \u001b[0m | \u001b[0m0.4985   \u001b[0m | \u001b[0m12.26    \u001b[0m | \u001b[0m2.819    \u001b[0m | \u001b[0m168.0    \u001b[0m | \u001b[0m0.727    \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m0.6831   \u001b[0m | \u001b[0m0.6333   \u001b[0m | \u001b[0m1.092    \u001b[0m | \u001b[0m0.1772   \u001b[0m | \u001b[0m9.254    \u001b[0m | \u001b[0m5.005    \u001b[0m | \u001b[0m199.4    \u001b[0m | \u001b[0m0.8314   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m0.6794   \u001b[0m | \u001b[0m0.2456   \u001b[0m | \u001b[0m0.1378   \u001b[0m | \u001b[0m0.2605   \u001b[0m | \u001b[0m5.513    \u001b[0m | \u001b[0m1.683    \u001b[0m | \u001b[0m192.1    \u001b[0m | \u001b[0m0.7085   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m0.6782   \u001b[0m | \u001b[0m0.6185   \u001b[0m | \u001b[0m2.631    \u001b[0m | \u001b[0m0.2456   \u001b[0m | \u001b[0m3.195    \u001b[0m | \u001b[0m5.36     \u001b[0m | \u001b[0m125.6    \u001b[0m | \u001b[0m0.6119   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m0.6786   \u001b[0m | \u001b[0m0.8249   \u001b[0m | \u001b[0m4.947    \u001b[0m | \u001b[0m0.103    \u001b[0m | \u001b[0m5.649    \u001b[0m | \u001b[0m3.807    \u001b[0m | \u001b[0m111.2    \u001b[0m | \u001b[0m0.7603   \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m0.6862   \u001b[0m | \u001b[0m0.9406   \u001b[0m | \u001b[0m3.442    \u001b[0m | \u001b[0m0.3361   \u001b[0m | \u001b[0m17.56    \u001b[0m | \u001b[0m3.946    \u001b[0m | \u001b[0m50.27    \u001b[0m | \u001b[0m0.8589   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m0.6869   \u001b[0m | \u001b[0m0.3012   \u001b[0m | \u001b[0m2.08     \u001b[0m | \u001b[0m0.3462   \u001b[0m | \u001b[0m11.02    \u001b[0m | \u001b[0m5.846    \u001b[0m | \u001b[0m78.36    \u001b[0m | \u001b[0m0.9149   \u001b[0m |\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m0.6764   \u001b[0m | \u001b[0m0.241    \u001b[0m | \u001b[0m3.453    \u001b[0m | \u001b[0m0.2276   \u001b[0m | \u001b[0m17.71    \u001b[0m | \u001b[0m4.584    \u001b[0m | \u001b[0m50.56    \u001b[0m | \u001b[0m0.8865   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m0.6805   \u001b[0m | \u001b[0m0.5338   \u001b[0m | \u001b[0m4.898    \u001b[0m | \u001b[0m0.3728   \u001b[0m | \u001b[0m15.56    \u001b[0m | \u001b[0m9.396    \u001b[0m | \u001b[0m121.7    \u001b[0m | \u001b[0m0.9357   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m0.6801   \u001b[0m | \u001b[0m0.6967   \u001b[0m | \u001b[0m3.215    \u001b[0m | \u001b[0m0.4629   \u001b[0m | \u001b[0m10.71    \u001b[0m | \u001b[0m6.91     \u001b[0m | \u001b[0m112.9    \u001b[0m | \u001b[0m0.9385   \u001b[0m |\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m0.6707   \u001b[0m | \u001b[0m0.3469   \u001b[0m | \u001b[0m3.959    \u001b[0m | \u001b[0m0.4121   \u001b[0m | \u001b[0m19.6     \u001b[0m | \u001b[0m2.199    \u001b[0m | \u001b[0m90.82    \u001b[0m | \u001b[0m0.7674   \u001b[0m |\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m0.6696   \u001b[0m | \u001b[0m0.4486   \u001b[0m | \u001b[0m1.322    \u001b[0m | \u001b[0m0.3448   \u001b[0m | \u001b[0m14.22    \u001b[0m | \u001b[0m4.326    \u001b[0m | \u001b[0m68.44    \u001b[0m | \u001b[0m0.9663   \u001b[0m |\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m0.6903   \u001b[0m | \u001b[0m0.5768   \u001b[0m | \u001b[0m2.772    \u001b[0m | \u001b[0m0.2146   \u001b[0m | \u001b[0m17.4     \u001b[0m | \u001b[0m3.753    \u001b[0m | \u001b[0m50.06    \u001b[0m | \u001b[0m0.8095   \u001b[0m |\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m0.6711   \u001b[0m | \u001b[0m0.8662   \u001b[0m | \u001b[0m2.991    \u001b[0m | \u001b[0m0.3669   \u001b[0m | \u001b[0m16.7     \u001b[0m | \u001b[0m3.646    \u001b[0m | \u001b[0m50.24    \u001b[0m | \u001b[0m0.7318   \u001b[0m |\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m0.6782   \u001b[0m | \u001b[0m0.1405   \u001b[0m | \u001b[0m0.7684   \u001b[0m | \u001b[0m0.2244   \u001b[0m | \u001b[0m13.83    \u001b[0m | \u001b[0m2.119    \u001b[0m | \u001b[0m86.92    \u001b[0m | \u001b[0m0.6232   \u001b[0m |\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m0.6722   \u001b[0m | \u001b[0m0.5655   \u001b[0m | \u001b[0m1.825    \u001b[0m | \u001b[0m0.48     \u001b[0m | \u001b[0m8.66     \u001b[0m | \u001b[0m4.161    \u001b[0m | \u001b[0m90.69    \u001b[0m | \u001b[0m0.6885   \u001b[0m |\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m0.6775   \u001b[0m | \u001b[0m0.6488   \u001b[0m | \u001b[0m4.829    \u001b[0m | \u001b[0m0.1282   \u001b[0m | \u001b[0m4.802    \u001b[0m | \u001b[0m2.988    \u001b[0m | \u001b[0m153.3    \u001b[0m | \u001b[0m0.8025   \u001b[0m |\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m0.6726   \u001b[0m | \u001b[0m0.9735   \u001b[0m | \u001b[0m1.275    \u001b[0m | \u001b[0m0.4596   \u001b[0m | \u001b[0m9.066    \u001b[0m | \u001b[0m3.669    \u001b[0m | \u001b[0m177.8    \u001b[0m | \u001b[0m0.6694   \u001b[0m |\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m0.6756   \u001b[0m | \u001b[0m0.5082   \u001b[0m | \u001b[0m2.454    \u001b[0m | \u001b[0m0.4186   \u001b[0m | \u001b[0m17.43    \u001b[0m | \u001b[0m4.236    \u001b[0m | \u001b[0m78.22    \u001b[0m | \u001b[0m0.9487   \u001b[0m |\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m0.6764   \u001b[0m | \u001b[0m0.9484   \u001b[0m | \u001b[0m3.225    \u001b[0m | \u001b[0m0.0157   \u001b[0m | \u001b[0m15.56    \u001b[0m | \u001b[0m9.475    \u001b[0m | \u001b[0m141.0    \u001b[0m | \u001b[0m0.8286   \u001b[0m |\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m0.6877   \u001b[0m | \u001b[0m0.5091   \u001b[0m | \u001b[0m1.063    \u001b[0m | \u001b[0m0.02338  \u001b[0m | \u001b[0m14.2     \u001b[0m | \u001b[0m3.587    \u001b[0m | \u001b[0m160.2    \u001b[0m | \u001b[0m0.9678   \u001b[0m |\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m0.6677   \u001b[0m | \u001b[0m0.4233   \u001b[0m | \u001b[0m2.901    \u001b[0m | \u001b[0m0.3877   \u001b[0m | \u001b[0m6.667    \u001b[0m | \u001b[0m9.744    \u001b[0m | \u001b[0m108.8    \u001b[0m | \u001b[0m0.8613   \u001b[0m |\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m0.6756   \u001b[0m | \u001b[0m0.8992   \u001b[0m | \u001b[0m4.651    \u001b[0m | \u001b[0m0.2855   \u001b[0m | \u001b[0m18.46    \u001b[0m | \u001b[0m7.442    \u001b[0m | \u001b[0m61.69    \u001b[0m | \u001b[0m0.6777   \u001b[0m |\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m0.6692   \u001b[0m | \u001b[0m0.9031   \u001b[0m | \u001b[0m1.648    \u001b[0m | \u001b[0m0.3652   \u001b[0m | \u001b[0m15.05    \u001b[0m | \u001b[0m2.783    \u001b[0m | \u001b[0m157.3    \u001b[0m | \u001b[0m0.6205   \u001b[0m |\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m0.6771   \u001b[0m | \u001b[0m0.731    \u001b[0m | \u001b[0m4.359    \u001b[0m | \u001b[0m0.3554   \u001b[0m | \u001b[0m9.307    \u001b[0m | \u001b[0m6.139    \u001b[0m | \u001b[0m82.92    \u001b[0m | \u001b[0m0.6848   \u001b[0m |\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m0.6707   \u001b[0m | \u001b[0m0.5774   \u001b[0m | \u001b[0m3.152    \u001b[0m | \u001b[0m0.495    \u001b[0m | \u001b[0m7.602    \u001b[0m | \u001b[0m6.994    \u001b[0m | \u001b[0m174.1    \u001b[0m | \u001b[0m0.836    \u001b[0m |\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m0.6764   \u001b[0m | \u001b[0m0.7371   \u001b[0m | \u001b[0m3.922    \u001b[0m | \u001b[0m0.2807   \u001b[0m | \u001b[0m12.09    \u001b[0m | \u001b[0m6.088    \u001b[0m | \u001b[0m131.0    \u001b[0m | \u001b[0m0.8881   \u001b[0m |\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m0.6805   \u001b[0m | \u001b[0m0.9415   \u001b[0m | \u001b[0m4.783    \u001b[0m | \u001b[0m0.2224   \u001b[0m | \u001b[0m5.917    \u001b[0m | \u001b[0m9.105    \u001b[0m | \u001b[0m183.4    \u001b[0m | \u001b[0m0.8057   \u001b[0m |\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m0.6865   \u001b[0m | \u001b[0m0.755    \u001b[0m | \u001b[0m2.482    \u001b[0m | \u001b[0m0.2567   \u001b[0m | \u001b[0m16.38    \u001b[0m | \u001b[0m2.655    \u001b[0m | \u001b[0m64.13    \u001b[0m | \u001b[0m0.7115   \u001b[0m |\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m0.6733   \u001b[0m | \u001b[0m0.3474   \u001b[0m | \u001b[0m3.35     \u001b[0m | \u001b[0m0.3197   \u001b[0m | \u001b[0m6.603    \u001b[0m | \u001b[0m3.83     \u001b[0m | \u001b[0m99.73    \u001b[0m | \u001b[0m0.707    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.73       219\n",
      "           1       0.60      0.33      0.43       174\n",
      "           2       0.74      0.80      0.77       270\n",
      "\n",
      "    accuracy                           0.68       663\n",
      "   macro avg       0.66      0.65      0.64       663\n",
      "weighted avg       0.67      0.68      0.67       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Funzione di ottimizzazione\n",
    "def xgb_evaluate(max_depth, learning_rate, n_estimators, gamma, min_child_weight, subsample, colsample_bytree):\n",
    "    params = {\n",
    "        'max_depth': int(max_depth),\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators': int(n_estimators),\n",
    "        'gamma': gamma,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3,  # Modifica secondo il numero delle tue classi\n",
    "        'n_jobs': 4,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(**params)\n",
    "    cv = StratifiedKFold(n_splits=10)\n",
    "    scores = cross_val_score(xgb_model, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "    return scores.mean()\n",
    "\n",
    "# Definire il dominio di ricerca\n",
    "pbounds = {\n",
    "    'max_depth': (3, 20),\n",
    "    'learning_rate': (0.01, 0.5),\n",
    "    'n_estimators': (50, 200),\n",
    "    'gamma': (0, 5),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'subsample': (0.6, 1.0),\n",
    "    'colsample_bytree': (0.1, 1.0)\n",
    "}\n",
    "\n",
    "\n",
    "# Ottimizzazione bayesiana\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_evaluate,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=50)\n",
    "\n",
    "# Migliori parametri\n",
    "best_params = optimizer.max['params']\n",
    "best_params['max_depth'] = int(best_params['max_depth'])\n",
    "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "\n",
    "# Addestrare il modello con i migliori parametri\n",
    "best_xgb = xgb.XGBClassifier(\n",
    "    **best_params,\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,  # Modifica secondo il numero delle tue classi\n",
    "    n_jobs=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Fare previsioni sul set di test\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Calcolare la matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizzare la matrice di confusione utilizzando seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matrice di Confusione\")\n",
    "plt.xlabel(\"Predetto\")\n",
    "plt.ylabel(\"Effettivo\")\n",
    "plt.show()\n",
    "\n",
    "# Visualizzare il classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68\n",
      "Precision: 0.67\n",
      "Recall: 0.68\n",
      "F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Calcola le metriche totali\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Stampa le metriche totali\n",
    "print(\"Accuracy:\", round(accuracy,2))\n",
    "print(\"Precision:\", round(precision,2))\n",
    "print(\"Recall:\", round(recall,2))\n",
    "print(\"F1 Score:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m_p_r_eta</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>m_ac_italia_ipartecipazioneIn_missioniMilitari...</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>m_ac_chiesa_nonDovrebbe_condizionare_stato.1</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>m_ac_valori_resistenza_altra_epoca</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>m_ac_lavorare_importante_postoStabile_no</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>reg_Abruzzo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>reg_Basilicata</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>reg_Umbria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>reg_Valle_Daosta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>reg_Marche</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Feature  Importance\n",
       "1                                            m_p_r_eta        1105\n",
       "93   m_ac_italia_ipartecipazioneIn_missioniMilitari...         450\n",
       "43        m_ac_chiesa_nonDovrebbe_condizionare_stato.1         398\n",
       "19                  m_ac_valori_resistenza_altra_epoca         391\n",
       "94            m_ac_lavorare_importante_postoStabile_no         366\n",
       "..                                                 ...         ...\n",
       "167                                        reg_Abruzzo           0\n",
       "168                                     reg_Basilicata           0\n",
       "184                                         reg_Umbria           0\n",
       "185                                   reg_Valle_Daosta           0\n",
       "176                                         reg_Marche           0\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizza l'importanza delle feature\n",
    "importances = miglior_modello.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "set()\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Numero di feature: 187, Accuratezza: 0.6847662141779789\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "{'reg_Molise'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 48\u001b[0m\n\u001b[0;32m     38\u001b[0m opt \u001b[38;5;241m=\u001b[39m BayesSearchCV(\n\u001b[0;32m     39\u001b[0m     lgb_classifier,\n\u001b[0;32m     40\u001b[0m     search_spaces\u001b[38;5;241m=\u001b[39mparam_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Esegui la ricerca bayesiana\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_X_train_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Salva i risultati della cross-validation\u001b[39;00m\n\u001b[0;32m     51\u001b[0m cross_validations[i] \u001b[38;5;241m=\u001b[39m opt\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\skopt\\searchcv.py:538\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m     )\n\u001b[1;32m--> 538\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\skopt\\searchcv.py:595\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    593\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 595\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\skopt\\searchcv.py:449\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[0;32m    447\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m--> 449\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\lucap\\anaconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Definisci la strategia di cross-validation con 10 fold stratificati\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Definisci lo spazio degli iperparametri\n",
    "param_space = {\n",
    "    'learning_rate': Real(0.01, 0.5, 'log-uniform'),\n",
    "    'num_leaves': Integer(2, 100),\n",
    "    'n_estimators': Integer(50, 200),\n",
    "    'max_depth': Integer(1, 20),\n",
    "    'colsample_bytree': Real(0.1, 1.0, 'uniform'),\n",
    "    'reg_alpha': Real(0.0, 1.0, 'uniform'),\n",
    "    'reg_lambda': Real(0.0, 5.0, 'uniform')\n",
    "}\n",
    "\n",
    "# Inizializza il classificatore LightGBM\n",
    "lgb_classifier = lgb.LGBMClassifier(boosting_type='gbdt', n_jobs=4, importance_type='split', random_state=42)\n",
    "\n",
    "cross_validations = {}\n",
    "df_cross_validations = pd.DataFrame()\n",
    "\n",
    "df_X_train_full = X_train.copy()\n",
    "df_X_test_full = X_test.copy()\n",
    "\n",
    "acc_scores = {'n_features': [], 'acc_score': []}\n",
    "\n",
    "for i in range(len(df_X_train_full.columns), 10, -1):\n",
    "    rfe = RFE(lgb_classifier, n_features_to_select=i)\n",
    "    rfe = rfe.fit(df_X_train_full, y_train.ravel())\n",
    "\n",
    "    print(set(rfe.feature_names_in_).difference(rfe.get_feature_names_out()))\n",
    "    X_train_transformed = rfe.transform(df_X_train_full)\n",
    "    X_test_transformed = rfe.transform(df_X_test_full)\n",
    "    \n",
    "    df_X_train_full = pd.DataFrame(X_train_transformed, columns=rfe.get_feature_names_out())\n",
    "    df_X_test_full = pd.DataFrame(X_test_transformed, columns=rfe.get_feature_names_out())\n",
    "\n",
    "    # Inizializza la ricerca bayesiana\n",
    "    opt = BayesSearchCV(\n",
    "        lgb_classifier,\n",
    "        search_spaces=param_space,\n",
    "        n_iter=40,  # Numero di iterazioni della ricerca bayesiana\n",
    "        cv=cv_strategy,  # Utilizza la strategia di cross-validation definita\n",
    "        n_jobs=4,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Esegui la ricerca bayesiana\n",
    "    opt.fit(df_X_train_full, y_train.ravel())\n",
    "\n",
    "    # Salva i risultati della cross-validation\n",
    "    cross_validations[i] = opt\n",
    "    _tmp_cv = pd.DataFrame(opt.cv_results_)\n",
    "    _tmp_cv['n_features'] = i\n",
    "    _tmp_cv['features'] = ','.join([column for column in rfe.get_feature_names_out()])\n",
    "    \n",
    "    df_cross_validations = pd.concat([df_cross_validations, _tmp_cv], ignore_index=True)\n",
    "    \n",
    "    # Estrai il miglior modello e fai previsioni sul set di test\n",
    "    miglior_modello = opt.best_estimator_\n",
    "    miglior_modello.fit(df_X_train_full, y_train.ravel())\n",
    "    y_pred = miglior_modello.predict(df_X_test_full)  \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Numero di feature: {i}, Accuratezza: {accuracy}\")\n",
    "    acc_scores['n_features'].append(i)\n",
    "    acc_scores['acc_score'].append(accuracy)\n",
    "\n",
    "# Visualizza i risultati\n",
    "print(\"Risultati Cross-Validation:\")\n",
    "print(df_cross_validations)\n",
    "\n",
    "# Visualizza l'accuratezza in funzione del numero di feature\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(acc_scores['n_features'], acc_scores['acc_score'], marker='o')\n",
    "plt.xlabel('Numero di Feature')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.title('Accuratezza in funzione del numero di feature')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Salva i risultati in un file CSV (opzionale)\n",
    "df_cross_validations.to_csv('cross_validation_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'reg_Valle_Daosta'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'reg_Molise'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 784\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 185\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'prf_lav_Dipendente_di_una_cooperativa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 184\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'reg_Basilicata'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 780\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 780\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 183\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'prf_lav_Preferisco_non_rispondere'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 778\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'reg_Umbria'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 776\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'reg_Abruzzo'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 774\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'reg_Marche'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 772\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 179\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6726998491704375\n",
      "{'reg_Trentino_Alto_Adige'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 178\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 178\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_p_nascita_in_italia_genitori'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 177\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'prf_lav_Nel_terzo_settore_es.cooperative_sociali_enti_no_profit_etc.'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 176\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'reg_Friuli_Venezia_Giulia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'reg_Liguria'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 174\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 762\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 174\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'reg_Sardegna'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 173\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 760\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 173\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'reg_Toscana'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 758\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'reg_Calabria'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 756\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 171\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'reg_Emilia_Romagna'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 754\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 170\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 754\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 170\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'prf_lav_Non_saprei'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 169\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'prf_lav_Dipendente_di_una_multinazionale'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 750\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'prf_lav_Dipendente_di_una_grande_impresa_italiana'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 167\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 167\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'reg_Piemonte'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 166\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 166\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'reg_Veneto'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 744\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 165\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'prf_lav_Dipendente_di_una_piccola/media_impresa_italiana'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 742\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 742\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 164\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6953242835595776\n",
      "{'reg_Lazio'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 740\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 163\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6923076923076923\n",
      "{'m_TREND_52_SOLIDARIETA'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 162\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 738\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 162\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_TREND_46_SPERIMENTAZIONE_GENETICA'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 161\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 736\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 161\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_TREND_15_INADEGUATEZZA_INDIVIDUALE'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 160\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 160\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_TREND_58_CONFRONTO_CON_LA_GENERAZIONE_PASSATA'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 732\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 159\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_TREND_31_EPOCALITA_E_FUTURO_SMARRITO_nostalgico_nei_confronti_del_passato'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 158\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 730\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 158\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_TREND_29_RADICALIZZAZIONE_crede_nel_compromesso'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 157\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 728\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 157\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_TREND_35_EUROPA_E_MODERNITA_crede_che_lentrata_in_Europa_abbia_modernizzato_il_nostro_paese'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 726\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 156\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 726\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 156\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_TREND_28_GIOVANI_fiducia_alle_nuove_generazioni'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 155\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 724\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 155\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_TREND_1_PATRIA_E_UNITA_NAZIONALE_credono_ancora_nellla_patria'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 722\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 722\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 154\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'prf_lav_Avviare_una_sua_attivita_imprenditoriale_azienda_negozio_etc.'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 153\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 720\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 153\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_TREND_54_DISORIENTAMENTO'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 718\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 152\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 718\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 152\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_TREND_39_SCUOLA_E_FORMAZIONE_formazione_e_una_priorita_del_Paese'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 716\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 151\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 716\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 151\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_op_situazEconomic_propria_ultimi10anni'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 713\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 713\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 150\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'m_TREND_37_SCIENZA_FECONDA_crede_nelle_potenzialita_dellinnovazione_scientifica'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 149\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 149\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6923076923076923\n",
      "{'m_sesso'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 709\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 709\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 148\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'reg_Campania'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 707\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 147\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 707\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 147\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'prf_lav_Libero_professionista'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 705\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 146\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 705\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 146\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'reg_Puglia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 703\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 145\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 703\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 145\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_p_pubblico_privato'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 144\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 701\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 144\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'reg_Lombardia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 699\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'prf_lav_Nel_settore_pubblico'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 697\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 697\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_op_situazEconomic_futura'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 694\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 141\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 694\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 141\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_TREND_7_SFIDUCIA_NEL_SISTEMA_DEI_PARTI'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 692\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 140\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 692\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 140\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'reg_Sicilia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 690\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 139\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 690\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 139\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6726998491704375\n",
      "{'m_TREND_53_INCLUSI_ED_ESCLUSI_si_sente_pienamente_parte_della_societa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 688\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 138\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 688\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 138\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_op_scuolaPubblica_ultimiAnni'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 685\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 137\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 685\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 137\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_op_come_reddito_consenteDiVivere'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 682\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 136\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 682\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 136\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'m_p_lettura_quotidiani'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 680\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 680\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_TREND_27_SINDACATO_crede_ancora_nel_modello_sindacale'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 134\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 134\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'m_TREND_56_TERRITORIALITA_2009_individua_nella_difesa_della_territorialita_larma_vicente'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 133\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6998491704374057\n",
      "{'m_op_attenzione_personeNelTerritorio_verso_impegnoTutelaAmbienteNatura'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 672\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 132\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 672\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 132\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_op_attenzione_personeNelTerritorio_verso_risparmioEnergetico'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 131\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 668\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 131\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_TREND_50_IL_MODELLO_IMPRESA_individua_nellimpresa_modello_economico_vincente'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 666\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 130\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 666\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 130\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_modernizz_vs_regress_Paese'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 663\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_TREND_19_SICUREZZA_-_CRIMINALITA_si_sente_al_sicuro'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 661\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 128\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_op_attenzione_personeNelTerritorio_verso_sistemiEnergieAlternative'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 657\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 127\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 657\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 127\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.7013574660633484\n",
      "{'m_ac_generazionePrecedente_maggiore_sicurezzaLavorativa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 652\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 126\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 652\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 126\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6923076923076923\n",
      "{'m_op_disorientamento_realta_quotidiana_vs_3anniFa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 649\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 125\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 649\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 125\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_ac_scoperte_scientificTecnol_rendono_vita_piuFacile'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 124\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 644\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 124\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_p_radio_ore'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 641\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 123\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 641\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 123\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_p_frequenza_concerti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 638\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 122\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 638\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 122\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_attenzione_personeNelTerritorio_verso_acquaistoProdottiEcosostenibili'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_op_fiducia_nei_familiari_con_cui_convive'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 120\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 629\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 120\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6968325791855203\n",
      "{'m_op_legge_aborto_1987'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 626\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 119\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 626\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 119\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.702865761689291\n",
      "{'m_ac_mediazione_nonRisolve_problemi'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 621\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 118\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_TREND_10_MERITO_propende_per_la_meritocrazia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 619\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_p_frequenza_palestra_sport'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 616\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 116\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 616\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 116\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6953242835595776\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_dei_familiari_con_cui_convive'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 611\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 115\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 611\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 115\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_op_impegnoPersone_in_tutelaAmbiente'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 606\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 114\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 606\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 114\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_attenzione_personeNelTerritorio_verso_controlloQualitaProvenienzaAlimenti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 602\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 602\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_op_attenzione_personeNelTerritorio_verso_ricicloRaccoltaDiff'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 598\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 598\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_p_r_ampiezza6'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 594\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 111\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 594\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 111\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_op_favore_eutanasia_a_determinate_condizioni'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 590\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 590\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 110\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_op_fiducia_negli_italiani'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 585\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 109\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 585\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 109\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.698340874811463\n",
      "{'m_ac_globaliz_inarrestabile'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 580\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 580\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_p_frequenza_cinema'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 577\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 577\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_ac_impegnoSocialeGiovani_sempreMenoForte'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 572\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 572\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_p_scolarita'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 568\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 568\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 105\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.669683257918552\n",
      "{'m_ac_percez_inadeguatezza_da_velocitaCambiamento'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 563\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 104\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_p_frequenza_mostre'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 560\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 103\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 560\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 103\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_ac_ricercaCompromesso_faMarcire_situazioni'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 555\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 102\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_ac_aumento_competizione_con_piuPreparati'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 550\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 550\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 101\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.669683257918552\n",
      "{'m_p_frequenza_teatro'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 547\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 547\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 100\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'m_ac_valore_attuale_patria'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 99\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.669683257918552\n",
      "{'m_ac_scuola_deveEssere_severa_selettiva_meritocratica'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 537\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 98\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 537\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 98\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_valorizzare_scuoleEccellenza'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 532\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 532\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 97\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_op_importanza_nellaSocieta_solidarieta'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 527\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 96\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 527\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 96\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_op_contributoDelSingolo_salvaguardia_ambiente'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 522\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 95\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 522\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 95\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_ac_generazionePrecedente_maggiore_mobilitaEconomicoSociale'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 517\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_governatori_scegliere_senzaBadareOpposizione'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 93\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_ac_nuoveGenerazioni_miglioreranno_mondo'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 507\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 92\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 507\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 92\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_ScuolaEFormazione_principaleProblema_delPaese'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 91\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_ac_generazionePrecedente_piuFelice'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 497\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 497\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 90\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_aumento_stress_competizione'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 492\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 492\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_TREND_8_VALORI_FONDATIVI_mantiene_radicati_i_valori'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 490\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 490\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6802413273001509\n",
      "{'m_ac_italia_paeseInDeclino'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 485\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 485\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 87\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_dei_suoi_parenti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 480\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 480\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 86\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_passato_vivereMeglio_ancheSePiuPoveri'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 475\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 475\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_ac_giovaniOggi_incapaci_fareSacrifici'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 470\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 470\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 84\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6953242835595776\n",
      "{'m_ac_comprareItaliano_perFronteggiare_crisi'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 465\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 465\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 83\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6968325791855203\n",
      "{'m_op_sviluppo_sensoCivico_Paese'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 460\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 460\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 82\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_giovani_di_30anniFa_miglioriDiOggi'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 455\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 455\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 81\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_ac_scienza_problemi_piuChe_benefici'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 450\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 450\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_degli_amici_che_fanno_parte_della_sua_rete_social_network'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 445\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 445\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_ac_sacrificioEconomico_per_migliorare_ScuolaUniversitaRicerca'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 440\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 440\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 78\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_fiducia_nei_vicini_di_casa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 435\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 435\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 77\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_importanza_farParte_comunita'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 430\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 430\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 76\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_ac_sentirsiSpesso_solo_isolato'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 425\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 425\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6953242835595776\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_degli_amici_e_conoscenti_dei_suoi_familiari'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 420\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 420\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'m_ac_modelloImprenditorialePrivato_unico_meritocratico'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 415\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 415\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 73\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_dei_vicini_di_casa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 410\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 410\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6923076923076923\n",
      "{'m_ac_sperimentazioniGenetiche_piuRischi_cheVantaggi'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 405\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 405\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6832579185520362\n",
      "{'m_ac_privilegio_lavoratori_sett_pubblico'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 400\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 400\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_op_disorientamento_veros_realta_quotidiana'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 395\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 395\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'m_ac_musulmaniInItalia_dirittoReligione_inScuole'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 68\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_ac_immigrati_devono_adeguarsi'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 385\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 385\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 67\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 380\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 380\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_ac_guerre_talvolta_maleNecessario.1'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 375\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 65\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'m_ac_generazioniFuture_vivrannoPeggio'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 370\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 370\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 64\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_ac_importanza_partiti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 365\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 63\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 365\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 63\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_degli_italiani'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 360\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 62\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_modelloImprenditorialePrivato_unico_garantireEquita'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 355\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 61\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'m_ac_validita_insegnamChiesa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 350\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 350\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 60\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_TREND_30_ISLAM_tolleranza_e_fiducia_nei_confronti_dell_Islam'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6968325791855203\n",
      "{'m_ac_generazionePrecedente_migliore_qualitaVita'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 343\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 343\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6953242835595776\n",
      "{'m_op_peso_volontariato_in_economiaPaese'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_ac_vantaggi_globalizz_economie_mercati'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 333\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 56\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 333\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 56\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_op_fiducia_negli_amici_e_conoscenti_dei_suoi_familiari'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 328\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'m_ac_attuale_classeInsegnante_incompetente'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 323\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 323\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_op_importanza_nellaSocieta_altruismo'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 318\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 318\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6817496229260935\n",
      "{'m_ac_meglio_uguaglianza_vs_merito_singolo'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 313\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 313\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 52\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'m_ac_problemi_eticiMorali_sperimentazioneGenetica'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 308\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 308\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6968325791855203\n",
      "{'m_op_ottica_di_beneComune_italia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_ac_nonSicuro_doveVive'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 298\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 298\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_ac_dazi_su_produzioni_importanti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 293\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 293\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_TREND_26_NAZIONE_EUROPA'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 291\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 47\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 286\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 286\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 46\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.698340874811463\n",
      "{'m_op_rinuncie_per_postoStabile'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 281\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 281\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_ac_immigrati_nonRispettano_regoleDelloStareInsieme'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 276\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 276\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_affidamento_pubblica_tecnici'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 271\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 271\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'m_ac_diminuzione_ruolo_partiti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 266\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'m_ac_lavorare_importante_postoStabile_no'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 261\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 261\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_repressione_unicaArma_vs_crimin'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 256\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 256\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6923076923076923\n",
      "{'m_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 251\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 251\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_op_ottica_di_beneComune_comuneResidenza'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 246\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 246\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_ac_immigrati_diritto_voto'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 241\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 241\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6742081447963801\n",
      "{'m_op_aiutoReciproco_inCasoDiBisogno_dei_colleghi_di_lavoro'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 236\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 236\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_dovere_difesa_produzPaese_vs_globaliz'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_ac_badare_propriInteressi_perSopravvivere'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 226\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 226\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6892911010558069\n",
      "{'m_ac_crimin_diventera_incontenibile'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 216\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 216\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_attivita_associazionismo_Italia'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 211\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 211\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.7013574660633484\n",
      "{'m_ac_difesa_scuolaPubblica_insensata'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 206\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 206\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_op_fiducia_nei_suoi_parenti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 201\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 201\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_op_fiducia_negli_amici_che_fanno_parte_della_sua_rete_social_network'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 196\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 196\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_op_importanza_nellaSocieta_mutualismo'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 191\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 191\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'m_ac_uguaglianza_sociale_frena_individui'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'m_ac_lavoroNord_consente_diEssere_alPasso_con_UE'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6787330316742082\n",
      "{'m_ac_societa_troppoPermissiva_gay'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 176\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.693815987933635\n",
      "{'m_ac_immigrati_rubano_lavoro'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 171\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6726998491704375\n",
      "{'m_ac_propensioneRischio_italia_vs_europa'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6772247360482655\n",
      "{'m_op_fiducia_nei_colleghi_di_lavoro'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 161\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 161\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 156\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 156\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_op_partecipazione_in_UE'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6907993966817496\n",
      "{'m_ac_sindacato_ancoraUtile'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 148\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6968325791855203\n",
      "{'m_TREND_53_IL_PERICOLO_POPULISTA'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 146\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 146\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6877828054298643\n",
      "{'m_TREND_25_IMMIGRAZIONE_atteggiamento_POSITIVO_nei_confronti_degli_immigrati'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 144\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 144\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6847662141779789\n",
      "{'m_ac_testamento_biologico'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 139\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 139\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6862745098039216\n",
      "{'m_ac_troppo_focus_uguaglianza_vs_merito'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 134\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 134\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6711915535444947\n",
      "{'m_ac_troppo_allarmismo_ecologia_inquinamento'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n",
      "{'m_ac_religioneIslamica_pericoloPerTutti'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 124\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 124\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.665158371040724\n",
      "{'m_ac_modernizzazioneItalia_grazie_UE'}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 119\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 119\n",
      "[LightGBM] [Info] Number of data points in the train set: 2648, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.107336\n",
      "[LightGBM] [Info] Start training from score -1.337648\n",
      "[LightGBM] [Info] Start training from score -0.898697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.6757164404223228\n"
     ]
    }
   ],
   "source": [
    "cross_validations = {}\n",
    "\n",
    "df_cross_validations = pd.DataFrame()\n",
    "\n",
    "df_X_train_full = X_train\n",
    "df_X_test_full = X_test\n",
    "\n",
    "acc_scores = {'n_features':[],'acc_score':[]}\n",
    "for i in range(len(df_X_train_full.columns),10,-1):\n",
    "    rfe = RFE(rf_classifier,n_features_to_select=i)\n",
    "    rfe = rfe.fit(df_X_train_full, y_train.ravel())\n",
    "\n",
    "    print(set(rfe.feature_names_in_).difference(rfe.get_feature_names_out()))\n",
    "    X_train_transformed = rfe.transform(df_X_train_full)\n",
    "    X_test_transformed = rfe.transform(df_X_test_full)\n",
    "    \n",
    "    df_X_train_full = pd.DataFrame(X_train_transformed,columns=rfe.get_feature_names_out())\n",
    "    df_X_test_full = pd.DataFrame(X_test_transformed,columns=rfe.get_feature_names_out())\n",
    "\n",
    "            \n",
    "    parametri_grid_lgb = {\n",
    "            'learning_rate' : [0.03368851897306291],\n",
    "            'n_estimators' : [135],\n",
    "            'max_depth' : [13],\n",
    "            'colsample_bytree' : [0.3102745722485355],\n",
    "            'reg_alpha' : [0.02354920960868235],\n",
    "            'reg_lambda' : [0.01979707285897026]\n",
    "            }\n",
    "\n",
    "\n",
    "    grid_search = GridSearchCV(lgb_classifier, parametri_grid_lgb, cv=10,\n",
    "                           scoring='accuracy',\n",
    "                           return_train_score=True,n_jobs=4)\n",
    "    grid_search.fit(df_X_train_full, y_train.ravel())\n",
    "    cross_validations[i] = grid_search \n",
    "    _tmp_cv = pd.DataFrame(grid_search.cv_results_)\n",
    "    _tmp_cv['n_features'] = i\n",
    "    _tmp_cv['features'] = ','.join([column for column in rfe.get_feature_names_out() ])\n",
    "    \n",
    "    df_cross_validations = pd.concat([df_cross_validations,_tmp_cv])\n",
    "    \n",
    "    model = grid_search.best_estimator_\n",
    "    model.fit(df_X_train_full,y_train.ravel())\n",
    "    y_pred = model.predict(df_X_test_full)  \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    print(accuracy)\n",
    "    acc_scores['n_features'].append(i)\n",
    "    acc_scores['acc_score'].append(accuracy)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.363181</td>\n",
       "      <td>0.669651</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.686792</td>\n",
       "      <td>0.694340</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.713208</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.675472</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.692206</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.970625</td>\n",
       "      <td>0.966009</td>\n",
       "      <td>0.968947</td>\n",
       "      <td>0.966429</td>\n",
       "      <td>0.973143</td>\n",
       "      <td>0.970625</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.968960</td>\n",
       "      <td>0.967701</td>\n",
       "      <td>0.969285</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>179</td>\n",
       "      <td>m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.839954</td>\n",
       "      <td>1.426995</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.690566</td>\n",
       "      <td>0.732075</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.690566</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.690566</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.691832</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968947</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.972723</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>0.971896</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>165</td>\n",
       "      <td>m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.874140</td>\n",
       "      <td>1.112533</td>\n",
       "      <td>0.028625</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.683019</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.694340</td>\n",
       "      <td>0.683019</td>\n",
       "      <td>0.683019</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.691827</td>\n",
       "      <td>0.018786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969786</td>\n",
       "      <td>0.968947</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>0.972723</td>\n",
       "      <td>0.973982</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.971884</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.971477</td>\n",
       "      <td>0.970921</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>184</td>\n",
       "      <td>m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.895076</td>\n",
       "      <td>1.027447</td>\n",
       "      <td>0.030477</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.694340</td>\n",
       "      <td>0.743396</td>\n",
       "      <td>0.690566</td>\n",
       "      <td>0.686792</td>\n",
       "      <td>0.690566</td>\n",
       "      <td>0.705660</td>\n",
       "      <td>0.686792</td>\n",
       "      <td>0.683019</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966429</td>\n",
       "      <td>0.967268</td>\n",
       "      <td>0.969786</td>\n",
       "      <td>0.967268</td>\n",
       "      <td>0.970206</td>\n",
       "      <td>0.971465</td>\n",
       "      <td>0.970625</td>\n",
       "      <td>0.968527</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.968121</td>\n",
       "      <td>0.969285</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>156</td>\n",
       "      <td>m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.001956</td>\n",
       "      <td>1.373305</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.683019</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.683019</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.691081</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972723</td>\n",
       "      <td>0.971465</td>\n",
       "      <td>0.967268</td>\n",
       "      <td>0.969786</td>\n",
       "      <td>0.973563</td>\n",
       "      <td>0.971884</td>\n",
       "      <td>0.970625</td>\n",
       "      <td>0.969786</td>\n",
       "      <td>0.973154</td>\n",
       "      <td>0.969379</td>\n",
       "      <td>0.970963</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>181</td>\n",
       "      <td>m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.836839</td>\n",
       "      <td>0.942733</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.694340</td>\n",
       "      <td>0.694340</td>\n",
       "      <td>0.686792</td>\n",
       "      <td>0.720755</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.667925</td>\n",
       "      <td>0.662879</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.691079</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.942929</td>\n",
       "      <td>0.943768</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.941670</td>\n",
       "      <td>0.941251</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.938733</td>\n",
       "      <td>0.944211</td>\n",
       "      <td>0.940856</td>\n",
       "      <td>0.942346</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>71</td>\n",
       "      <td>m_p_r_eta,m_ac_privilegio_lavoratori_sett_pubb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       6.363181      0.669651         0.025316        0.005098   \n",
       "0       5.839954      1.426995         0.025541        0.009167   \n",
       "0       5.874140      1.112533         0.028625        0.011545   \n",
       "0       4.895076      1.027447         0.030477        0.010961   \n",
       "0       6.001956      1.373305         0.031988        0.015321   \n",
       "0       3.836839      0.942733         0.023502        0.008369   \n",
       "\n",
       "  param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "0               0.310275            0.033689              13   \n",
       "0               0.310275            0.033689              13   \n",
       "0               0.310275            0.033689              13   \n",
       "0               0.310275            0.033689              13   \n",
       "0               0.310275            0.033689              13   \n",
       "0               0.310275            0.033689              13   \n",
       "\n",
       "  param_n_estimators param_reg_alpha param_reg_lambda  \\\n",
       "0                135        0.023549         0.019797   \n",
       "0                135        0.023549         0.019797   \n",
       "0                135        0.023549         0.019797   \n",
       "0                135        0.023549         0.019797   \n",
       "0                135        0.023549         0.019797   \n",
       "0                135        0.023549         0.019797   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.698113   \n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.690566   \n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.683019   \n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.694340   \n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.683019   \n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.679245   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.709434           0.686792           0.694340           0.701887   \n",
       "0           0.732075           0.679245           0.690566           0.701887   \n",
       "0           0.735849           0.694340           0.683019           0.683019   \n",
       "0           0.743396           0.690566           0.686792           0.690566   \n",
       "0           0.754717           0.679245           0.679245           0.698113   \n",
       "0           0.698113           0.694340           0.694340           0.686792   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.713208           0.698113           0.675472           0.674242   \n",
       "0           0.690566           0.698113           0.679245           0.674242   \n",
       "0           0.698113           0.701887           0.698113           0.659091   \n",
       "0           0.705660           0.686792           0.683019           0.659091   \n",
       "0           0.709434           0.683019           0.660377           0.681818   \n",
       "0           0.720755           0.709434           0.667925           0.662879   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.670455         0.692206        0.014181                1   \n",
       "0           0.681818         0.691832        0.015784                1   \n",
       "0           0.681818         0.691827        0.018786                1   \n",
       "0           0.674242         0.691447        0.020900                1   \n",
       "0           0.681818         0.691081        0.024414                1   \n",
       "0           0.696970         0.691079        0.016771                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.970625            0.966009            0.968947   \n",
       "0            0.968947            0.970206            0.968527   \n",
       "0            0.969786            0.968947            0.968527   \n",
       "0            0.966429            0.967268            0.969786   \n",
       "0            0.972723            0.971465            0.967268   \n",
       "0            0.943349            0.942929            0.943768   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0            0.966429            0.973143            0.970625   \n",
       "0            0.970206            0.972723            0.968527   \n",
       "0            0.972723            0.973982            0.970206   \n",
       "0            0.967268            0.970206            0.971465   \n",
       "0            0.969786            0.973563            0.971884   \n",
       "0            0.943349            0.941670            0.941251   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0            0.970206            0.970206            0.968960   \n",
       "0            0.970206            0.968527            0.971896   \n",
       "0            0.971884            0.970206            0.971477   \n",
       "0            0.970625            0.968527            0.973154   \n",
       "0            0.970625            0.969786            0.973154   \n",
       "0            0.943349            0.938733            0.944211   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  n_features  \\\n",
       "0            0.967701          0.969285         0.002044         179   \n",
       "0            0.968121          0.969789         0.001478         165   \n",
       "0            0.971477          0.970921         0.001616         184   \n",
       "0            0.968121          0.969285         0.002021         156   \n",
       "0            0.969379          0.970963         0.001866         181   \n",
       "0            0.940856          0.942346         0.001606          71   \n",
       "\n",
       "                                            features  \n",
       "0  m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...  \n",
       "0  m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...  \n",
       "0  m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...  \n",
       "0  m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...  \n",
       "0  m_sesso,m_p_r_eta,m_p_scolarita,m_p_pubblico_p...  \n",
       "0  m_p_r_eta,m_ac_privilegio_lavoratori_sett_pubb...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cross_validations.sort_values('mean_test_score',ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.836839</td>\n",
       "      <td>0.942733</td>\n",
       "      <td>0.023502</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.310275</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>13</td>\n",
       "      <td>135</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.019797</td>\n",
       "      <td>{'colsample_bytree': 0.3102745722485355, 'lear...</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.69434</td>\n",
       "      <td>0.69434</td>\n",
       "      <td>0.686792</td>\n",
       "      <td>0.720755</td>\n",
       "      <td>0.709434</td>\n",
       "      <td>0.667925</td>\n",
       "      <td>0.662879</td>\n",
       "      <td>0.69697</td>\n",
       "      <td>0.691079</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.942929</td>\n",
       "      <td>0.943768</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.94167</td>\n",
       "      <td>0.941251</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.938733</td>\n",
       "      <td>0.944211</td>\n",
       "      <td>0.940856</td>\n",
       "      <td>0.942346</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>71</td>\n",
       "      <td>m_p_r_eta,m_ac_privilegio_lavoratori_sett_pubb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.836839      0.942733         0.023502        0.008369   \n",
       "\n",
       "  param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "0               0.310275            0.033689              13   \n",
       "\n",
       "  param_n_estimators param_reg_alpha param_reg_lambda  \\\n",
       "0                135        0.023549         0.019797   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'colsample_bytree': 0.3102745722485355, 'lear...           0.679245   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.698113            0.69434            0.69434           0.686792   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.720755           0.709434           0.667925           0.662879   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.69697         0.691079        0.016771                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.943349            0.942929            0.943768   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0            0.943349             0.94167            0.941251   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0            0.943349            0.938733            0.944211   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  n_features  \\\n",
       "0            0.940856          0.942346         0.001606          71   \n",
       "\n",
       "                                            features  \n",
       "0  m_p_r_eta,m_ac_privilegio_lavoratori_sett_pubb...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_res = df_cross_validations.sort_values('mean_test_score',ascending=False).head(6)\n",
    "tab_res = tab_res.tail(1)\n",
    "tab_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m_p_r_eta',\n",
       " 'm_ac_privilegio_lavoratori_sett_pubblico',\n",
       " 'm_ac_propensioneRischio_italia_vs_europa',\n",
       " 'm_ac_importanza_partiti',\n",
       " 'm_ac_diminuzione_ruolo_partiti',\n",
       " 'm_ac_affidamento_pubblica_tecnici',\n",
       " 'm_ac_valori_resistenza_altra_epoca',\n",
       " 'm_ac_sindacato_ancoraUtile',\n",
       " 'm_ac_uguaglianza_sociale_frena_individui',\n",
       " 'm_ac_troppo_focus_uguaglianza_vs_merito',\n",
       " 'm_ac_meglio_uguaglianza_vs_merito_singolo',\n",
       " 'm_op_disorientamento_veros_realta_quotidiana',\n",
       " 'm_ac_vantaggi_globalizz_economie_mercati',\n",
       " 'm_ac_dovere_difesa_produzPaese_vs_globaliz',\n",
       " 'm_ac_nonSicuro_doveVive',\n",
       " 'm_ac_repressione_unicaArma_vs_crimin',\n",
       " 'm_ac_crimin_diventera_incontenibile',\n",
       " 'm_ac_validita_insegnamChiesa',\n",
       " 'm_ac_societa_troppoPermissiva_gay',\n",
       " 'm_ac_legalizz_drogheLeggere',\n",
       " 'm_ac_chiesa_nonDovrebbe_condizionare_stato.1',\n",
       " 'm_ac_testamento_biologico',\n",
       " 'm_ac_immigrati_rubano_lavoro',\n",
       " 'm_ac_immigrati_risorsa',\n",
       " 'm_ac_immigrati_portano_criminalita',\n",
       " 'm_ac_immigrati_devono_adeguarsi',\n",
       " 'm_ac_immigrati_diritto_voto',\n",
       " 'm_ac_immigrati_nonRispettano_regoleDelloStareInsieme',\n",
       " 'm_op_sentimento_italianoVSeuropeo',\n",
       " 'm_ac_modernizzazioneItalia_grazie_UE',\n",
       " 'm_ac_religioneIslamica_pericoloPerTutti',\n",
       " 'm_ac_musulmaniInItalia_dirittoReligione_inScuole',\n",
       " 'm_ac_italia_troppeConcessioni_immigratiMusulmani',\n",
       " 'm_ac_generazioniFuture_vivrannoPeggio',\n",
       " 'm_op_partecipazione_in_UE',\n",
       " 'm_ac_troppo_allarmismo_ecologia_inquinamento',\n",
       " 'm_ac_sviluppoEconomico_incompatibileCon_tutelaAmbiente',\n",
       " 'm_ac_preoccupazione_situazioneAmbientale_luogoInCuiVivo',\n",
       " 'm_ac_difesa_scuolaPubblica_insensata',\n",
       " 'm_ac_attuale_classeInsegnante_incompetente',\n",
       " 'm_ac_problemi_eticiMorali_sperimentazioneGenetica',\n",
       " 'm_ac_nord_unicoMotore_economiaItaliana',\n",
       " 'm_ac_lavoroNord_consente_diEssere_alPasso_con_UE',\n",
       " 'm_ac_guerre_talvolta_maleNecessario.1',\n",
       " 'm_ac_italia_ipartecipazioneIn_missioniMilitariEstere',\n",
       " 'm_ac_lavorare_importante_postoStabile_no',\n",
       " 'm_op_rinuncie_per_postoStabile',\n",
       " 'm_ac_badare_propriInteressi_perSopravvivere',\n",
       " 'm_ac_modelloImprenditorialePrivato_unico_produceRicchezzaPerTutti',\n",
       " 'm_ac_modelloImprenditorialePrivato_unico_garantireEquita',\n",
       " 'm_ac_italia_riparte_solo_puntandoSu_cittaEterritori_noStatoCentrale',\n",
       " 'm_ac_dazi_su_produzioni_importanti',\n",
       " 'm_ac_generazionePrecedente_migliore_qualitaVita',\n",
       " 'm_ac_meno_relazioniSociali_amicali_vs_qualcheAnnoFa',\n",
       " 'm_op_fiducia_negli_amici_che_fanno_parte_della_sua_rete_social_network',\n",
       " 'm_op_fiducia_nei_suoi_parenti',\n",
       " 'm_op_fiducia_negli_amici_e_conoscenti_dei_suoi_familiari',\n",
       " 'm_op_fiducia_nei_colleghi_di_lavoro',\n",
       " 'm_op_aiutoReciproco_inCasoDiBisogno_degli_italiani',\n",
       " 'm_op_aiutoReciproco_inCasoDiBisogno_dei_colleghi_di_lavoro',\n",
       " 'm_op_ottica_di_beneComune_italia',\n",
       " 'm_op_ottica_di_beneComune_comuneResidenza',\n",
       " 'm_op_attivita_associazionismo_Italia',\n",
       " 'm_op_importanza_nellaSocieta_altruismo',\n",
       " 'm_op_importanza_nellaSocieta_mutualismo',\n",
       " 'm_op_danni_populismo_in_italia',\n",
       " 'm_op_peso_volontariato_in_economiaPaese',\n",
       " 'm_TREND_25_IMMIGRAZIONE_atteggiamento_POSITIVO_nei_confronti_degli_immigrati',\n",
       " 'm_TREND_26_NAZIONE_EUROPA',\n",
       " 'm_TREND_30_ISLAM_tolleranza_e_fiducia_nei_confronti_dell_Islam',\n",
       " 'm_TREND_53_IL_PERICOLO_POPULISTA']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_set = tab_res['features']\n",
    "best_features_set = tab_res['features'].values[0]\n",
    "best_features_set = best_features_set.split(',')\n",
    "best_features_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.3102745722485355,\n",
       " 'learning_rate': 0.03368851897306291,\n",
       " 'max_depth': 13,\n",
       " 'n_estimators': 135,\n",
       " 'reg_alpha': 0.02354920960868235,\n",
       " 'reg_lambda': 0.01979707285897026}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_res['params'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

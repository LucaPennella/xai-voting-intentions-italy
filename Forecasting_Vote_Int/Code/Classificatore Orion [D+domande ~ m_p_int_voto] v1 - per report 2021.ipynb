{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# General\n","import os\n","import gc\n","import glob\n","\n","# Plotting\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mtick\n","\n","# Data science\n","import numpy as np\n","import pandas as pd\n","import json\n","## Feature selection\n","from scipy.stats import spearmanr\n","from scipy.cluster import hierarchy\n","\n","# ML\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, cross_val_predict\n","from sklearn import preprocessing\n","from copy import deepcopy\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score, confusion_matrix, plot_confusion_matrix,classification_report\n","from sklearn import metrics\n","from sklearn.inspection import permutation_importance\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n","# # Hyperparameter tuning\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import f1_score\n","# Model persistence\n","import joblib\n","\n","# mostra grafici in finestra\n","get_ipython().run_line_magic('matplotlib', 'qt') #'inline'\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["os.chdir(os.path.dirname(__file__)) # change to dir name (excludes file from name) of filepath\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('..\\..\\Dati_BB\\Walden 97-19\\Dati Orion\\Walden 16-19 [D+domande+m_p_int_voto].csv', sep=';')#,nrwos=100)\n","print(df.shape)\n","df.head()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#modello base\n","clf_base = RandomForestClassifier(n_estimators = 1000,\n","                            max_depth = 12,\n","                            random_state = 42,\n","                            max_features=5,\n","                            criterion = 'gini',\n","                            class_weight = \"balanced\")# class_weight)\n","# modello principale\n","clf = deepcopy(clf_base)\n","\n","# encoders and scalers\n","encoder_bin = OneHotEncoder(drop = 'first') #for binary features (drops one)\n","encoder_cat  = OneHotEncoder() # for categorical features (no drops)\n","\n","MM_scaler = MinMaxScaler()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# int voto aliases\n","diz_aliases_int_voto = {\"Partito Democratico-PD\":'PD',\n","                \"Partito Democratico\":'PD',\n","                \"Lega con Salvini\":'Destra',\n","                \"Lega Nord\":'Destra',\n","                \"Lega\":'Destra',\n","                \"Forza Italia\":'Destra',\n","                \"Fratelli d'Italia\":'Destra',\n","                'MoVimento 5 Stelle':'M5S',\n","                'Movimento 5 stelle':'M5S',\n","                'voterei  scheda bianca / annullerei la scheda':'bianca/nulla',\n","                'voterei scheda bianca / scheda nulla':'bianca/nulla',\n","                \"piu' Europa con Emma Bonino\":'+Europa',\n","                'Sinistra italiana (SEL + altri)':'Sinistra',\n","                'Potere al Popolo':'Sinistra',\n","                'Rifondazione Comunista':'Sinistra',\n","                \"Fratelli d'Italia-Alleanza Nazionale&nbsp;\":\"Destra\",\n","                'La Sinistra':'Sinistra'}\n","\n","# pulitura dati in int voto e autocol\n","df['m_p_int_voto'] = df['m_p_int_voto'].replace(diz_aliases_int_voto)\n","df_ready = df[(df.m_p_int_voto!='preferisco non rispondere') & (df.m_p_int_voto!='sono indeciso')&\n","        (df.m_p_int_voto!='non andrei a votare')&(df.m_p_int_voto!='bianca/nulla')&\n","        (df.m_p_autocol!='preferisco non rispondere')]\n","df_ready.m_p_int_voto.value_counts()\n","\n","# identificazione variabili di accordo\n","variabili_ac = []\n","for var_ac in df_ready.columns:\n","    if '_ac_' in var_ac:\n","        print(var_ac)\n","        variabili_ac.append(var_ac)\n","\n","# preparazione dati pre-train-test-split\n","df_pre_tts = df_ready[df_ready.m_p_int_voto.map(df_ready.m_p_int_voto.value_counts()) > 100]\n","df_pre_tts = df_pre_tts.dropna()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["####################################### 1) MODELLO di BASE\n","# # tieni solo variabili demografiche\n","# X_0 = df_pre_tts.drop(columns = variabili_ac+['m_p_autocol']+['m_p_int_voto'])\n","# y = df_pre_tts.m_p_int_voto\n","\n","# # crea dummies\n","# not_dummy = ['m_p_r_eta']\n","# X_dummies_0 = X_0.drop(columns = not_dummy)\n","# encoder_bin.fit(X_dummies_0)\n","# X_dummies = encoder_bin.transform(X_dummies_0)\n","\n","# # trasforma in dataframe\n","# X_dummies = pd.DataFrame(X_dummies.toarray(), columns=encoder_bin.get_feature_names())\n","\n","# # scala tutte le variabili con MinMaxScaler\n","# # aggiungi le non_dummy\n","# X = pd.concat([X_0[not_dummy].reset_index(drop=True),X_dummies], axis=1)\n","# # scala tutto\n","# MM_scaler.fit(X)\n","# X[X.columns] = MM_scaler.transform(X)\n","\n","from rachael_noodles.feature_engineering import XY_encoder\n","XX, yy = XY_encoder(df = df_pre_tts, target = 'm_p_int_voto',\n","                                    numeric_features = ['m_p_r_eta'],\n","                                    categorical_features = ['m_p_r_ampiezza6','m_istat_reg'],\n","                                    bool_features = ['m_sesso', 'm_p_pubblico_privato'])\n","\n","# train test split\n","X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size = 1/3, random_state = 40, #y.factorize()[0]\n","                                                stratify = yy)\n","\n","# allena modello\n","clf_base.fit(X_train, y_train)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Hyperparameter tuning\n"," Hyperparameter grid\n"," Estimator for use in random search\n"," Create the random search model\n"," Run search and store best model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","y_pred_best = clf_base_best.predict(X_test)\n","print('_'+classification_report(y_test, y_pred_best))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cross-validation\n","from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn import metrics\n","scores = cross_val_score(clf_base_best, X_train, y_train, cv = 4, scoring = 'f1_micro')\n","print(\"Cross-validation\")\n","print(np.round(scores,2))\n",""]},{"cell_type":"markdown","metadata":{},"source":["# PLOTTING\n"," CONFUSION MATRIX with best model"]},{"cell_type":"markdown","metadata":{},"source":[" ## Display feature importances\n","sns.set(font_scale=1)\n"," Print the feature ranking\n"," Plot the feature importances of the forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["############################### 1) MODELLO con VALORIALI SELEZIONATE\n","# tieni solo variabili demografiche\n","# X_0 = df_pre_tts.drop(columns = ['m_p_int_voto'])\n","# y = df_pre_tts.m_p_int_voto\n","\n","# # crea dummies\n","# not_dummy = variabili_ac+['m_p_r_eta']\n","# # dummy booleane\n","# dummy_bool = ['m_sesso', 'm_p_pubblico_privato']\n","# X_dummies_bool_0 = X_0[dummy_bool]\n","# encoder_bin.fit(X_dummies_bool_0)\n","# X_dummies_bool = encoder_bin.transform(X_dummies_bool_0)\n","# X_dummies_bool = pd.DataFrame(X_dummies_bool.toarray(), columns=encoder_bin.get_feature_names())\n","\n","# # dummy categoriche\n","# X_dummies_cat_0 = X_0.drop(columns = not_dummy+dummy_bool)\n","# encoder_cat.fit(X_dummies_cat_0)\n","# X_dummies_cat = encoder_cat.transform(X_dummies_cat_0)\n","# # trasforma in dataframe\n","# X_dummies_cat = pd.DataFrame(X_dummies_cat.toarray(), columns=encoder_cat.get_feature_names())\n","\n","# # scala tutte le variabili con MinMaxScaler\n","# # aggiungi le non_dummy\n","# X = pd.concat([X_0[not_dummy].reset_index(drop=True),X_dummies_bool, X_dummies_cat], axis=1)\n","\n","# # scala tutto\n","# MM_scaler = MinMaxScaler().fit(X)\n","# X[X.columns] = MM_scaler.transform(X)\n","\n","from rachael_noodles.feature_engineering import XY_encoder\n","X, y = XY_encoder(df = df_pre_tts, target = 'm_p_int_voto',\n","                                    numeric_features = variabili_ac+['m_p_r_eta'],\n","                                    categorical_features = ['m_p_autocol','m_p_r_ampiezza6','m_istat_reg'],\n","                                    bool_features = ['m_sesso', 'm_p_pubblico_privato'])\n","\n","# train test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 40, #y.factorize()[0]\n","                                                stratify = y)\n","\n","# allena modello\n","clf.fit(X_train, y_train)\n","print(\"RF train accuracy: %0.3f\" % clf.score(X_train, y_train))\n","print(\"RF test accuracy: %0.3f\" % clf.score(X_test, y_test))\n",""]},{"cell_type":"markdown","metadata":{},"source":[" # Hyperparameter tuning\n","# stessi parametri del modello base\n"," Create the random search model\n"," Fit model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred_best = clf_best.predict(X_test)\n","print('_'+classification_report(y_test, y_pred_best))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores = cross_val_score(clf_best, X_train, y_train, cv = 4, scoring='f1_micro')\n","print(\"Cross-validation\")\n","print(np.round(scores,2))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf_best.variables_untransformed = list(df_pre_tts.columns)\n","clf_best.feature_names = list(X_train.columns)\n","#joblib.dump(clf_best, 'Models\\Orion_clf_best [39 feat - no valle daosta].joblib')\n",""]},{"cell_type":"markdown","metadata":{},"source":["# PLOTTING\n"," CONFUSION MATRIX with best model"]},{"cell_type":"markdown","metadata":{},"source":[" ## Display feature importances\n","sns.set(font_scale=1)\n"," Print the feature ranking\n"," Plot the feature importances of the forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.stats import spearmanr\n","from scipy.cluster import hierarchy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = clf_best\n","result = permutation_importance(model, X_train, y_train, n_repeats=10,\n","                                random_state=42)\n","perm_sorted_idx = result.importances_mean.argsort()\n","\n","tree_importance_sorted_idx = np.argsort(model.feature_importances_)\n","tree_indices = np.arange(0, len(model.feature_importances_)) + 0.5\n","\n","fig, ax1 = plt.subplots(figsize=(12, 8))\n","ax1.barh(tree_indices,\n","         model.feature_importances_[tree_importance_sorted_idx], height=0.7)\n","ax1.set_yticklabels(X_train.columns[tree_importance_sorted_idx])\n","ax1.set_yticks(tree_indices)\n","ax1.set_ylim((0, len(model.feature_importances_)))\n","plt.tight_layout()\n","\n","fig, ax2 = plt.subplots(figsize=(10,10))\n","ax2.boxplot(result.importances[perm_sorted_idx].T, vert=False,\n","            labels=X_train.columns[perm_sorted_idx])\n","ax2.set_xlabel(\"Drop in accuracy if permuted\", size = 12)\n","#ax2.axvline(x=0.05, c = 'red')\n","fig.tight_layout()\n","plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig,ax1 = plt.subplots(figsize=(12,8))\n","corr = spearmanr(X).correlation\n","corr_linkage = hierarchy.ward(corr)\n","dendro = hierarchy.dendrogram(corr_linkage, labels=X.columns, orientation='right',\n","color_threshold=1.5, ax=ax1)\n","dendro_idx = np.arange(0, len(dendro['ivl']))\n","#plt.axvline(x=1.6, c = 'orange')\n","#plt.axvline(x=1.7, c = 'red')\n","plt.tight_layout()\n","\n","fig, ax2 = plt.subplots(figsize=(10,10))\n","ax2.imshow(np.abs(corr[dendro['leaves'], :][:, dendro['leaves']][:,::-1]),cmap='RdBu',origin='lower')\n","ax2.set_yticks(dendro_idx)\n","ax2.set_yticklabels(dendro['ivl'])\n","ax2.set_xticks([])\n","fig.tight_layout()\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# algo comparison\n","from sklearn import model_selection\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import AdaBoostClassifier\n","\n","models = []\n","models.append(('RF', RandomForestClassifier()))#RandomForestClassifier()))\n","models.append(('ADA', AdaBoostClassifier()))\n","models.append(('LDA', LinearDiscriminantAnalysis()))\n","models.append(('KNN', KNeighborsClassifier()))\n","models.append(('SVM', SVC()))\n","# evaluate each model in turn\n","results = []\n","names = []\n","scoring = 'f1_micro' #'f1_micro'\n","for name, model in models:\n","\tkfold = model_selection.KFold(n_splits=10, random_state=42)\n","\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n","\tresults.append(cv_results)\n","\tnames.append(name)\n","\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","\tprint(msg)\n","# boxplot algorithm comparison\n","fig = plt.figure()\n","fig.suptitle('Baseline Algorithm Comparison')\n","ax = fig.add_subplot(111)\n","plt.boxplot(results)\n","ax.set_xticklabels(names)\n","ax.set_xlabel(\"Modello\", size = 12)\n","ax.set_ylabel(\"Accuratezza\", size = 12)\n","ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.,0))\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# hyperparameter tuning modelli di confronto\n","from sklearn.tree import DecisionTreeClassifier\n","# AdABoost\n","ada_param_grid = { \n","    'n_estimators': [50, 100, 300, 500],\n","    'base_estimator':[None, DecisionTreeClassifier(),SVC(),DecisionTreeClassifier(class_weight = 'balanced',\n","    criterion = 'gini'),DecisionTreeClassifier(class_weight = 'balanced',\n","    criterion = 'entropy')],\n","}\n","\n","# Estimator for use in random search\n","ada_estimator = AdaBoostClassifier(random_state = RSEED)\n","\n","\n","adaCV = GridSearchCV(ada_estimator, ada_param_grid, n_jobs = None, #-1 for all cores \n","                        scoring = \"f1_micro\", cv = 4, verbose = 1)\n","\n","# Fit model\n","adaCV.fit(X_train, y_train)\n","ada_best = adaCV.best_estimator_\n","print('Best hyperparameters', adaCV.best_params_)\n","print(\"Ada train accuracy: %0.3f\" % ada_best.score(X_train, y_train))\n","print(\"Ada test accuracy: %0.3f\" % ada_best.score(X_test, y_test))\n","\n","# classification report\n","y_pred_ada = ada_best.predict(X_test)\n","print('_'+classification_report(y_test, y_pred_ada))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LDA\n","lda_param_grid = { \n","    'solver': ['svd','lsqr','eigen'],\n","    'shrinkage':[None, 'auto']\n","}\n","\n","# Estimator for use in random search\n","lda_estimator = LinearDiscriminantAnalysis()\n","\n","ldaCV = GridSearchCV(lda_estimator, lda_param_grid, n_jobs = None, #-1 for all cores \n","                        scoring = \"f1_micro\", cv = 4, verbose = 1)\n","\n","# Fit model\n","ldaCV.fit(X_train, y_train)\n","lda_best = ldaCV.best_estimator_\n","print(\"LDA train accuracy: %0.3f\" % lda_best.score(X_train, y_train))\n","print(\"LDA test accuracy: %0.3f\" % lda_best.score(X_test, y_test))\n","\n","# classification report\n","y_pred_lda = lda_best.predict(X_test)\n","print('_'+classification_report(y_test, y_pred_lda))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# KNN\n","knn_param_grid = { \n","    'leaf_size': list(range(1,50)),\n","    'n_neighbors': list(range(1,30)),\n","    'p' : [1,2]\n","}\n","\n","# Estimator for use in random search\n","knn_estimator = KNeighborsClassifier()\n","\n","scoring = \"f1_macro\" # works better than micro, which does not predict Sinistra\n","knnCV = RandomizedSearchCV(knn_estimator, knn_param_grid, n_jobs = None, #-1 for all cores \n","                        scoring = scoring, cv = 4, \n","                        n_iter = 40, verbose = 1, random_state=RSEED)\n","\n","# Fit model\n","knnCV.fit(X_train, y_train)\n","knn_best = knnCV.best_estimator_\n","print(\"KNN train accuracy: %0.3f\" % knn_best.score(X_train, y_train))\n","print(\"KNN test accuracy: %0.3f\" % knn_best.score(X_test, y_test))\n","\n","# classification report\n","y_pred_knn = knn_best.predict(X_test)\n","print('_'+classification_report(y_test, y_pred_knn))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SVC\n","svc_param_grid = { \n","    'C': [6,7,8,9,10,11,12], \n","    'kernel': ['linear','rbf']\n","}\n","\n","# Estimator for use in random search\n","svc_estimator = SVC()\n","\n","scoring = \"f1_macro\" #micro omits Sinistra\n","svcCV = RandomizedSearchCV(svc_estimator, svc_param_grid, n_jobs = None, #-1 for all cores \n","                        scoring = scoring, cv = 4, verbose = 1,\n","                        n_iter = 40, random_state=RSEED)\n","\n","# Fit model\n","svcCV.fit(X_train, y_train)\n","svc_best = svcCV.best_estimator_\n","print(\"Best hyperparameters: \", svcCV.best_params_)\n","print(\"SVC train accuracy: %0.3f\" % svc_best.score(X_train, y_train))\n","print(\"SVC test accuracy: %0.3f\" % svc_best.score(X_test, y_test))\n","\n","# classification report\n","y_pred_svc = svc_best.predict(X_test)\n","print('_'+classification_report(y_test, y_pred_svc))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# best models comparison\n","best_models = []\n","best_models.append(('RF', clf_best))#RandomForestClassifier()))\n","best_models.append(('ADA', ada_best))\n","best_models.append(('LDA', lda_best))\n","best_models.append(('KNN', knn_best))\n","best_models.append(('SVM', svc_best))\n","# evaluate each model in turn\n","results = []\n","names = []\n","scoring = 'f1_micro' #'f1_micro'\n","for name, model in best_models:\n","\tkfold = model_selection.KFold(n_splits=10, random_state=42)\n","\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n","\tresults.append(cv_results)\n","\tnames.append(name)\n","\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n","\tprint(msg)\n","# boxplot algorithm comparison\n","fig = plt.figure()\n","fig.suptitle('Tuned Algorithm Comparison')\n","ax = fig.add_subplot(111)\n","plt.boxplot(results)\n","ax.set_xticklabels(names)\n","ax.set_xlabel(\"Modello\", size = 12)\n","ax.set_ylabel(\"Accuratezza\", size = 12)\n","ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.,0))\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}